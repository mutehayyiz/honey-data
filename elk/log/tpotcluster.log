[2022-04-28T15:38:32,906][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-28T15:38:33,004][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-28T15:38:33,005][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-28T15:38:41,159][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-28T15:38:41,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-28T15:38:41,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-28T15:38:41,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-28T15:38:41,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-28T15:38:41,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-28T15:38:41,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-28T15:38:41,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-28T15:38:41,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-28T15:38:41,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-28T15:38:41,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-28T15:38:41,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-28T15:38:41,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-28T15:38:41,179][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-28T15:38:41,181][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-28T15:38:41,184][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-28T15:38:41,186][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-28T15:38:41,186][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-28T15:38:41,188][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-28T15:38:41,190][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-28T15:38:41,191][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-28T15:38:41,192][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-28T15:38:41,192][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-28T15:38:41,194][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-28T15:38:41,195][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-28T15:38:41,196][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-28T15:38:41,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-28T15:38:41,198][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-28T15:38:41,199][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-28T15:38:41,199][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-28T15:38:41,202][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-28T15:38:41,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-28T15:38:41,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-28T15:38:41,204][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-28T15:38:41,205][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-28T15:38:41,207][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-28T15:38:41,207][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-28T15:38:41,208][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-28T15:38:41,209][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-28T15:38:41,210][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-28T15:38:41,213][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-28T15:38:41,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-28T15:38:41,215][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-28T15:38:41,215][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-28T15:38:41,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-28T15:38:41,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-28T15:38:41,217][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-28T15:38:41,218][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-28T15:38:41,220][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-28T15:38:41,221][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-28T15:38:41,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-28T15:38:41,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-28T15:38:41,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-28T15:38:41,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-28T15:38:41,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-28T15:38:41,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-28T15:38:41,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-28T15:38:41,240][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-28T15:38:41,245][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-28T15:38:41,345][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [101.6gb], net total_space [125.8gb], types [ext4]
[2022-04-28T15:38:41,346][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-28T15:38:41,689][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-28T15:38:55,773][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-28T15:38:55,779][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-28T15:38:56,726][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-28T15:38:56,860][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-28T15:38:57,732][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-28T15:38:58,474][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-28T15:38:58,475][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-28T15:38:58,517][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-28T15:38:58,518][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-28T15:38:58,710][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-28T15:39:01,794][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-28T15:39:01,994][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 319, version: 14667, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-28T15:39:02,235][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 319, version: 14667, reason: Publication{term=319, version=14667}
[2022-04-28T15:39:02,368][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-28T15:39:02,368][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-28T15:39:03,231][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-28T15:39:03,237][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [66] indices into cluster_state
[2022-04-28T15:39:04,088][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-28T15:39:04,089][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-28T15:39:04,914][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-ASN.mmdb]
[2022-04-28T15:39:05,320][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-28T15:39:05,324][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-28T15:39:05,324][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-28T15:39:05,985][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-28T15:39:06,214][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-28T15:39:09,253][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-28T15:39:09,289][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-ASN.mmdb]
[2022-04-28T15:39:09,312][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-City.mmdb]
[2022-04-28T15:39:09,685][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-28T15:39:09,816][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-28T15:39:09,818][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-28T15:39:18,635][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-04-28T15:39:18,903][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-04-28T15:39:20,112][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-28T15:39:20,158][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-City.mmdb]
[2022-04-28T15:39:20,160][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-Country.mmdb]
[2022-04-28T15:39:22,262][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-28T15:39:22,325][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-Country.mmdb]
[2022-04-28T15:39:22,869][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-28T15:39:22,878][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-28T15:39:23,525][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0], [.kibana-event-log-7.16.2-000001][0], [logstash-2022.03.13][0]]]).
[2022-04-28T15:39:24,074][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-28T15:39:24,074][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-28T15:40:04,729][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 1148 finished with response BulkByScrollResponse[took=143.9ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-28T15:40:06,648][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][68] overhead, spent [259ms] collecting in the last [1s]
[2022-04-28T15:40:06,904][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 1173 finished with response BulkByScrollResponse[took=2s,timed_out=false,sliceId=null,updated=920,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-28T15:40:15,767][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-04-28T15:40:42,591][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-2022.04.28] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-28T15:40:42,789][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-2022.04.28][0]]]).
[2022-04-28T15:40:42,982][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:43,172][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:44,019][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:44,118][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:44,122][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:44,241][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:45,010][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:45,152][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:46,070][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:46,340][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:46,488][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:46,653][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:40:53,070][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:41:25,111][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:41:43,219][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:41:43,365][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:41:43,371][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:42:07,120][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:42:25,240][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:43:20,178][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:43:36,226][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:43:45,250][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:04,286][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:25,215][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:38,575][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:46,330][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:46,400][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:46,617][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:44:47,298][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:45:11,254][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:46:26,433][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:47:12,473][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:49:16,530][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:49:31,550][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:50:52,521][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:50:52,656][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:50:52,663][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:50:52,783][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:50:53,494][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:50:53,617][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:53:21,495][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:55:00,527][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:57:38,888][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T15:57:39,592][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:00:48,029][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:00:48,100][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:00:53,833][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:00:54,035][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:00:54,142][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:02:52,123][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:03:11,749][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:03:12,142][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:03:12,208][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:04:53,293][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:04:53,404][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:13:48,097][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:17:54,898][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:18:13,974][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:36:19,075][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:36:19,210][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:36:19,224][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:37:03,525][INFO ][o.e.c.m.MetadataDeleteIndexService] [tpotcluster-node-01] [logstash-1970.01.01/dT_-bXESTqOmxna6SslMrQ] deleting index
[2022-04-28T16:37:28,906][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-1970.01.01] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-28T16:37:29,403][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-1970.01.01][0]]]).
[2022-04-28T16:37:29,751][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-1970.01.01/3VgxcubuRsOl528YkobjPQ] update_mapping [_doc]
[2022-04-28T16:38:26,250][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T16:41:59,440][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][3757] overhead, spent [473ms] collecting in the last [1.7s]
[2022-04-28T16:42:02,001][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [17466ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:42:57,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [19281ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:43:12,784][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [5516ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:43:23,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [6572ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:43:39,959][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [11629ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:44:03,126][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [6772ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:46:13,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [29635ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:47:55,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5211ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:48:51,851][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5636081137ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:00,193][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/262498ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:05,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/262648368906ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:13,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12774ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:22,604][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12774507190ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:26,017][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6s/12686ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:34,095][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6s/12685732954ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:41,357][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15332ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:49:51,569][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15331866543ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:50:04,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23212ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:50:17,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23212034850ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:50:14,211][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:47654}] took [12774ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:50:31,477][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20872ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:50:39,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20872742188ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:50:45,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20053ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:50:36,539][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [20873ms] which is above the warn threshold of [5s]
[2022-04-28T16:50:43,343][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [44084ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:50:55,026][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20052336312ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:51:07,813][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22287ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:51:22,217][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@49d1d9b] took [22286ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:51:22,897][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22286960283ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:51:37,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.3s/29387ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:51:50,107][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.3s/29387620224ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:51:25,905][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:47660}] took [22287ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:51:57,119][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.2s/20268ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:52:07,126][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.2s/20267555135ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:52:21,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24031ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:52:33,931][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24030898288ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:52:46,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25304ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:52:54,791][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25304169509ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:03,978][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17440ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:10,316][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17440012414ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:18,832][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14868ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:26,593][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14867996795ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:31,320][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12370ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:38,967][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12370304975ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:53,713][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22441ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:53:59,106][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [22440ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:53:58,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22440578361ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:54:03,633][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@112cca35, interval=5s}] took [7877ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:54:01,765][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8s/7877ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:54:06,843][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8s/7877368266ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:54:40,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.8s/38842ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:54:45,571][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2s/9239994040ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:54:53,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.9s/12958ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:54:09,841][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [2.8m/173987ms] ago, timed out [42.6s/42689ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [32947]
[2022-04-28T16:54:56,699][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42560022917ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:04,075][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1s/7186ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:11,216][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1s/7185288566ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:23,822][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23414ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:30,858][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23414028660ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:30,858][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [23414ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:55:38,218][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.8s/13851ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:47,302][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.8s/13851797704ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:42,063][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:47668}] took [37266ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:55:59,465][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21622ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:55:59,962][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@561dc704, interval=1m}] took [21622ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:56:09,421][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21622033749ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:56:31,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.2s/25226ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:56:50,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.2s/25225823549ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:57:06,820][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41817ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:57:17,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41816679040ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:57:27,840][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21102ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:57:39,039][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21102079536ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:57:54,523][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27015ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:58:09,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [27015ms] which is above the warn threshold of [5000ms]
[2022-04-28T16:58:27,777][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27015359127ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:58:38,177][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.3s/43395ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:58:50,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.3s/43395123740ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:59:02,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25s/25004ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:58:57,856][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [43395ms] which is above the warn threshold of [5s]
[2022-04-28T16:59:10,959][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25s/25003503460ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T16:59:40,956][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37817ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T16:59:53,468][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37817165719ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:00:10,452][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29535ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:00:16,367][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_task_manager/_update_by_query?ignore_unavailable=true&refresh=true&conflicts=proceed][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:49692}] took [29535ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:00:24,659][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29535101868ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:00:36,530][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26003ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:00:50,902][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26002291507ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:00:58,458][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22109ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:05,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22109109988ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:09,931][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [22109ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:01:11,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.2s/13282ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:23,435][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.2s/13282017252ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:30,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18544ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:35,141][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18544561609ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:40,653][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.3s/10375ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:49,228][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.3s/10374461692ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:01:56,692][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16294ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:04,129][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16294300626ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:13,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15858ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:23,673][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15858004798ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:25,626][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [32152ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:02:29,301][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16555ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:36,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16555268421ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:28,819][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [32947] timed out after [131298ms]
[2022-04-28T17:02:46,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.7s/16777ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:02:53,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.7s/16776388886ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:01,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15881ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:13,363][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15881181095ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:21,580][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19525ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:30,291][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19525017980ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:42,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.8s/19814ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:52,163][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.8s/19814053312ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:03:41,342][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [19525ms] which is above the warn threshold of [5s]
[2022-04-28T17:04:04,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23146ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:04:12,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23146389535ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:04:26,998][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22326ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:04:36,516][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22325988897ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:04:48,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21410ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:04:57,819][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21409908261ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:05:01,341][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [43735ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:05:07,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.8s/18870ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:05:15,941][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.8s/18869960836ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:05:25,839][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18460ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:05:39,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18459698789ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:05:51,933][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26150ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:06:01,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26149826201ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:06:12,900][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21006ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:06:27,275][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21005872622ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:06:36,185][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.6s/22690ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:06:50,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.6s/22690894771ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:07:02,955][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27087ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:07:16,472][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27087066264ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:07:34,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32s/32097ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:08:00,988][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32s/32096127578ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:08:12,524][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37804ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:08:39,344][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37804733508ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:08:57,839][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43852ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:09:20,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43852118609ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:09:35,735][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39210ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:09:46,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39209126805ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:09:59,978][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23009ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:10:00,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [62218ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:10:10,875][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23009688540ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:10:22,604][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.8s/23800ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:10:24,526][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@561dc704, interval=1m}] took [23799ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:10:33,515][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23799526073ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:10:45,092][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.7s/22753ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:10:54,080][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.7s/22753346424ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:10:39,023][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [23799ms] which is above the warn threshold of [5s]
[2022-04-28T17:11:03,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@112cca35, interval=5s}] took [17724ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:11:03,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17725ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:11:11,307][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17724612430ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:11:24,824][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21933ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:11:33,668][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21933283674ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:11:45,602][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.4s/20427ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:11:54,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.4s/20427229863ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:12:05,995][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.6s/20693ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:12:17,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.6s/20692792430ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:12:28,275][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21649ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:12:40,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21649053558ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:12:54,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26131ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:12:54,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [47780ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:13:05,574][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26131169379ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:13:16,908][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23137ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:13:25,855][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23137134452ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:13:35,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18427ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:13:44,682][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18426564274ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:13:58,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22548ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:14:08,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22548203225ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:14:19,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21152ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:14:28,608][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21152202420ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:14:37,836][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [43700ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:14:39,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21109ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:14:49,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21108815763ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:15:00,954][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.7s/20720ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:15:11,681][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.7s/20719941638ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:14:54,139][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [33302] timed out after [170348ms]
[2022-04-28T17:15:19,664][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19143ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:15:16,999][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [20720ms] which is above the warn threshold of [5s]
[2022-04-28T17:15:24,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19142712006ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:15:33,870][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.1s/14189ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:15:51,181][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.1s/14188912115ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:16:02,764][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.6s/28648ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:16:17,672][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.6s/28648372110ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:16:31,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.6s/28681ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:16:47,357][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.6s/28680375196ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:17:06,140][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.6s/34631ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:17:22,241][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.6s/34631946498ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:17:36,126][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.8s/29864ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:17:41,004][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [64495ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:17:47,898][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.8s/29863443210ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:18:02,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26673ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:18:17,685][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26673173909ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:18:29,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26491ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:18:45,369][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26491244917ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:19:09,334][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.1s/36169ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:19:28,412][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.1s/36168608860ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:19:51,312][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.8s/45829ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:20:07,858][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.8s/45829368712ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:20:33,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42533ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:20:50,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42533065892ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:20:58,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [42533ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:21:07,696][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.9s/33957ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:20:51,482][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [42533ms] which is above the warn threshold of [5s]
[2022-04-28T17:21:18,526][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.9s/33956800881ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:21:35,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27155ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:21:47,153][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27155248136ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:21:56,952][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21429ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:22:05,552][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21428836758ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:22:13,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17521ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:22:26,291][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17520499383ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:22:37,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22944ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:22:44,814][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22944007518ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:23:02,158][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.6s/25699ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:23:15,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.6s/25699573843ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:23:26,281][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23928ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:23:35,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23928062443ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:23:47,814][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21356ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:23:51,895][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [45284ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:23:55,084][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21356011272ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:04,480][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16610ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:13,354][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16609656363ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:21,328][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.2s/17273ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:28,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.2s/17272655386ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:20,241][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [4.9m/298962ms] ago, timed out [2.4m/149487ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [33581]
[2022-04-28T17:24:39,703][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18017ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:47,899][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18017448004ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:49,031][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [33581] timed out after [149475ms]
[2022-04-28T17:24:53,472][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14085ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:01,689][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [14084ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:24:59,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14084963399ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:24:54,889][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14085ms] which is above the warn threshold of [5s]
[2022-04-28T17:25:05,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12207ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:07,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@561dc704, interval=1m}] took [12206ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:24:54,376][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [16.4m/987015ms] ago, timed out [13.6m/816667ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [33302]
[2022-04-28T17:25:12,998][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12206596939ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:20,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14423ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:29,152][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14423222078ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:38,153][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17772ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:45,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17772501814ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:25:49,055][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [32195ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:25:53,493][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.5s/15569ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:26:02,793][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.5s/15568545857ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:26:09,521][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16069ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:26:18,079][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16069344572ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:26:33,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24158ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:26:47,361][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24157262330ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:26:57,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.2s/24278ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:27:07,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.2s/24278447234ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:27:18,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19647ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:27:20,940][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@18d434eb] took [19646ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:27:25,921][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19646958231ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:27:35,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17629ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:27:51,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17628768864ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:00,625][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.2s/25259ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:09,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [25258ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:28:09,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.2s/25258926283ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:20,444][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@561dc704, interval=1m}] took [16979ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:28:17,515][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16979ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:32,155][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16979281310ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:41,984][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23545ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:48,860][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23545004676ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:28:55,666][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14733ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:02,266][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14732715812ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:11,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15495ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:15,066][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15495162820ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:13,594][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [33852] timed out after [98145ms]
[2022-04-28T17:29:13,436][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [15495ms] which is above the warn threshold of [5s]
[2022-04-28T17:29:25,024][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13193ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:28,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [13192ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:29:28,356][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13192766542ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:37,085][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6s/12676ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:43,678][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6s/12676496629ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:29:53,013][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15839ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:03,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15838869473ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:14,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [34948ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:30:12,206][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19109ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:21,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19109255749ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:29,037][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16828ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:35,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16827822790ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:38,268][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9525ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:34,136][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [3.1m/191286ms] ago, timed out [1.5m/93141ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{wANpCSKPS8KThEkpUlfJwQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [33852]
[2022-04-28T17:30:43,210][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9525245349ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:49,385][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10961ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:30:58,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10960608155ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:31:11,063][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21492ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:31:20,907][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21492048417ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:31:24,045][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13344ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:31:24,288][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@112cca35, interval=5s}] took [13343ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:31:24,726][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13343866610ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:31:54,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [8987ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:32:07,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@3683a987] took [5215ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:32:21,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [5532ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:32:44,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [14386ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:33:48,928][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@604e2a24] took [7023ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:34:40,186][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [37840ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:36:47,773][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [45888ms] which is above the warn threshold of [5s]
[2022-04-28T17:39:08,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10967ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:39:35,152][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10967523523ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:39:33,375][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_7.17.0/_search?from=0&rest_total_hits_as_int=true&size=100][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:49678}] took [157875ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:40:11,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/92054ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:40:12,070][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/.kibana_7.17.0/_doc/endpoint%3Auser-artifact-manifest%3Aendpoint-manifest-v1][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:49680}] took [188147ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:40:32,387][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.reporting-*/_search?size=1&seq_no_primary_term=true&_source_excludes=output][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:49636}] took [157156ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:40:36,352][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/92054114942ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:40:57,911][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.4s/46484ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:41:12,117][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.4s/46484064185ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:41:30,846][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32748ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:41:14,888][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [17.6s/17646ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.23-000004], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@def90a9d]], which exceeds the warn threshold of [10s]
[2022-04-28T17:41:46,481][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32747098143ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:41:53,696][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [32747ms] which is above the warn threshold of [5000ms]
[2022-04-28T17:42:11,321][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40658ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:42:49,487][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40658840238ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:43:10,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.3s/59383ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:43:25,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.3s/59383000024ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:43:43,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33040ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:43:56,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33039318490ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:44:33,488][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48106ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:45:01,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48106777934ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:46:19,905][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/107565ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:47:13,369][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/107564640234ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:48:44,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/125473ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:49:32,510][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/125473121464ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:50:37,488][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90983ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:53:14,420][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90983054160ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:54:25,371][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/262479ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:55:21,399][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/262478463747ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:55:44,621][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86071ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:56:26,125][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86071102063ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:56:58,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73943ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:57:32,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73942997097ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:58:13,768][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/69972ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:58:20,126][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [69972ms] which is above the warn threshold of [5s]
[2022-04-28T17:58:37,333][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/69971873110ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:58:55,119][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.7s/46770ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T17:59:31,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.7s/46770327595ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T17:59:54,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.6s/56688ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:00:43,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.6s/56687553554ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:01:03,045][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70882ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:05:13,869][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [4.1m/248985ms] to compute cluster state update for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a6f4a7a]], which exceeds the warn threshold of [10s]
[2022-04-28T18:05:22,344][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70881940384ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:05:34,326][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/271769ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:05:45,152][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/271769371211ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:05:52,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18261ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:06:04,667][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18260600765ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:06:17,405][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24535ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:06:39,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24535871235ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:06:54,912][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.4s/37493ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:07:22,064][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.4s/37492559946ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:07:40,722][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45776ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:08:01,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45775704573ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:08:18,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.8s/34813ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:08:35,672][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.8s/34813302012ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:08:48,934][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33774ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:09:03,897][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33774197932ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:09:22,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34s/34072ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:09:39,189][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34s/34071624956ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:10:16,025][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.6s/52677ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:10:39,419][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.6s/52676928844ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:11:02,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.4s/46441ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:11:44,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.4s/46441558714ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:12:23,546][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80901ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:13:16,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80901191429ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:13:47,305][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][3835][78] duration [3.7m], collections [1]/[28.2m], total [3.7m]/[3.7m], memory [1.4gb]->[293mb]/[2gb], all_pools {[young] [1.1gb]->[0b]/[0b]}{[old] [283.2mb]->[283.2mb]/[2gb]}{[survivor] [10mb]->[9.8mb]/[0b]}
[2022-04-28T18:13:49,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85795ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:14:14,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85794288633ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:14:12,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [299885ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:14:44,028][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.6s/54691ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:14:59,837][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.6s/54691252880ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:15:36,268][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.3s/52315ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:16:00,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.3s/52314925688ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:16:24,157][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48165ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:16:32,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@1def2005, interval=5s}] took [48165ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:16:51,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48165406703ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:17:58,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93755ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:18:47,210][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93754447864ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:19:37,146][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@2175699d] took [190639ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:19:34,936][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/96884ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:20:00,326][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/96884695220ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:20:43,513][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68530ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:21:37,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68529314496ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:22:22,006][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/98401ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:22:57,701][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/98401677240ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:23:47,760][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85980ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:24:14,526][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85979493073ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:24:35,290][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.4s/47409ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:25:13,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.4s/47409126014ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:25:36,186][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60780ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:26:10,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60779844760ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:26:58,952][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/83125ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:27:16,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/83125212570ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:27:40,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.4s/41467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:28:11,666][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.4s/41466551884ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:28:59,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79042ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:29:23,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79041949014ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:29:45,939][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.9s/45988ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:30:21,945][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.9s/45988691012ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:30:47,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.7s/58718ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:31:00,127][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.7s/58717424434ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:31:15,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30673ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:31:26,858][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30673373503ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:31:41,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26669ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:31:55,529][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26668411690ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:32:14,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33031ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:31:53,282][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [57342ms] which is above the warn threshold of [5s]
[2022-04-28T18:32:47,394][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33031501245ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:33:06,500][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.4s/47454ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:33:23,126][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.4s/47453590850ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:33:39,841][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.6s/37636ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:33:55,947][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.6s/37636399386ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:34:10,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31s/31084ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:34:30,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31s/31083915192ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:34:46,196][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35254ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:34:58,988][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35254526005ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:35:13,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26906ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:35:28,095][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26905556662ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:35:50,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.4s/37477ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:36:05,426][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.4s/37476957431ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:36:33,900][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.6s/42612ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:37:03,166][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.6s/42612412711ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:37:24,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [42612ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:37:41,679][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68380ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:38:00,367][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68379360376ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:38:20,773][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.3s/39378ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:38:50,872][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.3s/39378397050ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:39:08,962][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48164ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:39:27,811][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48163554095ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:39:20,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@112cca35, interval=5s}] took [48163ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:39:47,547][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.3s/36321ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:40:03,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.3s/36321551664ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:40:25,852][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.4s/40471ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:40:44,613][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.4s/40470764180ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:40:56,668][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [1m/61412ms] to compute cluster state update for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@5b09f3b2]], which exceeds the warn threshold of [10s]
[2022-04-28T18:40:54,730][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.1s/29112ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:41:05,318][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.1s/29111762708ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:41:16,037][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21380ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:41:26,295][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21380499763ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:41:34,170][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18047ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:41:38,944][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@7253a090] took [18046ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:41:42,686][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18046677988ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:41:55,115][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21134ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:42:09,436][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21133879591ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:42:20,541][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25s/25048ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:42:41,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25s/25048345601ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:42:59,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.9s/38905ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:43:20,777][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.9s/38904706851ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:43:39,398][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.8s/39855ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:44:00,792][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.8s/39854961620ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:44:30,082][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.7s/50762ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:45:08,614][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.7s/50762327504ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:45:38,160][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66579ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:46:22,583][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66578681782ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:46:51,505][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74958ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:47:16,432][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74957913571ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:47:39,236][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.5s/47547ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:48:19,423][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.5s/47547377572ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:48:46,191][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67128ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:49:17,142][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67128140523ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:49:29,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44s/44000ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:49:46,245][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.9s/43999589279ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:50:03,905][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32713ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:50:18,827][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32713452061ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:50:32,435][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.7s/29701ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:50:49,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.7s/29700307178ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:51:02,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28719ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:50:59,024][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [62414ms] which is above the warn threshold of [5s]
[2022-04-28T18:51:25,245][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46fb98d4, interval=1s}] took [58419ms] which is above the warn threshold of [5000ms]
[2022-04-28T18:51:44,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28719519518ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:52:06,801][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/65334ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:52:27,802][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/65333662201ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:53:02,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53s/53045ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:54:00,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53s/53044783992ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:55:23,462][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/143481ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:55:48,109][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/143480910395ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:56:10,330][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47s/47012ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T18:57:19,313][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47s/47012719693ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T18:58:44,756][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/154119ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:00:08,769][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/154118695160ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:01:17,881][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/153217ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:02:57,124][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/153217472713ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:04:54,737][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.6m/216515ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:07:05,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.6m/216514512005ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:07:58,564][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [11.9s/11927ms] to compute cluster state update for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a6f4a7a]], which exceeds the warn threshold of [10s]
[2022-04-28T19:07:49,343][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017e1258@6ca00c35] took [216514ms] which is above the warn threshold of [5000ms]
[2022-04-28T19:10:03,881][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/308699ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:11:23,048][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [18.9s/18914ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a6f4a7a]], which exceeds the warn threshold of [10s]
[2022-04-28T19:12:45,346][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/308402288218ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:15:10,312][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/306632ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:15:13,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@77407d0d, interval=1m}] took [306489ms] which is above the warn threshold of [5000ms]
[2022-04-28T19:17:44,020][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/306489759907ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:20:34,510][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/324474ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:23:18,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/324912812097ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:26:11,294][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/336550ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:28:40,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/336550527062ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:31:30,399][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/318690ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:34:00,489][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/318526768150ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:36:56,222][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/325850ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:39:38,675][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/326013010654ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:42:18,877][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/322655ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:44:58,353][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/322654822869ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:48:04,949][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/346528ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:49:12,411][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [14.6s/14614ms] to compute cluster state update for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@5b09f3b2], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.23-000004], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@def90a9d]], which exceeds the warn threshold of [10s]
[2022-04-28T19:50:57,443][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/346220855852ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:54:01,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356886ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T19:54:17,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@1def2005, interval=5s}] took [357193ms] which is above the warn threshold of [5000ms]
[2022-04-28T19:56:54,757][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/357193231406ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T19:59:53,293][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/335251ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T20:02:31,165][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/334914391902ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T20:00:00,323][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [692108ms] which is above the warn threshold of [5s]
[2022-04-28T20:05:09,828][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/332962ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T20:07:37,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/333298575874ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T20:10:10,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/300894ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T20:11:57,278][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [11.9s/11928ms] to compute cluster state update for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a6f4a7a]], which exceeds the warn threshold of [10s]
[2022-04-28T20:12:36,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/300453709899ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T20:15:16,514][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/305725ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T20:17:56,626][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/305705704585ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T20:20:42,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/325798ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T20:21:57,489][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [13.9s/13981ms] to compute cluster state update for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@5b09f3b2]], which exceeds the warn threshold of [10s]
[2022-04-28T20:23:05,819][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/326123545994ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T20:25:53,071][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/310009ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T20:28:32,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/310142586839ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T20:34:52,643][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-28T20:34:52,659][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-28T20:34:52,660][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-28T20:34:59,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-28T20:34:59,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-28T20:34:59,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-28T20:34:59,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-28T20:34:59,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-28T20:34:59,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-28T20:34:59,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-28T20:34:59,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-28T20:34:59,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-28T20:34:59,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-28T20:34:59,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-28T20:34:59,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-28T20:34:59,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-28T20:34:59,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-28T20:34:59,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-28T20:34:59,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-28T20:34:59,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-28T20:34:59,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-28T20:34:59,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-28T20:34:59,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-28T20:34:59,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-28T20:34:59,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-28T20:34:59,236][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-28T20:34:59,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-28T20:34:59,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-28T20:34:59,238][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-28T20:34:59,238][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-28T20:34:59,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-28T20:34:59,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-28T20:34:59,240][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-28T20:34:59,240][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-28T20:34:59,241][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-28T20:34:59,241][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-28T20:34:59,241][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-28T20:34:59,243][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-28T20:34:59,244][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-28T20:34:59,244][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-28T20:34:59,245][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-28T20:34:59,245][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-28T20:34:59,245][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-28T20:34:59,246][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-28T20:34:59,247][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-28T20:34:59,247][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-28T20:34:59,247][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-28T20:34:59,248][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-28T20:34:59,248][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-28T20:34:59,249][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-28T20:34:59,249][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-28T20:34:59,249][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-28T20:34:59,250][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-28T20:34:59,250][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-28T20:34:59,250][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-28T20:34:59,251][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-28T20:34:59,251][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-28T20:34:59,251][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-28T20:34:59,252][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-28T20:34:59,252][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-28T20:34:59,252][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-28T20:34:59,256][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-28T20:34:59,371][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [101.5gb], net total_space [125.8gb], types [ext4]
[2022-04-28T20:34:59,372][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-28T20:35:00,341][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-28T20:35:15,577][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-28T20:35:15,589][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-28T20:35:15,590][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-28T20:35:15,591][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-28T20:35:15,591][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-28T20:35:15,592][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-28T20:35:15,593][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-28T20:35:15,593][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-28T20:35:15,594][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-28T20:35:15,594][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-28T20:35:15,595][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-28T20:35:15,596][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-28T20:35:15,597][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-28T20:35:15,599][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-28T20:35:15,600][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-28T20:35:17,439][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-28T20:35:17,571][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-28T20:35:18,827][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-28T20:35:20,249][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-28T20:35:20,251][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-28T20:35:20,312][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-28T20:35:20,314][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-28T20:35:20,792][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-28T20:35:25,476][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-28T20:35:25,650][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{_ZdCGVtwT3uCbw_MLAR1Dw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 320, version: 14815, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{_ZdCGVtwT3uCbw_MLAR1Dw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-28T20:35:25,944][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{_ZdCGVtwT3uCbw_MLAR1Dw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 320, version: 14815, reason: Publication{term=320, version=14815}
[2022-04-28T20:35:26,102][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-28T20:35:26,103][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-28T20:35:28,874][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-28T20:35:28,888][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [67] indices into cluster_state
[2022-04-28T20:35:30,304][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-28T20:35:30,306][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-28T20:35:31,523][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-28T20:35:31,868][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-28T20:35:32,697][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-28T20:35:32,726][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-28T20:35:32,727][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-28T20:35:33,041][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-28T20:35:33,678][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-28T20:35:34,329][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-28T20:35:37,828][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-28T20:35:46,490][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0], [.ds-ilm-history-5-2022.03.12-000001][0]]]).
[2022-04-28T20:36:17,658][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T20:36:23,524][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T20:36:23,776][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.28/7864FDZkTruSh8zJU3zSVA] update_mapping [_doc]
[2022-04-28T21:01:24,523][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1b8f85da, interval=1s}] took [5227ms] which is above the warn threshold of [5000ms]
[2022-04-28T21:09:37,443][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_task_manager/_update_by_query?ignore_unavailable=true&refresh=true&conflicts=proceed][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52042}] took [25308ms] which is above the warn threshold of [5000ms]
[2022-04-28T21:09:37,443][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:50016}] took [16124ms] which is above the warn threshold of [5000ms]
[2022-04-28T21:09:38,972][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:50018}] took [16124ms] which is above the warn threshold of [5000ms]
[2022-04-28T21:39:22,095][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-28T21:39:22,161][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-28T21:39:22,162][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-28T21:53:23,461][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-28T21:53:23,470][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-28T21:53:23,471][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-28T21:53:23,471][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-28T21:53:23,472][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-28T21:53:23,472][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-28T21:53:23,472][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-28T21:53:23,473][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-28T21:53:23,473][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-28T21:53:23,474][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-28T21:53:23,474][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-28T21:53:23,475][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-28T21:53:23,475][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-28T21:53:23,476][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-28T21:53:23,477][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-28T21:53:23,478][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-28T21:53:23,478][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-28T21:53:23,478][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-28T21:53:23,479][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-28T21:53:23,479][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-28T21:53:23,480][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-28T21:53:23,480][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-28T21:53:23,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-28T21:53:23,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-28T21:53:23,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-28T21:53:23,482][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-28T21:53:23,482][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-28T21:53:23,483][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-28T21:53:23,483][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-28T21:53:23,483][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-28T21:53:23,484][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-28T21:53:23,484][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-28T21:53:23,484][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-28T21:53:23,485][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-28T21:53:23,485][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-28T21:53:23,485][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-28T21:53:23,486][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-28T21:53:23,486][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-28T21:53:23,486][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-28T21:53:23,487][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-28T21:53:23,487][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-28T21:53:23,488][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-28T21:53:23,488][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-28T21:53:23,488][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-28T21:53:23,489][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-28T21:53:23,489][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-28T21:53:23,489][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-28T21:53:23,490][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-28T21:53:23,490][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-28T21:53:23,490][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-28T21:53:23,491][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-28T21:53:23,491][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-28T21:53:23,491][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-28T21:53:23,492][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-28T21:53:23,492][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-28T21:53:23,492][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-28T21:53:23,493][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-28T21:53:23,493][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-28T21:53:23,494][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-28T21:53:23,603][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [101.4gb], net total_space [125.8gb], types [ext4]
[2022-04-28T21:53:23,604][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-28T21:53:24,251][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-28T22:01:03,757][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3s/5322ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T22:27:10,071][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5624215585ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T22:34:31,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.4m/2307809ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T22:39:13,155][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.4m/2307496798879ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T22:43:34,078][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.8m/531203ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T22:47:43,699][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.8m/531514961592ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T22:51:19,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8m/472299ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T22:40:35,276][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@70093951, interval=5s}] took [2307496ms] which is above the warn threshold of [5000ms]
[2022-04-28T22:55:19,264][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8m/472158776713ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T22:58:16,845][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7m/425247ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T22:58:35,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f4b0a23, interval=30s}] took [424843ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:01:55,034][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7m/424843367634ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:08:25,969][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-28T23:08:26,024][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-28T23:08:26,026][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-28T23:08:30,988][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-28T23:08:30,993][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-28T23:08:30,995][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-28T23:08:30,997][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-28T23:08:30,997][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-28T23:08:30,998][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-28T23:08:30,999][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-28T23:08:30,999][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-28T23:08:31,000][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-28T23:08:31,000][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-28T23:08:31,000][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-28T23:08:31,001][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-28T23:08:31,001][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-28T23:08:31,002][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-28T23:08:31,002][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-28T23:08:31,003][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-28T23:08:31,003][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-28T23:08:31,003][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-28T23:08:31,004][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-28T23:08:31,004][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-28T23:08:31,005][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-28T23:08:31,005][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-28T23:08:31,006][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-28T23:08:31,006][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-28T23:08:31,007][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-28T23:08:31,007][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-28T23:08:31,008][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-28T23:08:31,008][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-28T23:08:31,008][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-28T23:08:31,009][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-28T23:08:31,010][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-28T23:08:31,010][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-28T23:08:31,011][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-28T23:08:31,011][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-28T23:08:31,012][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-28T23:08:31,012][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-28T23:08:31,013][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-28T23:08:31,013][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-28T23:08:31,013][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-28T23:08:31,014][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-28T23:08:31,014][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-28T23:08:31,014][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-28T23:08:31,016][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-28T23:08:31,017][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-28T23:08:31,018][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-28T23:08:31,018][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-28T23:08:31,018][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-28T23:08:31,019][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-28T23:08:31,019][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-28T23:08:31,020][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-28T23:08:31,020][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-28T23:08:31,020][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-28T23:08:31,021][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-28T23:08:31,021][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-28T23:08:31,021][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-28T23:08:31,022][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-28T23:08:31,023][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-28T23:08:31,023][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-28T23:08:31,025][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-28T23:08:31,153][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [101.4gb], net total_space [125.8gb], types [ext4]
[2022-04-28T23:08:31,154][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-28T23:08:32,050][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-28T23:10:01,134][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [5091ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:09:40,059][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5091ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:14:53,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5091138563ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:16:12,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4m/388945ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:17:23,387][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4m/388944955052ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:18:45,099][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/157281ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:20:08,690][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/157280326172ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:22:16,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/210415ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:22:17,132][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@48065758, interval=30s}] took [210415ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:24:07,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/210415458954ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:00,128][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/171531ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:11,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/171531357439ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:21,778][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24048ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:26,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24047623392ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:34,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.2s/10295ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:44,367][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.2s/10295265866ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:49,935][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17637ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:25:55,961][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17636880990ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:26:01,746][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12090ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:26:01,746][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [12090ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:26:08,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12090199762ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:26:30,889][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25317ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:26:58,345][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25316358707ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:27:14,155][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.1s/45155ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:27:26,721][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.1s/45155681062ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:27:40,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26487ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:27:55,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26486619700ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:28:12,170][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31206ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:28:18,495][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@48065758, interval=30s}] took [31205ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:28:29,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31205661534ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:29:02,271][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48s/48033ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:29:05,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@78bec81b, interval=1m}] took [48033ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:29:24,290][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48s/48033767446ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:29:50,992][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.6s/48603ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:29:56,177][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [48602ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:30:20,811][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.6s/48602534764ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:30:47,319][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.4s/57451ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:30:51,863][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@78bec81b, interval=1m}] took [57450ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:31:11,193][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.4s/57450765528ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:31:39,349][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51261ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:32:04,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51261394171ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:32:26,788][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@48065758, interval=30s}] took [50156ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:32:26,695][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.1s/50156ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:32:51,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.1s/50156285124ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:33:14,404][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.1s/45126ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:33:55,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.1s/45125945519ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:34:35,462][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/81524ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:35:02,708][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/81523256058ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:35:22,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.4s/47471ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:35:24,680][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [47471ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:35:40,413][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.4s/47471727150ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:36:00,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.7s/38784ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:36:05,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@78bec81b, interval=1m}] took [38783ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:36:15,130][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.7s/38783609491ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:36:35,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [32168ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:36:32,960][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.1s/32169ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:36:59,334][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.1s/32168588693ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:37:27,436][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.5s/54518ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:37:29,222][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@48065758, interval=30s}] took [54518ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:37:44,252][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.5s/54518708546ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:38:11,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.2s/43249ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:38:16,729][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [43248ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:38:53,383][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.2s/43248751157ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:39:55,129][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [95550ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:39:54,470][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95550ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:40:37,411][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95550173448ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:41:55,421][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127226ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:42:26,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127225713134ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:42:58,792][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60934ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:43:37,532][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60934170833ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:44:26,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90230ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:44:59,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90230363498ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:45:27,280][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.1s/58107ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:45:59,674][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.1s/58107043551ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:46:37,116][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74017ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:46:40,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [74016ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:47:13,307][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74016639982ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:47:48,576][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70762ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:47:50,882][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@48065758, interval=30s}] took [70761ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:48:27,670][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70761667204ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:49:05,495][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/75453ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:49:13,593][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@78bec81b, interval=1m}] took [75453ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:49:33,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/75453011920ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:50:02,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.7s/58713ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:50:23,539][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.7s/58712895113ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:50:36,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36s/36028ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:50:49,752][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36s/36028133272ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:51:13,033][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.9s/33955ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:51:30,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.9s/33955545185ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:51:46,536][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36s/36081ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:51:48,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [36080ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:51:56,668][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36s/36080784242ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:52:04,655][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18622ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:52:06,799][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@48065758, interval=30s}] took [18622ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:52:14,067][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18622336494ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:53:32,337][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76019ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:56:17,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/75596492470ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:57:26,307][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/238860ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-28T23:58:31,887][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@a188b38, interval=5s}] took [239282ms] which is above the warn threshold of [5000ms]
[2022-04-28T23:58:32,598][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/239282279945ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-28T23:59:58,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/152536ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:38:26,234][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-29T03:38:26,254][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-29T03:38:26,256][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-29T03:38:34,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-29T03:38:34,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-29T03:38:34,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-29T03:38:34,240][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-29T03:38:34,241][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-29T03:38:34,241][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-29T03:38:34,242][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-29T03:38:34,242][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-29T03:38:34,243][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-29T03:38:34,243][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-29T03:38:34,244][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-29T03:38:34,244][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-29T03:38:34,245][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-29T03:38:34,246][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-29T03:38:34,246][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-29T03:38:34,247][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-29T03:38:34,248][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-29T03:38:34,248][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-29T03:38:34,249][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-29T03:38:34,249][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-29T03:38:34,250][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-29T03:38:34,250][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-29T03:38:34,251][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-29T03:38:34,252][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-29T03:38:34,252][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-29T03:38:34,253][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-29T03:38:34,253][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-29T03:38:34,254][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-29T03:38:34,254][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-29T03:38:34,255][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-29T03:38:34,255][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-29T03:38:34,256][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-29T03:38:34,256][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-29T03:38:34,257][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-29T03:38:34,258][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-29T03:38:34,258][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-29T03:38:34,259][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-29T03:38:34,259][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-29T03:38:34,260][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-29T03:38:34,260][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-29T03:38:34,261][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-29T03:38:34,262][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-29T03:38:34,262][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-29T03:38:34,263][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-29T03:38:34,263][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-29T03:38:34,263][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-29T03:38:34,264][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-29T03:38:34,264][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-29T03:38:34,265][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-29T03:38:34,265][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-29T03:38:34,266][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-29T03:38:34,266][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-29T03:38:34,267][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-29T03:38:34,268][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-29T03:38:34,268][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-29T03:38:34,269][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-29T03:38:34,269][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-29T03:38:34,270][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-29T03:38:34,271][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-29T03:38:34,391][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [102.8gb], net total_space [125.8gb], types [ext4]
[2022-04-29T03:38:34,393][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-29T03:38:35,334][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-29T03:38:51,937][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-29T03:38:51,941][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-29T03:38:51,942][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-29T03:38:51,944][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-29T03:38:51,944][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-29T03:38:51,945][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-29T03:38:51,946][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-29T03:38:51,947][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-29T03:38:51,948][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-29T03:38:51,948][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-29T03:38:51,949][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-29T03:38:51,950][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-29T03:38:51,951][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-29T03:38:51,952][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-29T03:38:51,953][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-29T03:38:53,674][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-29T03:38:53,939][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-29T03:38:55,237][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-29T03:38:56,565][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-29T03:38:56,569][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-29T03:38:56,686][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-29T03:38:56,688][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-29T03:38:57,048][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-29T03:39:02,528][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-29T03:39:02,806][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{uDlsp7fdSEejs2mxoHPTIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 321, version: 14886, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{uDlsp7fdSEejs2mxoHPTIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-29T03:39:03,293][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{uDlsp7fdSEejs2mxoHPTIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 321, version: 14886, reason: Publication{term=321, version=14886}
[2022-04-29T03:39:03,469][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-29T03:39:03,470][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-29T03:39:04,875][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-29T03:39:04,882][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [67] indices into cluster_state
[2022-04-29T03:39:05,859][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-29T03:39:05,860][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-29T03:39:07,342][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-ASN.mmdb]
[2022-04-29T03:39:08,179][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-29T03:39:08,191][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-29T03:39:08,194][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-29T03:39:09,580][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-29T03:39:10,028][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-29T03:39:10,697][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:11,907][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][15] overhead, spent [252ms] collecting in the last [1s]
[2022-04-29T03:39:11,960][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:12,014][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:12,064][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:12,838][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:12,861][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:12,933][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:12,970][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-29T03:39:14,380][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-29T03:39:14,452][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-ASN.mmdb]
[2022-04-29T03:39:14,463][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-City.mmdb]
[2022-04-29T03:39:14,921][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-29T03:39:14,923][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-29T03:39:16,310][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-29T03:39:27,124][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-29T03:39:27,201][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-City.mmdb]
[2022-04-29T03:39:27,203][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-Country.mmdb]
[2022-04-29T03:39:28,470][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-29T03:39:28,530][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-Country.mmdb]
[2022-04-29T03:39:28,827][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-29T03:39:28,838][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-29T03:39:31,838][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-29T03:39:31,857][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-29T03:39:36,603][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.28][0]]]).
[2022-04-29T03:39:58,705][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-2022.04.29] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-29T03:39:58,837][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-2022.04.29][0]]]).
[2022-04-29T03:39:59,005][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,397][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,464][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,574][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,675][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,750][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,756][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,890][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,894][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:39:59,979][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:00,120][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:00,945][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:01,192][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:01,364][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:03,883][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:04,050][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:04,310][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:04,434][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:04,469][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:04,651][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:04,974][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:05,561][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:05,698][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:05,815][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:05,834][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:05,991][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:06,384][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:06,578][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:06,698][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:07,133][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:08,163][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:08,304][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:08,429][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:08,641][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:08,750][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:08,903][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:09,108][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:09,251][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:09,517][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:09,942][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:10,196][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:10,454][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:10,651][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:10,776][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:11,998][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:43,071][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:44,041][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:40:50,032][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:41:03,080][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.29/ceWSD_OsSzOrbV53oGgasQ] update_mapping [_doc]
[2022-04-29T03:42:21,822][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46dd2892, interval=1s}] took [8472ms] which is above the warn threshold of [5000ms]
[2022-04-29T03:46:48,186][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@46dd2892, interval=1s}] took [26739ms] which is above the warn threshold of [5000ms]
[2022-04-29T03:46:50,424][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [26417ms] which is above the warn threshold of [5s]
[2022-04-29T03:46:58,293][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2s/8271ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:48:17,817][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1s/8133099010ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T03:48:25,917][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.9m/296152ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:48:34,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.9m/296289531552ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T03:48:43,997][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17997ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:48:59,585][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17996974942ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T03:49:25,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40739ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:49:45,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40738937726ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T03:50:10,383][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.6s/45650ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:50:40,171][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.6s/45650473853ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T03:51:53,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95815ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:52:50,393][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95265229363ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T03:55:18,434][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/211181ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T03:57:48,047][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/211581405341ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T04:04:25,512][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.1m/546836ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T04:06:24,341][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@135a03c4, interval=5s}] took [1254165ms] which is above the warn threshold of [5000ms]
[2022-04-29T04:07:26,483][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.1m/546642802939ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T04:02:07,549][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:52242}] took [95265ms] which is above the warn threshold of [5000ms]
[2022-04-29T04:09:47,137][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/322162ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T04:12:02,930][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/322083777895ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T04:14:35,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287253ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T04:21:55,975][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287370631210ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T04:23:59,582][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.4m/564355ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T04:31:18,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.4m/564299774132ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T04:38:40,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6m/880925ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-29T04:41:53,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6m/880652616292ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-29T04:44:38,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/359518ms] on absolute clock which is above the warn threshold of [5000ms]
