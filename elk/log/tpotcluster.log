[2022-04-11T15:52:44,135][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-11T15:52:44,172][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-11T15:52:44,173][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-11T15:52:50,304][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-11T15:52:50,305][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-11T15:52:50,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-11T15:52:50,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-11T15:52:50,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-11T15:52:50,307][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-11T15:52:50,307][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-11T15:52:50,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-11T15:52:50,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-11T15:52:50,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-11T15:52:50,309][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-11T15:52:50,309][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-11T15:52:50,310][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-11T15:52:50,310][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-11T15:52:50,311][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-11T15:52:50,311][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-11T15:52:50,311][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-11T15:52:50,312][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-11T15:52:50,312][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-11T15:52:50,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-11T15:52:50,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-11T15:52:50,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-11T15:52:50,314][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-11T15:52:50,314][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-11T15:52:50,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-11T15:52:50,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-11T15:52:50,316][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-11T15:52:50,316][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-11T15:52:50,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-11T15:52:50,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-11T15:52:50,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-11T15:52:50,318][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-11T15:52:50,318][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-11T15:52:50,319][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-11T15:52:50,319][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-11T15:52:50,320][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-11T15:52:50,320][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-11T15:52:50,320][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-11T15:52:50,321][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-11T15:52:50,321][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-11T15:52:50,322][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-11T15:52:50,322][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-11T15:52:50,323][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-11T15:52:50,323][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-11T15:52:50,324][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-11T15:52:50,324][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-11T15:52:50,324][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-11T15:52:50,325][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-11T15:52:50,325][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-11T15:52:50,326][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-11T15:52:50,326][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-11T15:52:50,327][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-11T15:52:50,327][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-11T15:52:50,327][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-11T15:52:50,328][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-11T15:52:50,328][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-11T15:52:50,329][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-11T15:52:50,329][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-11T15:52:50,330][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-11T15:52:50,397][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.7gb], net total_space [125.8gb], types [ext4]
[2022-04-11T15:52:50,398][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-11T15:52:50,648][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-11T15:53:02,147][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-11T15:53:02,151][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-11T15:53:03,318][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-11T15:53:03,448][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-11T15:53:04,204][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-11T15:53:04,920][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-11T15:53:04,921][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-11T15:53:04,954][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-11T15:53:04,956][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-11T15:53:05,181][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-11T15:53:07,668][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-11T15:53:07,776][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kZcfg0TbRnKG2C5trZnzkA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 229, version: 8817, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kZcfg0TbRnKG2C5trZnzkA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-11T15:53:07,962][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kZcfg0TbRnKG2C5trZnzkA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 229, version: 8817, reason: Publication{term=229, version=8817}
[2022-04-11T15:53:08,091][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-11T15:53:08,092][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-11T15:53:08,886][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-11T15:53:08,892][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [45] indices into cluster_state
[2022-04-11T15:53:09,593][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-11T15:53:09,594][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-11T15:53:10,238][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-11T15:53:10,389][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-11T15:53:10,762][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-11T15:53:10,829][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-11T15:53:10,835][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-11T15:53:10,839][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-11T15:53:11,294][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T15:53:11,427][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T15:53:14,200][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-11T15:53:23,440][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.10][0]]]).
[2022-04-11T15:53:29,522][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-04-11T15:53:29,738][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-04-11T15:54:13,342][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 640 finished with response BulkByScrollResponse[took=357.7ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-11T15:54:15,013][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 666 finished with response BulkByScrollResponse[took=1.6s,timed_out=false,sliceId=null,updated=1016,created=0,deleted=0,batches=2,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-11T15:54:24,222][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-04-11T15:55:05,723][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-2022.04.11] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-11T15:55:05,863][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-2022.04.11][0]]]).
[2022-04-11T15:55:06,032][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,148][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,180][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,199][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,346][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,353][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,442][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,614][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,633][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,793][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:06,890][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:07,042][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:08,355][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:08,423][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:08,432][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:08,440][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:08,567][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:10,361][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:14,384][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:14,474][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:55:50,421][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:07,250][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:09,477][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:09,611][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:11,483][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:14,464][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:20,507][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:20,579][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:56:34,486][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:57:22,573][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:57:31,658][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:57:32,371][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:57:46,685][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T15:59:08,694][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:01:54,862][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:03:08,750][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000001] from [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}] to [{"phase":"hot","action":"rollover","name":"attempt-rollover"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:08,805][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.03.12-000001] from [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}] to [{"phase":"hot","action":"rollover","name":"attempt-rollover"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:08,863][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [.kibana-event-log-7.16.2-000002] creating index, cause [rollover_index], templates [.kibana-event-log-7.16.2-template], shards [1]/[1]
[2022-04-11T16:03:08,867][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] updating number_of_replicas to [0] for indices [.kibana-event-log-7.16.2-000002]
[2022-04-11T16:03:08,974][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [.ds-ilm-history-5-2022.04.11-000002] creating index, cause [rollover_data_stream], templates [ilm-history], shards [1]/[0]
[2022-04-11T16:03:09,099][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.ds-ilm-history-5-2022.04.11-000002][0]]]).
[2022-04-11T16:03:09,134][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000002] from [null] to [{"phase":"new","action":"complete","name":"complete"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:09,136][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000001] from [{"phase":"hot","action":"rollover","name":"attempt-rollover"}] to [{"phase":"hot","action":"rollover","name":"wait-for-active-shards"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:09,137][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.04.11-000002] from [null] to [{"phase":"new","action":"complete","name":"complete"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,138][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.03.12-000001] from [{"phase":"hot","action":"rollover","name":"attempt-rollover"}] to [{"phase":"hot","action":"rollover","name":"wait-for-active-shards"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,189][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.04.11-000002] from [{"phase":"new","action":"complete","name":"complete"}] to [{"phase":"hot","action":"unfollow","name":"branch-check-unfollow-prerequisites"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,191][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000002] from [{"phase":"new","action":"complete","name":"complete"}] to [{"phase":"hot","action":"unfollow","name":"branch-check-unfollow-prerequisites"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:09,195][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.03.12-000001] from [{"phase":"hot","action":"rollover","name":"wait-for-active-shards"}] to [{"phase":"hot","action":"rollover","name":"update-rollover-lifecycle-date"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,197][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.03.12-000001] from [{"phase":"hot","action":"rollover","name":"update-rollover-lifecycle-date"}] to [{"phase":"hot","action":"rollover","name":"set-indexing-complete"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,198][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000001] from [{"phase":"hot","action":"rollover","name":"wait-for-active-shards"}] to [{"phase":"hot","action":"rollover","name":"update-rollover-lifecycle-date"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:09,200][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000001] from [{"phase":"hot","action":"rollover","name":"update-rollover-lifecycle-date"}] to [{"phase":"hot","action":"rollover","name":"set-indexing-complete"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:09,386][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.04.11-000002] from [{"phase":"hot","action":"unfollow","name":"branch-check-unfollow-prerequisites"}] to [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,387][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000002] from [{"phase":"hot","action":"unfollow","name":"branch-check-unfollow-prerequisites"}] to [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}] in policy [kibana-event-log-policy]
[2022-04-11T16:03:09,388][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.ds-ilm-history-5-2022.03.12-000001] from [{"phase":"hot","action":"rollover","name":"set-indexing-complete"}] to [{"phase":"hot","action":"complete","name":"complete"}] in policy [ilm-history-ilm-policy]
[2022-04-11T16:03:09,389][INFO ][o.e.x.i.IndexLifecycleTransition] [tpotcluster-node-01] moving index [.kibana-event-log-7.16.2-000001] from [{"phase":"hot","action":"rollover","name":"set-indexing-complete"}] to [{"phase":"hot","action":"complete","name":"complete"}] in policy [kibana-event-log-policy]
[2022-04-11T16:04:29,673][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:04:29,999][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:04:30,085][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:08:34,780][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:08:35,054][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:10:07,043][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:10:07,115][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:10:08,045][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:12:23,402][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:18:35,730][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:18:35,815][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:21:19,330][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:31:50,554][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:36:57,756][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:36:58,560][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:36:58,626][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:37:02,405][INFO ][o.e.c.m.MetadataDeleteIndexService] [tpotcluster-node-01] [logstash-1970.01.01/0jugN3uXT1aOat1QmEPt3w] deleting index
[2022-04-11T16:39:49,877][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:40:12,730][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:40:12,846][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:40:14,891][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:40:37,755][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:52:37,693][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T16:53:09,741][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@840d4cb, interval=1s}] took [25202ms] which is above the warn threshold of [5000ms]
[2022-04-11T16:53:50,458][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@840d4cb, interval=1s}] took [13068ms] which is above the warn threshold of [5000ms]
[2022-04-11T16:54:23,923][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@50261f32, interval=5s}] took [8366ms] which is above the warn threshold of [5000ms]
[2022-04-11T16:55:08,361][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@840d4cb, interval=1s}] took [6214ms] which is above the warn threshold of [5000ms]
[2022-04-11T16:56:08,952][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@840d4cb, interval=1s}] took [27524ms] which is above the warn threshold of [5000ms]
[2022-04-11T16:58:51,468][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5064ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:02:47,148][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.9m/295274ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:04:07,262][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.9m/295520430430ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:04:17,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/215723ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:04:50,571][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/215722607389ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:06:13,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91079ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:08:04,194][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90505192583ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:08:20,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/151780ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:08:43,490][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/152353407516ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:10:06,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/103754ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:11:08,571][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/103468523952ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:13:01,661][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/173718ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:15:10,028][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/173572821534ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:16:43,814][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@840d4cb, interval=1s}] took [173572ms] which is above the warn threshold of [5000ms]
[2022-04-11T17:16:44,298][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/225235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:14:43,696][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:57516}] took [152354ms] which is above the warn threshold of [5000ms]
[2022-04-11T17:18:55,333][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/225665885443ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:21:08,343][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/261349ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:21:56,927][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/260978937718ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:23:43,644][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/155818ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:25:45,857][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/156188086658ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:26:16,861][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@7d4f44c5, interval=5s}] took [417167ms] which is above the warn threshold of [5000ms]
[2022-04-11T17:27:16,639][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/212458ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:29:18,766][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/212151066267ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:31:20,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/242693ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:33:16,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/242857030006ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:36:08,323][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287585ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:38:22,257][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287728436838ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:36:16,844][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [242857ms] which is above the warn threshold of [5s]
[2022-04-11T17:40:35,253][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/268588ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:39:46,247][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [14s/14058ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@4f5159d4], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.09-000003], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@e3ea0679]], which exceeds the warn threshold of [10s]
[2022-04-11T17:42:54,255][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/268587441654ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:45:48,904][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/313297ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:45:19,897][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [13.4s/13423ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@feb6b09c], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@9d860bdd]], which exceeds the warn threshold of [10s]
[2022-04-11T17:47:56,556][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/313137089808ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:49:35,621][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/226870ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:52:22,122][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/226909676362ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:55:07,570][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/314280ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T17:57:29,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/314399869232ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T17:59:53,327][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/303472ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:02:25,532][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/303137068077ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:04:44,071][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.8m/290909ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:05:20,007][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [9.6m/581724ms] which is longer than the warn threshold of [300000ms]; there are currently [3] pending tasks, the oldest of which has age [12.1m/728430ms]
[2022-04-11T18:06:36,328][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.8m/290760863056ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:08:01,517][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [28.6m/1716932ms] which is longer than the warn threshold of [300000ms]; there are currently [2] pending tasks, the oldest of which has age [13.9m/834543ms]
[2022-04-11T18:09:17,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273057ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:11:27,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273197806781ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:11:20,264][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [15s/15085ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@4f5159d4], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.09-000003], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@e3ea0679]], which exceeds the warn threshold of [10s]
[2022-04-11T18:13:14,535][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/236759ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:13:34,484][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [37.1m/2226907ms] which is longer than the warn threshold of [300000ms]; there are currently [2] pending tasks, the oldest of which has age [10.7m/643608ms]
[2022-04-11T18:15:51,679][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/236777489874ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:18:23,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/309021ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:21:08,385][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/308549713001ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:23:47,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/324300ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:26:23,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/325095965728ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:28:11,285][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/264073ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:30:31,224][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/263752169920ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T18:33:16,307][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/304071ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T18:35:49,217][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/304232246380ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:09:14,679][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-11T19:09:14,699][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-11T19:09:14,702][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-11T19:09:21,065][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-11T19:09:21,068][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-11T19:09:21,069][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-11T19:09:21,069][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-11T19:09:21,069][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-11T19:09:21,070][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-11T19:09:21,070][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-11T19:09:21,070][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-11T19:09:21,071][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-11T19:09:21,071][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-11T19:09:21,072][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-11T19:09:21,072][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-11T19:09:21,072][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-11T19:09:21,075][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-11T19:09:21,076][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-11T19:09:21,076][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-11T19:09:21,077][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-11T19:09:21,077][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-11T19:09:21,077][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-11T19:09:21,078][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-11T19:09:21,078][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-11T19:09:21,079][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-11T19:09:21,079][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-11T19:09:21,080][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-11T19:09:21,080][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-11T19:09:21,080][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-11T19:09:21,081][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-11T19:09:21,081][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-11T19:09:21,082][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-11T19:09:21,082][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-11T19:09:21,082][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-11T19:09:21,083][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-11T19:09:21,083][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-11T19:09:21,084][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-11T19:09:21,084][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-11T19:09:21,084][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-11T19:09:21,085][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-11T19:09:21,085][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-11T19:09:21,086][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-11T19:09:21,086][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-11T19:09:21,086][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-11T19:09:21,087][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-11T19:09:21,087][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-11T19:09:21,087][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-11T19:09:21,088][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-11T19:09:21,088][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-11T19:09:21,088][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-11T19:09:21,089][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-11T19:09:21,089][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-11T19:09:21,090][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-11T19:09:21,090][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-11T19:09:21,090][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-11T19:09:21,091][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-11T19:09:21,091][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-11T19:09:21,091][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-11T19:09:21,092][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-11T19:09:21,092][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-11T19:09:21,092][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-11T19:09:21,093][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-11T19:09:21,194][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.5gb], net total_space [125.8gb], types [ext4]
[2022-04-11T19:09:21,196][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-11T19:09:21,739][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-11T19:09:31,999][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-11T19:09:32,010][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-11T19:09:32,012][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-11T19:09:32,015][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-11T19:09:32,016][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T19:09:32,017][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-11T19:09:32,020][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-11T19:09:32,021][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T19:09:32,023][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-11T19:09:32,024][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-11T19:09:32,025][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-11T19:09:32,026][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T19:09:32,027][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T19:09:32,028][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T19:09:32,029][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-11T19:09:33,111][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-11T19:09:33,285][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-11T19:09:34,056][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-11T19:09:34,858][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-11T19:09:34,859][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-11T19:09:34,958][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-11T19:09:34,963][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-11T19:09:35,232][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-11T19:09:37,673][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-11T19:09:37,846][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 230, version: 8948, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-11T19:09:38,028][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 230, version: 8948, reason: Publication{term=230, version=8948}
[2022-04-11T19:09:38,143][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-11T19:09:38,146][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-11T19:09:38,895][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-11T19:09:38,907][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [47] indices into cluster_state
[2022-04-11T19:09:41,593][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-11T19:09:41,622][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-11T19:13:39,019][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [2.9m/179178ms] to notify listeners on successful publication of cluster state (version: 8952, uuid: OgWZStazRUq684aukeT3lQ) for [shard-started StartedShardEntry{shardId [[.tasks][0]], allocationId [mXnj0VgeR4q7un5j66voxA], primary term [172], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.tasks][0]], allocationId [mXnj0VgeR4q7un5j66voxA], primary term [172], message [after existing store recovery; bootstrap_history_uuid=false]}]], which exceeds the warn threshold of [10s]
[2022-04-11T19:12:03,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9041ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:15:24,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2s/9273075080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:15:46,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/324592ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:14:52,377][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@466b153f, interval=5s}] took [13961ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:16:42,863][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/324591934119ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:16:51,411][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66121ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:17:01,194][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66120545706ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:17:53,537][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63158ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:18:02,422][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63157895588ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:18:12,570][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18697ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:18:20,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18697633436ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:18:24,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [81855ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:18:34,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.7s/20706ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:18:45,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.7s/20705724732ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:18:54,981][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21594ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:19:05,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21594229627ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:19:10,492][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14755ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:19:07,819][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [52.3s/52300ms] to compute cluster state update for [shard-started StartedShardEntry{shardId [[.kibana_7.17.0_001][0]], allocationId [0sc8FCzORWi-9ycmZlz_dw], primary term [114], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.kibana_7.17.0_001][0]], allocationId [0sc8FCzORWi-9ycmZlz_dw], primary term [114], message [after existing store recovery; bootstrap_history_uuid=false]}], shard-started StartedShardEntry{shardId [[.kibana_task_manager_7.16.2_001][0]], allocationId [8F4wVIqbTByoiw_lk78s7g], primary term [172], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.kibana_task_manager_7.16.2_001][0]], allocationId [8F4wVIqbTByoiw_lk78s7g], primary term [172], message [after existing store recovery; bootstrap_history_uuid=false]}], shard-started StartedShardEntry{shardId [[.kibana_task_manager_7.16.2_001][0]], allocationId [8F4wVIqbTByoiw_lk78s7g], primary term [172], message [master {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]}[StartedShardEntry{shardId [[.kibana_task_manager_7.16.2_001][0]], allocationId [8F4wVIqbTByoiw_lk78s7g], primary term [172], message [master {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]}], shard-started StartedShardEntry{shardId [[.kibana_7.17.0_001][0]], allocationId [0sc8FCzORWi-9ycmZlz_dw], primary term [114], message [master {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]}[StartedShardEntry{shardId [[.kibana_7.17.0_001][0]], allocationId [0sc8FCzORWi-9ycmZlz_dw], primary term [114], message [master {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} marked shard as initializing, but shard state is [POST_RECOVERY], mark shard as started]}]], which exceeds the warn threshold of [10s]
[2022-04-11T19:19:58,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14754602111ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:19:58,699][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.9s/49982ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:19:59,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.9s/49982002165ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:19:59,710][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59676}] took [65646ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:20:00,474][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5110/0x00000008017e0960@acb6090] took [88040ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:20:01,131][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [9.6m/581760ms] which is longer than the warn threshold of [300000ms]; there are currently [4] pending tasks, the oldest of which has age [10.3m/619186ms]
[2022-04-11T19:20:07,996][ERROR][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] exception during geoip databases update
javax.net.ssl.SSLHandshakeException: Remote host terminated the handshake
	at sun.security.ssl.SSLSocketImpl.handleEOF(SSLSocketImpl.java:1715) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1514) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1416) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:451) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:422) ~[?:?]
	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:574) ~[?:?]
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:183) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1653) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1577) ~[?:?]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) ~[?:?]
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:308) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.lambda$get$0(HttpClient.java:55) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at java.security.AccessController.doPrivileged(AccessController.java:554) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.doPrivileged(HttpClient.java:97) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.get(HttpClient.java:49) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.getBytes(HttpClient.java:40) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.fetchDatabasesOverview(GeoIpDownloader.java:135) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.updateDatabases(GeoIpDownloader.java:123) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.runDownloader(GeoIpDownloader.java:260) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:97) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:43) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.persistent.NodePersistentTasksExecutor$1.doRun(NodePersistentTasksExecutor.java:42) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
	Suppressed: java.net.SocketException: Broken pipe
		at sun.nio.ch.NioSocketImpl.implWrite(NioSocketImpl.java:420) ~[?:?]
		at sun.nio.ch.NioSocketImpl.write(NioSocketImpl.java:440) ~[?:?]
		at sun.nio.ch.NioSocketImpl$2.write(NioSocketImpl.java:826) ~[?:?]
		at java.net.Socket$SocketOutputStream.write(Socket.java:1045) ~[?:?]
		at sun.security.ssl.SSLSocketOutputRecord.encodeAlert(SSLSocketOutputRecord.java:82) ~[?:?]
		at sun.security.ssl.TransportContext.fatal(TransportContext.java:400) ~[?:?]
		at sun.security.ssl.TransportContext.fatal(TransportContext.java:312) ~[?:?]
		at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:463) ~[?:?]
		at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:422) ~[?:?]
		at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:574) ~[?:?]
		at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:183) ~[?:?]
		at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1653) ~[?:?]
		at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1577) ~[?:?]
		at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) ~[?:?]
		at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:308) ~[?:?]
		at org.elasticsearch.ingest.geoip.HttpClient.lambda$get$0(HttpClient.java:55) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at java.security.AccessController.doPrivileged(AccessController.java:554) ~[?:?]
		at org.elasticsearch.ingest.geoip.HttpClient.doPrivileged(HttpClient.java:97) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.HttpClient.get(HttpClient.java:49) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.HttpClient.getBytes(HttpClient.java:40) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloader.fetchDatabasesOverview(GeoIpDownloader.java:135) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloader.updateDatabases(GeoIpDownloader.java:123) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloader.runDownloader(GeoIpDownloader.java:260) [ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:97) [ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:43) [ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.persistent.NodePersistentTasksExecutor$1.doRun(NodePersistentTasksExecutor.java:42) [elasticsearch-7.17.0.jar:7.17.0]
		at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
		at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
		at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: java.io.EOFException: SSL peer shut down incorrectly
	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:483) ~[?:?]
	at sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:472) ~[?:?]
	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:160) ~[?:?]
	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:111) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1506) ~[?:?]
	... 25 more
[2022-04-11T19:20:14,704][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-11T19:20:24,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3s/7348ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:20:25,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3s/7347603309ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:20:26,639][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-11T19:20:28,390][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-11T19:21:06,621][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [5655ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:21:25,598][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4s/8409ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:21:29,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4s/8409194725ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:21:33,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8s/7811ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:21:44,824][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8s/7810226333ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:21:51,241][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.5s/13517ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:21:52,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.5s/13517025970ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:21:52,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5110/0x00000008017e0960@2221fab3] took [30336ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:21:55,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.1s/9101ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:22:05,307][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.1s/9101138162ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:22:06,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10459ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:22:07,537][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10459700521ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:22:06,839][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59708}] took [10460ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:22:11,328][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [77162ms] which is above the warn threshold of [10s]; wrote global metadata [false] and metadata for [3] indices and skipped [44] unchanged indices
[2022-04-11T19:22:11,447][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [1.3m] publication of cluster state version [8961] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-04-11T19:22:35,030][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][46] overhead, spent [485ms] collecting in the last [1.4s]
[2022-04-11T19:22:36,795][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59708}] took [5248ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:22:36,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [21302ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:23:06,380][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [11813ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:23:22,098][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [5209ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:23:52,210][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T19:23:52,210][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T19:23:51,313][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [66584ms] which is above the warn threshold of [10s]; wrote global metadata [false] and metadata for [1] indices and skipped [46] unchanged indices
[2022-04-11T19:23:53,885][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5110/0x00000008017e0960@34c70944] took [14784ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:23:55,512][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [1.2m] publication of cluster state version [8962] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-04-11T19:24:17,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15701ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:22,427][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15701009904ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:25,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.6s/7641ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:28,725][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.6s/7641428985ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:29,675][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59726}] took [7641ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:24:32,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4s/7420ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:36,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4s/7420418102ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:42,112][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9505ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:44,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9504380025ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:24:43,118][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_license][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59726}] took [9504ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:24:45,902][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][56][12] duration [11.6s], collections [1]/[18.5s], total [11.6s]/[13.5s], memory [187.9mb]->[105.9mb]/[2gb], all_pools {[young] [84mb]->[0b]/[0b]}{[old] [95.9mb]->[95.9mb]/[2gb]}{[survivor] [8mb]->[9.9mb]/[0b]}
[2022-04-11T19:24:48,841][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][56] overhead, spent [11.6s] collecting in the last [18.5s]
[2022-04-11T19:24:53,244][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [35871ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:25:01,492][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5110/0x00000008017e0960@490ed723] took [5277ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:25:29,897][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=230, version=8962}] took [1.3m] which is above the warn threshold of [30s]: [running task [Publication{term=230, version=8962}]] took [76ms], [connecting to new nodes] took [46ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@da71c6e] took [0ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@1e79b753] took [29934ms], [org.elasticsearch.script.ScriptService@1b3834c1] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@5499c9a8] took [1ms], [org.elasticsearch.snapshots.RestoreService@61e8eb39] took [0ms], [org.elasticsearch.ingest.IngestService@32780b78] took [10457ms], [org.elasticsearch.action.ingest.IngestActionForwarder@683cafca] took [176ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4526/0x00000008016d2640@7272efec] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@54e573b8] took [6ms], [org.elasticsearch.tasks.TaskManager@26349197] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@2b7b3864] took [117ms], [org.elasticsearch.cluster.InternalClusterInfoService@4f422da9] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@11f2c0c1] took [0ms], [org.elasticsearch.indices.SystemIndexManager@3fe52349] took [959ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@3bda7ebe] took [0ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x00000008012d94e8@74c62010] took [405ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@7731947] took [1ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@448dbc41] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x00000008013ba000@5189d28] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@4a4e7366] took [60ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@1a79674e] took [30846ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@a100ad6] took [0ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@36a69f18] took [0ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@3c6a65a0] took [6673ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@207c6ae6] took [99ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@61349821] took [0ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@63688540] took [1741ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@5499c9a8] took [36ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@cc0bbe8] took [370ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@4f28cbcc] took [0ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@246b80b2] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@21a0698] took [2ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@41ebba80] took [0ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@370ef08a] took [0ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@753c2c19] took [38ms], [org.elasticsearch.node.ResponseCollectorService@691fa784] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@40f6a806] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@3c9a32] took [0ms], [org.elasticsearch.shutdown.PluginShutdownService@14f432c8] took [0ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@454bf96f] took [0ms], [org.elasticsearch.indices.store.IndicesStore@610d8b7c] took [0ms], [org.elasticsearch.persistent.PersistentTasksNodeService@6350bd9] took [0ms], [org.elasticsearch.license.LicenseService@7e5054da] took [0ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@69116b70] took [0ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@3d6dc9c5] took [0ms], [org.elasticsearch.gateway.GatewayService@14843365] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@33f528e4] took [0ms]
[2022-04-11T19:25:42,400][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [8111ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:26:48,033][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16332ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:26:51,903][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16332570136ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:27:01,322][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13659ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:27:10,115][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13658727913ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:27:20,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19346ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:27:32,289][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19346266631ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:27:40,827][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19424ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:27:50,177][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19423875845ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:01,843][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21545ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:12,400][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21544947806ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:21,367][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19494ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:27,512][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19493835335ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:28,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5110/0x00000008017e0960@1b9eb550] took [148387ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:28:34,291][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12757ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:40,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12756532327ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:46,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@28976841, interval=5s}] took [12243ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:28:46,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12243ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:51,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12243515448ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:55,351][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9012ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:28:59,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9011875458ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:03,569][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4s/8495ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:08,674][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4s/8494735711ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:13,606][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9507ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:17,686][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9506856892ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:21,824][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.9s/8954ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:25,964][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.9s/8954281751ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:25,964][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [8954ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:29:30,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.5s/8559ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:29,642][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [8954ms] which is above the warn threshold of [5s]
[2022-04-11T19:29:32,655][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.5s/8559279738ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:35,894][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3s/5353ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:39,688][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [5352ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:29:39,746][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3s/5352579788ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:42,195][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5s/6500ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:45,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4s/6499859307ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:45,174][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [212357ms] which is above the warn threshold of [10s]; wrote global metadata [false] and metadata for [2] indices and skipped [45] unchanged indices
[2022-04-11T19:29:47,598][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5481ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:50,938][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5480915140ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:53,328][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:29:54,599][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [10948ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:29:50,699][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [3.8m] publication of cluster state version [8963] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{nWOG4iQKS6aZqt_pISFuKw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-04-11T19:29:55,381][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5467593308ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:30:01,578][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@28976841, interval=5s}] took [7962ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:31:16,713][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24619ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:19,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24618382148ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:25,674][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9576ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:29,836][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9576439562ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:34,915][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9396ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:37,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9395965854ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:38,360][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59750}] took [9396ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:31:44,393][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.5s/8593ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:31:52,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.5s/8592619796ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:00,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5110/0x00000008017e0960@35cd7aa3] took [112244ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:31:59,698][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.1s/16127ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:06,571][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.1s/16127582896ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:13,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13957ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:19,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13956378652ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:24,484][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5s/10580ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:24,484][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:59750}] took [13956ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:32:31,240][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5s/10580728981ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:31,240][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][69][13] duration [16.5s], collections [1]/[2.3m], total [16.5s]/[30.1s], memory [177.9mb]->[110.9mb]/[2gb], all_pools {[young] [72mb]->[4mb]/[0b]}{[old] [95.9mb]->[100.2mb]/[2gb]}{[survivor] [9.9mb]->[6.7mb]/[0b]}
[2022-04-11T19:32:40,291][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [24537ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:32:40,373][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15329ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:46,645][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15328778045ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:53,622][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13673ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:32:58,456][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13672486579ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:03,892][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10472ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:08,727][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10472388688ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:13,192][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9318ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:12,127][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=230, version=8963}] took [3.1m] which is above the warn threshold of [30s]: [running task [Publication{term=230, version=8963}]] took [65ms], [connecting to new nodes] took [406ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@da71c6e] took [0ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@1e79b753] took [13164ms], [org.elasticsearch.script.ScriptService@1b3834c1] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@5499c9a8] took [0ms], [org.elasticsearch.snapshots.RestoreService@61e8eb39] took [0ms], [org.elasticsearch.ingest.IngestService@32780b78] took [6041ms], [org.elasticsearch.action.ingest.IngestActionForwarder@683cafca] took [69ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4526/0x00000008016d2640@7272efec] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@54e573b8] took [67ms], [org.elasticsearch.tasks.TaskManager@26349197] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@2b7b3864] took [111ms], [org.elasticsearch.cluster.InternalClusterInfoService@4f422da9] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@11f2c0c1] took [71ms], [org.elasticsearch.indices.SystemIndexManager@3fe52349] took [3635ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@3bda7ebe] took [72ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x00000008012d94e8@74c62010] took [443ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@7731947] took [156ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@448dbc41] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x00000008013ba000@5189d28] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@4a4e7366] took [73ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@1a79674e] took [82691ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@a100ad6] took [1ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@36a69f18] took [0ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@3c6a65a0] took [22672ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@207c6ae6] took [1330ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@61349821] took [527ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@63688540] took [20443ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@5499c9a8] took [930ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@cc0bbe8] took [17431ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@4f28cbcc] took [177ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@246b80b2] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@21a0698] took [11814ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@41ebba80] took [6478ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@370ef08a] took [0ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@753c2c19] took [1566ms], [org.elasticsearch.node.ResponseCollectorService@691fa784] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@40f6a806] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@3c9a32] took [0ms], [org.elasticsearch.shutdown.PluginShutdownService@14f432c8] took [161ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@454bf96f] took [149ms], [org.elasticsearch.indices.store.IndicesStore@610d8b7c] took [294ms], [org.elasticsearch.persistent.PersistentTasksNodeService@6350bd9] took [0ms], [org.elasticsearch.license.LicenseService@7e5054da] took [0ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@69116b70] took [80ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@3d6dc9c5] took [0ms], [org.elasticsearch.gateway.GatewayService@14843365] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@33f528e4] took [0ms]
[2022-04-11T19:33:18,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9318075504ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:27,960][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14693ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:33,453][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [7.8m/471501ms] which is longer than the warn threshold of [300000ms]; there are currently [8] pending tasks, the oldest of which has age [10.7m/645342ms]
[2022-04-11T19:33:34,592][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14693026452ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:40,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.8s/12885ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:31,182][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14693ms] which is above the warn threshold of [5s]
[2022-04-11T19:33:45,244][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [12885ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:33:46,296][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.8s/12885162150ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:51,404][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@466b153f, interval=5s}] took [10411ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:33:51,404][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10412ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:33:57,317][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10411997646ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:02,736][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.3s/11314ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:09,583][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.3s/11313843586ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:15,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.5s/12597ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:19,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6a37f7bf, interval=1s}] took [12596ms] which is above the warn threshold of [5000ms]
[2022-04-11T19:34:19,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.5s/12596497893ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:23,957][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6s/8693ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:28,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6s/8693472973ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:34:46,617][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [59.1s/59185ms] to compute cluster state update for [cluster_reroute(reroute after starting shards)], which exceeds the warn threshold of [10s]
[2022-04-11T19:36:00,322][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/92219ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:37:44,178][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/92218373512ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:39:52,616][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/229649ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:41:35,974][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/229649346783ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:42:50,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/172490ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:44:24,831][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/172240658825ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:46:03,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.2m/195551ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:48:12,134][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.2m/195800793034ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:50:31,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/268494ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T19:54:00,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/267993854474ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T19:57:10,691][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6m/396654ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:00:38,733][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6m/396678744625ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:03:25,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/367727ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:06:36,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/367954352579ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:10:17,163][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9m/415412ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:13:04,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9m/415659430698ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:16:15,863][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/340690ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:19:44,302][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/340176881629ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:23:11,885][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7m/423672ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:26:24,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7m/424185702636ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:29:22,626][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3m/383559ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:32:50,503][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3m/383104077230ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:36:28,220][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7m/421078ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:39:57,489][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7m/421355020849ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:43:10,540][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.7m/405021ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:46:29,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.7m/404867254215ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T20:50:08,467][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.7m/402656ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T20:57:58,288][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-11T20:57:58,344][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-11T20:57:58,345][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-11T20:58:05,155][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-11T20:58:05,156][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-11T20:58:05,157][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-11T20:58:05,157][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-11T20:58:05,158][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-11T20:58:05,159][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-11T20:58:05,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-11T20:58:05,161][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-11T20:58:05,163][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-11T20:58:05,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-11T20:58:05,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-11T20:58:05,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-11T20:58:05,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-11T20:58:05,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-11T20:58:05,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-11T20:58:05,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-11T20:58:05,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-11T20:58:05,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-11T20:58:05,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-11T20:58:05,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-11T20:58:05,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-11T20:58:05,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-11T20:58:05,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-11T20:58:05,179][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-11T20:58:05,180][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-11T20:58:05,181][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-11T20:58:05,182][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-11T20:58:05,182][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-11T20:58:05,183][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-11T20:58:05,184][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-11T20:58:05,185][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-11T20:58:05,186][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-11T20:58:05,187][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-11T20:58:05,188][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-11T20:58:05,189][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-11T20:58:05,190][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-11T20:58:05,191][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-11T20:58:05,192][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-11T20:58:05,193][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-11T20:58:05,194][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-11T20:58:05,195][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-11T20:58:05,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-11T20:58:05,202][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-11T20:58:05,202][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-11T20:58:05,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-11T20:58:05,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-11T20:58:05,204][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-11T20:58:05,204][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-11T20:58:05,204][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-11T20:58:05,205][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-11T20:58:05,205][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-11T20:58:05,205][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-11T20:58:05,206][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-11T20:58:05,206][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-11T20:58:05,207][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-11T20:58:05,207][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-11T20:58:05,207][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-11T20:58:05,208][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-11T20:58:05,209][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-11T20:58:05,310][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.5gb], net total_space [125.8gb], types [ext4]
[2022-04-11T20:58:05,312][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-11T20:58:06,085][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-11T20:58:23,872][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-11T20:58:23,876][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-11T20:58:23,877][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T20:58:23,878][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-11T20:58:23,879][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T20:58:23,879][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp]
[2022-04-11T20:58:23,880][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-11T20:58:23,881][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-11T20:58:23,881][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T20:58:23,882][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T20:58:23,883][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-11T20:58:23,884][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-11T20:58:26,538][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-11T20:58:26,738][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-11T20:58:28,753][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-11T20:58:30,260][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-11T20:58:30,261][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-11T20:58:30,321][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-11T20:58:30,323][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-11T20:58:30,637][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-11T20:58:34,621][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-11T20:58:34,855][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{NQHbqHqgR-a7MMmSAMORoA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 231, version: 8964, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{NQHbqHqgR-a7MMmSAMORoA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-11T20:58:35,115][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{NQHbqHqgR-a7MMmSAMORoA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 231, version: 8964, reason: Publication{term=231, version=8964}
[2022-04-11T20:58:35,376][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-11T20:58:35,378][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-11T20:58:36,883][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-11T20:58:36,898][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [47] indices into cluster_state
[2022-04-11T20:58:38,617][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-11T20:58:38,623][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-11T20:58:39,874][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-11T20:58:40,465][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-11T20:58:41,321][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-11T20:58:41,334][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-11T20:58:41,339][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-11T20:58:41,754][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-11T20:58:42,290][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T20:58:42,454][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T20:58:46,871][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-11T20:58:58,662][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.11][0]]]).
[2022-04-11T21:00:01,271][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-11T21:00:01,289][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-11T21:00:01,291][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-11T21:00:08,466][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-11T21:00:08,467][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-11T21:00:08,468][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-11T21:00:08,469][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-11T21:00:08,469][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-11T21:00:08,470][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-11T21:00:08,471][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-11T21:00:08,472][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-11T21:00:08,472][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-11T21:00:08,473][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-11T21:00:08,473][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-11T21:00:08,474][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-11T21:00:08,474][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-11T21:00:08,475][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-11T21:00:08,475][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-11T21:00:08,475][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-11T21:00:08,476][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-11T21:00:08,476][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-11T21:00:08,478][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-11T21:00:08,478][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-11T21:00:08,479][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-11T21:00:08,479][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-11T21:00:08,480][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-11T21:00:08,480][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-11T21:00:08,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-11T21:00:08,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-11T21:00:08,482][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-11T21:00:08,483][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-11T21:00:08,483][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-11T21:00:08,484][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-11T21:00:08,484][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-11T21:00:08,484][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-11T21:00:08,485][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-11T21:00:08,485][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-11T21:00:08,486][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-11T21:00:08,486][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-11T21:00:08,487][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-11T21:00:08,487][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-11T21:00:08,488][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-11T21:00:08,489][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-11T21:00:08,490][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-11T21:00:08,490][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-11T21:00:08,491][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-11T21:00:08,492][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-11T21:00:08,492][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-11T21:00:08,492][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-11T21:00:08,493][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-11T21:00:08,493][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-11T21:00:08,494][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-11T21:00:08,494][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-11T21:00:08,494][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-11T21:00:08,495][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-11T21:00:08,495][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-11T21:00:08,496][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-11T21:00:08,496][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-11T21:00:08,497][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-11T21:00:08,497][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-11T21:00:08,498][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-11T21:00:08,499][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-11T21:00:08,587][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.5gb], net total_space [125.8gb], types [ext4]
[2022-04-11T21:00:08,588][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-11T21:00:09,112][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-11T21:00:25,808][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-11T21:00:25,813][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-11T21:00:25,815][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-11T21:00:25,817][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-11T21:00:25,819][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T21:00:25,820][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-11T21:00:25,821][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-11T21:00:25,822][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T21:00:25,822][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-11T21:00:25,823][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-11T21:00:25,824][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-11T21:00:25,825][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T21:00:25,826][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T21:00:25,826][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-11T21:00:25,827][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-11T21:00:27,454][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-11T21:00:27,687][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-11T21:00:29,350][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-11T21:00:30,847][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-11T21:00:30,849][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-11T21:00:30,937][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-11T21:00:30,940][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-11T21:00:31,255][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-11T21:00:35,692][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-11T21:00:35,838][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 232, version: 9025, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-11T21:00:36,152][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 232, version: 9025, reason: Publication{term=232, version=9025}
[2022-04-11T21:00:36,403][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-11T21:00:36,404][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-11T21:00:37,961][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-11T21:00:37,984][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [47] indices into cluster_state
[2022-04-11T21:00:39,873][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-11T21:00:39,877][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-11T21:00:41,151][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-11T21:00:41,995][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-11T21:00:42,809][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-11T21:00:42,876][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-11T21:00:42,885][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-11T21:00:42,891][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-11T21:00:43,709][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-11T21:00:43,891][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-11T21:00:49,770][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-11T21:00:51,124][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][20] overhead, spent [382ms] collecting in the last [1s]
[2022-04-11T21:00:56,216][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0]]]).
[2022-04-11T21:01:28,480][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-1970.01.01] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-11T21:01:28,699][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:28,811][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-1970.01.01][0]]]).
[2022-04-11T21:01:29,075][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-1970.01.01/9Y6aaqQuTfir-K-bt-BQiw] update_mapping [_doc]
[2022-04-11T21:01:29,178][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:29,464][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:29,652][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:30,163][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:30,370][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:31,099][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:31,687][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:32,130][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:33,267][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:33,685][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:34,380][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:36,187][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:37,764][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:37,995][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:38,251][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:39,095][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:39,527][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:01:40,839][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:19:23,619][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.11/I4qSs1YcSCGPOEWZhQlVbw] update_mapping [_doc]
[2022-04-11T21:22:48,955][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [32776ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:23:53,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [6033ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:24:08,326][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [8000ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:24:53,625][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [8702ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:27:53,931][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5285ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:30:41,178][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5248600084ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:31:50,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/390762ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:32:16,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/391257461143ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:32:53,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64069ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:33:08,136][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64069603143ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:33:21,891][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28800ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:33:38,675][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28799896041ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:33:54,109][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.8s/31890ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:34:17,487][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.8s/31889629513ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:34:43,227][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45732ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:35:11,965][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45731915162ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:36:05,605][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85847ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:36:24,856][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85846877006ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:36:39,339][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.3s/35329ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:36:41,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@2f524db2, interval=5s}] took [35329ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:37:01,093][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.3s/35329042634ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:37:25,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.3s/44309ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:37:38,116][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.3s/44309560962ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:39:28,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/122395ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:39:52,307][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/122394741253ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:40:11,444][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.6s/42679ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:40:34,878][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [42550ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:41:00,962][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42550227482ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:41:09,688][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/61288ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:41:19,576][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/61417015763ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:41:33,017][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.7s/22700ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:41:49,083][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.6s/22699960278ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:42:04,022][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29090ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:42:29,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29089230012ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:42:45,917][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.1s/43102ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:43:08,836][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.1s/43102648140ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:43:57,550][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67050ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:44:23,394][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67049958817ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:44:30,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.6s/38694ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:43:58,548][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [17.3m/1040142ms] ago, timed out [16.7m/1005385ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [10741]
[2022-04-11T21:44:47,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.6s/38694122267ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:44:56,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26634ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:45:10,725][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26633515514ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:45:15,624][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [18278ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:45:14,902][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18278ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:45:30,361][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18278461642ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:45:35,373][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [19824ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:45:34,842][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.8s/19824ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:45:58,210][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.8s/19824018510ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:45:33,276][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [18278ms] which is above the warn threshold of [5s]
[2022-04-11T21:46:27,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.8s/45813ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:46:27,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [45812ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:46:35,011][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.8s/45812674788ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:11,794][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51279ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:19,668][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51279450343ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:18,821][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [10741] timed out after [34757ms]
[2022-04-11T21:47:22,365][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5s/10538ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:26,229][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5s/10537382667ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:31,225][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.8s/8831ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:31,225][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@5d70c66e, interval=1m}] took [8831ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:47:39,388][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.8s/8831167895ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:44,132][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.8s/12843ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:52,089][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.8s/12842835098ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:47:57,713][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.9s/12966ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:04,774][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.9s/12966152192ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:11,660][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14528ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:18,505][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14527801790ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:30,140][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13902ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:35,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13901757593ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:39,916][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14756ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:49,598][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14756808941ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:48:55,024][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14611ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:01,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14610352471ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:11,790][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13071ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:16,735][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13071247422ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:22,452][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14060ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:28,423][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14060512144ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:31,003][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1337][36] duration [17.9s], collections [1]/[1.6m], total [17.9s]/[19.9s], memory [1.3gb]->[250.3mb]/[2gb], all_pools {[young] [1.1gb]->[20mb]/[0b]}{[old] [223.4mb]->[223.4mb]/[2gb]}{[survivor] [6.3mb]->[6.8mb]/[0b]}
[2022-04-11T21:49:33,465][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10985ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:39,622][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10984562834ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:40,317][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [121722ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:49:45,426][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12388ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:49:54,680][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12388153237ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:50:03,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18679ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:50:22,991][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18678628624ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:50:27,716][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24015ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T21:50:30,610][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24015310780ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T21:50:31,027][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [24015ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:50:32,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [5171ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:50:51,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [6204ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:51:46,337][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [19813ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:52:44,535][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [5866ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:52:59,676][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [6004ms] which is above the warn threshold of [5s]
[2022-04-11T21:53:49,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [34467ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:54:17,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [13145ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:54:58,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017e2020@3271a754] took [6971ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:56:10,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [36426ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:57:06,616][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [5907ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:57:05,022][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve stats for node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][cluster:monitor/nodes/stats[n]] request_id [11084] timed out after [113584ms]
[2022-04-11T21:56:59,802][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [12435ms] which is above the warn threshold of [5s]
[2022-04-11T21:57:10,432][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [2.2m/132049ms] ago, timed out [18.8s/18872ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [11085]
[2022-04-11T21:57:14,065][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [2.3m/141133ms] ago, timed out [27.5s/27549ms] ago, action [cluster:monitor/nodes/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [11084]
[2022-04-11T21:57:24,395][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [6611ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:57:16,890][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [11085] timed out after [113177ms]
[2022-04-11T21:58:39,224][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [8805ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:58:29,614][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve stats for node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][cluster:monitor/nodes/stats[n]] request_id [11134] timed out after [17983ms]
[2022-04-11T21:58:30,187][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [11135] timed out after [17383ms]
[2022-04-11T21:58:40,561][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [32.7s/32793ms] ago, timed out [15.4s/15410ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [11135]
[2022-04-11T21:58:40,561][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [33.3s/33393ms] ago, timed out [15.4s/15410ms] ago, action [cluster:monitor/nodes/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [11134]
[2022-04-11T21:58:52,130][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [6404ms] which is above the warn threshold of [5000ms]
[2022-04-11T21:59:17,389][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [7604ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:00:23,803][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1396][37] duration [3.1s], collections [1]/[4.9s], total [3.1s]/[23.1s], memory [310.3mb]->[234mb]/[2gb], all_pools {[young] [84mb]->[0b]/[0b]}{[old] [223.4mb]->[223.5mb]/[2gb]}{[survivor] [6.8mb]->[10.5mb]/[0b]}
[2022-04-11T22:00:28,514][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1396] overhead, spent [3.1s] collecting in the last [4.9s]
[2022-04-11T22:00:29,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [5590ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:00:31,081][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1397][38] duration [2.6s], collections [1]/[6.8s], total [2.6s]/[25.7s], memory [234mb]->[264.6mb]/[2gb], all_pools {[young] [0b]->[28mb]/[0b]}{[old] [223.5mb]->[225.4mb]/[2gb]}{[survivor] [10.5mb]->[11.1mb]/[0b]}
[2022-04-11T22:00:32,543][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1397] overhead, spent [2.6s] collecting in the last [6.8s]
[2022-04-11T22:00:50,774][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3s/6365ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:00:52,294][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1401][39] duration [4.5s], collections [1]/[8.1s], total [4.5s]/[30.3s], memory [304.6mb]->[236.3mb]/[2gb], all_pools {[young] [72mb]->[12mb]/[0b]}{[old] [225.4mb]->[227.6mb]/[2gb]}{[survivor] [11.1mb]->[8.7mb]/[0b]}
[2022-04-11T22:00:56,709][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1401] overhead, spent [4.5s] collecting in the last [8.1s]
[2022-04-11T22:00:52,294][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:53468}] took [6966ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:00:56,660][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3s/6365551429ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:00:56,710][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [6365ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:00:56,928][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6861ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:00:56,928][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6861391882ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:00:56,940][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [6861ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:01:02,006][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1402][41] duration [4.9s], collections [2]/[11s], total [4.9s]/[35.2s], memory [236.3mb]->[236.2mb]/[2gb], all_pools {[young] [12mb]->[24mb]/[0b]}{[old] [227.6mb]->[230.9mb]/[2gb]}{[survivor] [8.7mb]->[5.3mb]/[0b]}
[2022-04-11T22:01:02,405][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1402] overhead, spent [4.9s] collecting in the last [11s]
[2022-04-11T22:01:24,235][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9s/6945ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:01:34,481][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1407][43] duration [9.3s], collections [2]/[1.8s], total [9.3s]/[44.6s], memory [276.2mb]->[324.2mb]/[2gb], all_pools {[young] [48mb]->[28mb]/[0b]}{[old] [230.9mb]->[230.9mb]/[2gb]}{[survivor] [5.3mb]->[8.8mb]/[0b]}
[2022-04-11T22:01:34,216][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9s/6945244923ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:01:38,079][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13998ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:01:37,971][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1407] overhead, spent [9.3s] collecting in the last [1.8s]
[2022-04-11T22:01:38,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13997114279ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:01:38,870][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [21542ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:01:40,787][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1408][44] duration [2.1s], collections [1]/[23.6s], total [2.1s]/[46.7s], memory [324.2mb]->[264.8mb]/[2gb], all_pools {[young] [28mb]->[28mb]/[0b]}{[old] [230.9mb]->[232.6mb]/[2gb]}{[survivor] [8.8mb]->[4.2mb]/[0b]}
[2022-04-11T22:02:02,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:24,103][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14466680507ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:24,505][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1412][46] duration [24.9s], collections [2]/[16.1s], total [24.9s]/[1.1m], memory [288.8mb]->[240mb]/[2gb], all_pools {[young] [52mb]->[88mb]/[0b]}{[old] [232.6mb]->[232.6mb]/[2gb]}{[survivor] [4.2mb]->[7.4mb]/[0b]}
[2022-04-11T22:02:27,479][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1412] overhead, spent [24.9s] collecting in the last [16.1s]
[2022-04-11T22:02:26,196][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24909ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:31,732][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [39375ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:02:32,203][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24909207751ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:35,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [8210ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:02:35,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2s/8210ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:37,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2s/8210095448ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:41,318][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6s/6601ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:44,769][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6s/6600605957ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:48,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [6516ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:02:48,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5s/6516ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:53,227][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5s/6516408599ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:02:49,069][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:33012}] took [6517ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:02:58,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10716ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:02,454][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10715628896ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:02,157][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [10715ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:03:08,104][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2s/9217ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:12,391][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2s/9216729782ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:15,879][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1s/8100ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:16,646][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_nodes?filter_path=nodes.*.version%2Cnodes.*.http.publish_address%2Cnodes.*.ip][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:53452}] took [8100ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:03:19,420][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1s/8100412485ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:19,290][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [8100ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:03:22,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6868ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:31,085][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6868169174ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:40,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16345ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:46,431][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16344574983ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:52,332][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13021ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:03:42,900][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:33018}] took [16344ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:03:55,185][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017e2020@b317c8f] took [13020ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:03:57,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13020892693ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:04:03,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2s/11250ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:04:10,779][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [11250ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:04:12,319][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2s/11250403689ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:04:11,635][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:33018}] took [11250ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:04:20,322][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16608ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:04:28,998][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16607521115ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:04:37,074][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16969ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:28,926][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16968876686ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:29,774][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1416][47] duration [30.2s], collections [1]/[1m], total [30.2s]/[1.6m], memory [316.6mb]->[324.6mb]/[2gb], all_pools {[young] [76mb]->[84mb]/[0b]}{[old] [232.6mb]->[232.6mb]/[2gb]}{[survivor] [8mb]->[6.4mb]/[0b]}
[2022-04-11T22:05:32,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:32,287][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1416] overhead, spent [30.2s] collecting in the last [1m]
[2022-04-11T22:05:34,453][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [89043ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:05:35,296][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55467186955ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:39,481][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7045ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:43,030][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7044780100ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:46,699][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2s/7227ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:53,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2s/7227744368ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:05:45,836][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [7045ms] which is above the warn threshold of [5s]
[2022-04-11T22:06:01,871][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.2s/14271ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:06:09,990][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.2s/14271012523ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:06:25,020][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23668ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:06:33,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23667320386ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:08:00,487][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95176ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:08:12,343][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95176258344ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:08:22,618][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1417][48] duration [1m], collections [1]/[1.9m], total [1m]/[2.7m], memory [324.6mb]->[319mb]/[2gb], all_pools {[young] [84mb]->[88mb]/[0b]}{[old] [232.6mb]->[232.6mb]/[2gb]}{[survivor] [6.4mb]->[6.4mb]/[0b]}
[2022-04-11T22:08:30,708][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.7s/30733ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:08:33,995][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1417] overhead, spent [1m] collecting in the last [1.9m]
[2022-04-11T22:08:41,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.7s/30733493136ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:08:38,935][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:33018}] took [30734ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:08:44,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [149577ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:08:49,668][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18392ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:09:03,184][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18391161031ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:09:09,486][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.5s/20555ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:09:24,599][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.5s/20555788966ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:09:39,109][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.3s/29353ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:09:53,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.3s/29352121073ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:10:06,467][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27132ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:10:20,118][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27132610677ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:10:34,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28889ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:10:46,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28888748550ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:11:03,543][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27838ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:11:19,861][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [56726ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:10:56,745][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [28889ms] which is above the warn threshold of [5s]
[2022-04-11T22:11:21,806][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27837986906ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:11:45,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.1s/41142ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:11:48,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec8889, interval=5s}] took [41141ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:12:03,155][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.1s/41141815228ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:11:51,124][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [11648] timed out after [217876ms]
[2022-04-11T22:12:21,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.8s/35841ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:12:24,175][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [6.3m/378718ms] ago, timed out [2.6m/160842ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{I-JEfLsbRoeRxhc3lMJqYA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [11648]
[2022-04-11T22:12:29,559][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.8s/35840987221ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:12:39,056][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19s/19063ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:12:49,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19s/19063664584ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:13:01,979][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22958ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:13:14,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22957521661ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:13:27,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.8s/24876ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:13:37,958][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.8s/24876554622ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:13:49,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22901ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:14:03,831][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22900352792ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T22:14:09,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@70507abe, interval=1s}] took [22900ms] which is above the warn threshold of [5000ms]
[2022-04-11T22:14:17,778][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.9s/27916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T22:14:30,502][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.9s/27916228893ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:22:07,645][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1h/3865991ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:26:12,335][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1h/3865990576951ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:30:52,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8m/651631ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:35:15,114][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-11T23:35:15,163][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-11T23:35:15,164][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-11T23:48:31,266][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-11T23:48:31,271][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-11T23:48:31,272][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-11T23:48:31,273][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-11T23:48:31,273][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-11T23:48:31,273][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-11T23:48:31,274][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-11T23:48:31,274][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-11T23:48:31,275][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-11T23:48:31,275][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-11T23:48:31,276][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-11T23:48:31,276][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-11T23:48:31,276][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-11T23:48:31,277][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-11T23:48:31,277][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-11T23:48:31,277][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-11T23:48:31,278][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-11T23:48:31,278][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-11T23:48:31,278][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-11T23:48:31,279][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-11T23:48:31,279][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-11T23:48:31,280][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-11T23:48:31,280][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-11T23:48:31,280][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-11T23:48:31,281][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-11T23:48:31,281][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-11T23:48:31,281][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-11T23:48:31,282][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-11T23:48:31,282][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-11T23:48:31,282][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-11T23:48:31,283][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-11T23:48:31,283][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-11T23:48:31,283][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-11T23:48:31,284][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-11T23:48:31,284][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-11T23:48:31,284][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-11T23:48:31,285][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-11T23:48:31,285][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-11T23:48:31,285][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-11T23:48:31,286][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-11T23:48:31,286][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-11T23:48:31,286][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-11T23:48:31,287][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-11T23:48:31,287][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-11T23:48:31,287][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-11T23:48:31,288][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-11T23:48:31,288][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-11T23:48:31,288][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-11T23:48:31,289][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-11T23:48:31,289][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-11T23:48:31,289][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-11T23:48:31,289][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-11T23:48:31,290][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-11T23:48:31,290][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-11T23:48:31,291][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-11T23:48:31,291][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-11T23:48:31,291][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-11T23:48:31,291][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-11T23:48:31,292][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-11T23:48:35,462][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.5gb], net total_space [125.8gb], types [ext4]
[2022-04-11T23:48:35,846][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-11T23:48:37,039][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-11T23:50:06,136][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7073ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:25,930][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7073821718ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:29,912][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/112756ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:32,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/112756061888ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:36,455][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2s/6247ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:39,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2s/6246744200ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:42,979][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9s/6934ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:51:50,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9s/6934177080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:52:00,201][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16216ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:52:12,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16216120572ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:52:22,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23497ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:52:27,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23496260291ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:52:38,495][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14931ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:53:01,687][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14931017778ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:52:38,495][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@42e8dbc6, interval=1m}] took [23496ms] which is above the warn threshold of [5000ms]
[2022-04-11T23:53:15,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.3s/36359ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:53:31,766][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.3s/36359638498ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:53:56,354][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.8s/34856ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:53:58,285][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c63529e, interval=5s}] took [34855ms] which is above the warn threshold of [5000ms]
[2022-04-11T23:54:08,375][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.8s/34855641990ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:54:19,835][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.4s/30422ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:54:20,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c63529e, interval=5s}] took [30421ms] which is above the warn threshold of [5000ms]
[2022-04-11T23:54:30,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.4s/30421856201ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:54:37,014][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17374ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:54:41,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17373641886ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:54:48,843][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.7s/11734ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:54:50,144][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c63529e, interval=5s}] took [11734ms] which is above the warn threshold of [5000ms]
[2022-04-11T23:54:54,435][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.7s/11734924478ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:01,320][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12377ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:10,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12376852664ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:19,169][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17943ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:21,256][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7d28a36d, interval=30s}] took [17943ms] which is above the warn threshold of [5000ms]
[2022-04-11T23:55:28,546][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17943092074ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:33,426][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14568ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:38,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14567268324ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:43,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9947ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:55:45,521][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9947366789ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-11T23:56:43,746][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7d28a36d, interval=30s}] took [10693ms] which is above the warn threshold of [5000ms]
[2022-04-11T23:59:09,289][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4s/8418ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-11T23:58:57,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c63529e, interval=5s}] took [17666ms] which is above the warn threshold of [5000ms]
[2022-04-12T01:19:52,537][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T01:19:53,081][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T01:19:53,083][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T05:24:48,770][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T05:24:48,822][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T05:24:48,825][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T06:52:01,243][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T06:52:01,286][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T06:52:01,288][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T06:52:58,643][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T06:52:58,650][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T06:52:58,651][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T06:52:58,652][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T06:52:58,652][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T06:52:58,653][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T06:52:58,653][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T06:52:58,654][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T06:52:58,654][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T06:52:58,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T06:52:58,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T06:52:58,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T06:52:58,656][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T06:52:58,656][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T06:52:58,657][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T06:52:58,657][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T06:52:58,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T06:52:58,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T06:52:58,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T06:52:58,659][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T06:52:58,659][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T06:52:58,659][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T06:52:58,660][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T06:52:58,660][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T06:52:58,660][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T06:52:58,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T06:52:58,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T06:52:58,662][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T06:52:58,662][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T06:52:58,662][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T06:52:58,663][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T06:52:58,663][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T06:52:58,663][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T06:52:58,664][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T06:52:58,664][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T06:52:58,664][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T06:52:58,664][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T06:52:58,665][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T06:52:58,666][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T06:52:58,667][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T06:52:58,668][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T06:52:58,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T06:52:58,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T06:52:58,670][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T06:52:58,670][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T06:52:58,670][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T06:52:58,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T06:52:58,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T06:52:58,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T06:52:58,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T06:52:58,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T06:52:58,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T06:52:58,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T06:52:58,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T06:52:58,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T06:52:58,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T06:52:58,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T06:52:58,675][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T06:52:58,679][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T06:52:58,785][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.6gb], net total_space [125.8gb], types [ext4]
[2022-04-12T06:52:58,787][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T06:53:00,839][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-12T06:55:11,556][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17498ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T06:56:59,416][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17497972975ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T06:57:29,298][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/180567ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T06:58:35,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/180567559914ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T06:59:38,916][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/129283ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:01:07,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/129282781969ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:00:26,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [223962ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:02:20,029][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/162851ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:03:53,547][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/162850528957ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:05:05,200][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/160434ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:05:59,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/160434825623ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:06:14,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/77559ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:06:46,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/77558367497ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:07:09,214][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.6s/55665ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:07:21,432][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.6s/55665181200ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:07:35,927][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25358ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:07:50,536][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25357992284ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:08:07,292][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31462ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:08:55,790][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31461530188ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:09:40,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87880ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:09:46,529][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [87880ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:10:10,684][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87880666734ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:10:36,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.7s/59752ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:11:16,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.7s/59751511066ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:12:10,699][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/92279ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:12:24,539][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5c752ac8, interval=1m}] took [92279ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:13:11,065][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/92279061350ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:13:49,543][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/100315ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:13:54,992][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [100315ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:14:30,350][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/100315457462ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:15:08,608][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78492ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:15:17,590][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [78491ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:15:56,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78491695865ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:17:10,430][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/121129ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:17:37,989][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/121128674788ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:18:01,601][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.2s/55260ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:18:15,209][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.2s/55260579322ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:18:33,289][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31181ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:18:46,036][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31180448586ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:19:04,527][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.6s/31657ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:19:07,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [31657ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:19:28,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.6s/31657842185ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:20:02,981][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.3s/56330ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:20:08,720][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [56329ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:20:41,934][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.3s/56329932564ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:21:43,235][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/98600ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:21:51,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [98599ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:22:20,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/98599591003ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:22:53,518][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/71454ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:23:37,009][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/71454036616ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:24:28,530][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90855ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:24:36,582][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [90854ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:25:23,488][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90854705398ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:26:27,796][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/123558ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:26:31,345][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [123558ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:27:11,443][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/123558235822ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:28:00,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93644ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:28:21,293][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93644366855ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:28:41,673][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42511ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:28:46,752][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [42510ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:28:58,730][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42510423860ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:29:15,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.4s/33422ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:29:35,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.4s/33422711066ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:29:27,115][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [33422ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:29:58,092][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.3s/42319ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:30:18,936][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.3s/42318239987ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:30:39,194][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.8s/40843ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:30:58,964][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.8s/40843047223ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:31:21,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.3s/41329ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:31:21,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5c752ac8, interval=1m}] took [41328ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:31:52,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.3s/41328971867ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:32:32,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67054ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:32:39,094][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [67054ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:33:00,255][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67054415699ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:33:32,337][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64998ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:33:47,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64997997959ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:34:08,309][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.4s/34455ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:34:32,066][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.4s/34454698117ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:34:48,714][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41885ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:34:57,081][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [41884ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:35:29,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41884710047ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:36:25,718][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93634ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:37:56,620][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93634192231ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:39:31,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/184561ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:39:39,833][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [184560ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:40:23,543][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/184560931105ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:41:21,961][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113597ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:41:49,372][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113597098698ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:42:18,717][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.7s/58705ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:43:01,110][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.7s/58704684540ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:43:29,750][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/69911ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:43:32,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [69912ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:43:52,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/69912055881ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:44:17,847][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.1s/49114ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:44:21,158][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5c752ac8, interval=1m}] took [49113ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:44:38,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.1s/49113799075ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:44:58,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [41565ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:44:59,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41566ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:45:17,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41565608915ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:45:37,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38265ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:45:52,620][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38264659425ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:46:13,606][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [32741ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:46:10,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32741ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:46:42,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32741120204ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:47:30,741][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/77500ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:47:36,151][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [77500ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:49:33,839][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/77500167922ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:51:50,013][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/258525ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:52:46,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/258524863235ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:53:16,255][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87896ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:53:41,372][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87896649272ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:54:03,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.3s/49342ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:54:22,533][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.3s/49341179617ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:54:42,444][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38377ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:54:46,521][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [38377ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:55:02,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38377100891ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:55:20,848][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37889ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:55:25,596][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [37889ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:55:38,864][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37889140208ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:55:58,327][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37816ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:55:59,844][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5c752ac8, interval=1m}] took [37816ms] which is above the warn threshold of [5000ms]
[2022-04-12T07:56:30,546][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37816427439ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:57:03,749][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60470ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:57:32,093][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60469732137ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:57:55,741][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55409ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:58:38,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55408653991ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T07:59:14,281][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80727ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T07:59:46,478][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80727366362ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:00:17,384][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62771ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:00:18,135][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [62771ms] which is above the warn threshold of [5000ms]
[2022-04-12T08:01:10,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62771511649ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:02:17,514][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/116853ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:03:49,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/116852897016ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:05:17,556][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/181789ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:06:40,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/181788345511ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:08:19,667][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/178235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:10:20,980][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/178235074907ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:12:34,018][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.1m/251780ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:12:34,820][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5c752ac8, interval=1m}] took [251675ms] which is above the warn threshold of [5000ms]
[2022-04-12T08:15:27,234][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.1m/251675704540ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:18:15,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/337233ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:18:41,996][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a9ddd3f, interval=30s}] took [337232ms] which is above the warn threshold of [5000ms]
[2022-04-12T08:21:11,198][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/337232071838ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:24:29,214][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2m/377611ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:27:28,024][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2m/377510611998ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:30:25,232][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5c752ac8, interval=1m}] took [350855ms] which is above the warn threshold of [5000ms]
[2022-04-12T08:30:20,075][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/350761ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:34:29,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/350855815526ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:38:16,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.7m/467200ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:38:15,848][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [467106ms] which is above the warn threshold of [5000ms]
[2022-04-12T08:45:57,373][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.7m/467106953208ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:50:27,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.8m/713062ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T08:51:19,736][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2eeccea6, interval=5s}] took [712841ms] which is above the warn threshold of [5000ms]
[2022-04-12T08:55:19,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.8m/712841819536ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T08:59:47,279][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5m/572736ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T09:04:08,824][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5m/573030387696ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T09:08:57,518][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.1m/546069ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T09:18:04,561][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T09:18:04,581][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T09:18:04,582][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T09:18:17,631][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T09:18:17,651][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T09:18:17,652][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T09:18:17,653][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T09:18:17,654][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T09:18:17,654][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T09:18:17,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T09:18:17,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T09:18:17,656][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T09:18:17,656][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T09:18:17,657][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T09:18:17,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T09:18:17,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T09:18:17,659][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T09:18:17,659][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T09:18:17,660][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T09:18:17,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T09:18:17,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T09:18:17,662][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T09:18:17,662][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T09:18:17,663][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T09:18:17,663][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T09:18:17,664][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T09:18:17,664][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T09:18:17,665][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T09:18:17,665][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T09:18:17,666][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T09:18:17,666][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T09:18:17,667][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T09:18:17,667][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T09:18:17,668][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T09:18:17,668][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T09:18:17,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T09:18:17,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T09:18:17,670][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T09:18:17,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T09:18:17,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T09:18:17,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T09:18:17,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T09:18:17,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T09:18:17,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T09:18:17,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T09:18:17,675][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T09:18:17,675][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T09:18:17,676][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T09:18:17,676][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T09:18:17,677][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T09:18:17,677][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T09:18:17,678][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T09:18:17,678][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T09:18:17,679][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T09:18:17,679][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T09:18:17,680][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T09:18:17,680][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T09:18:17,681][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T09:18:17,681][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T09:18:17,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T09:18:17,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T09:18:17,683][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T09:18:17,936][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.6gb], net total_space [125.8gb], types [ext4]
[2022-04-12T09:18:17,969][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T11:25:26,135][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T11:25:26,182][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T11:25:26,183][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T11:26:35,902][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T11:26:35,912][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T11:26:35,913][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T11:26:35,913][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T11:26:35,914][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T11:26:35,914][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T11:26:35,915][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T11:26:35,915][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T11:26:35,916][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T11:26:35,916][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T11:26:35,917][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T11:26:35,917][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T11:26:35,918][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T11:26:35,919][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T11:26:35,920][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T11:26:35,920][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T11:26:35,921][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T11:26:35,921][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T11:26:35,922][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T11:26:35,922][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T11:26:35,923][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T11:26:35,923][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T11:26:35,923][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T11:26:35,924][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T11:26:35,924][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T11:26:35,925][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T11:26:35,925][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T11:26:35,926][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T11:26:35,926][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T11:26:35,927][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T11:26:35,927][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T11:26:35,928][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T11:26:35,929][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T11:26:35,929][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T11:26:35,930][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T11:26:35,930][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T11:26:35,931][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T11:26:35,931][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T11:26:35,931][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T11:26:35,932][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T11:26:35,932][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T11:26:35,933][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T11:26:35,934][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T11:26:35,934][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T11:26:35,935][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T11:26:35,935][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T11:26:35,936][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T11:26:35,936][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T11:26:35,937][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T11:26:35,937][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T11:26:35,938][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T11:26:35,938][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T11:26:35,939][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T11:26:35,939][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T11:26:35,939][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T11:26:35,940][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T11:26:35,940][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T11:26:35,941][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T11:26:35,942][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T11:26:36,096][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.6gb], net total_space [125.8gb], types [ext4]
[2022-04-12T11:26:36,097][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T11:28:56,731][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-12T11:30:22,527][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9073ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:30:36,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [9073ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:32:02,899][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9073229182ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:32:33,355][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/142265ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:32:35,627][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [142264ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:32:51,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/142264924079ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:33:13,373][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.6s/44670ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:33:16,667][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [44670ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:33:30,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.6s/44670555417ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:33:49,355][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.7s/36760ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:33:52,889][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@40ab42ae, interval=1m}] took [36759ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:34:05,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.7s/36759681991ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:34:22,980][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [30680ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:34:29,033][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30681ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:34:51,043][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30680969577ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:35:10,100][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.5s/49569ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:35:18,931][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@40ab42ae, interval=1m}] took [49569ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:35:32,033][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.5s/49569145702ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:35:45,416][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [35989ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:35:44,615][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35990ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:35:56,142][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35989727866ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:36:20,289][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33803ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:36:22,010][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@40ab42ae, interval=1m}] took [33803ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:36:36,256][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33803181996ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:36:51,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33097ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:36:51,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [33097ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:37:08,562][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33097230835ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:37:22,582][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30556ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:37:37,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30555807127ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:37:56,935][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.6s/33681ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:38:15,364][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.6s/33681340181ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:38:40,141][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43833ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:38:57,024][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43832913015ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:39:09,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.4s/29419ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:39:21,244][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.4s/29418660207ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:39:34,423][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25774ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:39:38,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [25774ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:39:44,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25774308475ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:39:54,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19593ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:40:05,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19592569684ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:40:20,353][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26547ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:40:20,278][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [26547ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:40:29,387][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26547303297ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:40:40,220][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:40:50,682][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19916081470ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:41:08,664][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.5s/27554ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:41:24,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.5s/27553777567ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:41:39,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31166ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:41:52,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31166392538ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:42:04,426][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25162ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:42:15,894][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25161595355ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:42:28,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23757ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:42:40,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23757017517ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:42:53,935][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25767ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:42:55,372][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [25767ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:43:05,673][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25767321673ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:43:20,977][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [24624ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:43:19,046][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24625ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:43:33,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24624203365ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:43:48,368][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29531ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:43:53,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [29531ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:44:01,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29531213717ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:44:20,759][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [30568ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:44:20,759][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30568ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:44:38,100][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30568134793ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:44:56,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.2s/37299ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:45:10,441][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.2s/37299398215ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:45:18,730][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23351ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:45:19,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [23350ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:45:26,917][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23350160405ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:45:38,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [17971ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:45:36,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17971ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:45:51,548][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17971280094ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:46:07,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.4s/29453ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:46:21,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.4s/29452997472ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:46:37,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31236ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:46:39,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [31236ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:46:48,885][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31236248690ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:47:01,236][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.6s/22600ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:47:04,607][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [22599ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:47:14,587][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22599486864ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:47:28,727][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27330ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:47:28,727][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [27330ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:47:47,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27330096507ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:48:07,296][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37860ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:48:08,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [37860ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:48:27,390][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37860424351ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:48:44,845][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38214ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:48:45,992][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [38213ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:48:58,763][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38213972572ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:49:12,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27860ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:49:15,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@40ab42ae, interval=1m}] took [27859ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:49:26,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27859594015ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:49:40,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.2s/28206ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:49:53,596][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.2s/28206864583ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:50:09,563][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26630ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:50:31,569][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26629543317ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:50:48,413][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.2s/41248ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:50:51,593][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [41247ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:51:02,915][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.2s/41247887555ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:51:15,663][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26996ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:51:32,941][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26996497269ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:52:04,370][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.2s/44223ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:52:06,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@40ab42ae, interval=1m}] took [44222ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:52:29,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.2s/44222987910ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:53:12,578][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70141ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:53:21,996][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [70140ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:54:33,979][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70140925960ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:55:21,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/128000ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:55:45,322][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127999717900ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:56:12,350][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.2s/52277ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:56:14,050][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [52276ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:56:44,492][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.2s/52276689776ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:57:08,790][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.4s/56451ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:57:38,021][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.4s/56451635040ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:58:07,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.7s/55717ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:58:35,166][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.7s/55716542981ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:58:57,447][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.3s/54303ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T11:59:02,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [54302ms] which is above the warn threshold of [5000ms]
[2022-04-12T11:59:17,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.3s/54302843263ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T11:59:37,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.5s/39560ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:00:00,551][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.5s/39560311134ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:00:17,545][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.3s/41329ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:00:24,774][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [41328ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:00:37,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.3s/41328727626ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:00:57,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.5s/38561ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:01:33,122][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.5s/38560857966ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:02:24,025][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76665ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:03:17,663][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76665048546ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:04:26,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/128766ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:05:03,048][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/128765966590ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:05:38,908][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73892ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:06:24,741][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73892799139ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:06:58,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80465ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:07:30,846][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80464102561ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:07:56,656][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.4s/59430ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:07:58,720][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [59430ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:08:28,369][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.4s/59430668064ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:08:57,907][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.3s/59351ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:09:15,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.3s/59350399261ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:09:31,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35975ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:09:50,461][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35974995534ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:10:10,582][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37723ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:10:31,094][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37723201547ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:10:52,786][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44s/44075ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:11:06,192][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44s/44075075897ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:11:26,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.9s/32951ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:11:54,664][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.9s/32950618462ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:12:37,986][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70503ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:12:39,616][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [70503ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:13:21,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70503131925ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:13:59,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [78340ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:13:58,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78341ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:14:38,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78340946426ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:15:27,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87879ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:15:38,071][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [87879ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:16:19,668][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87879011104ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:17:09,517][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91846ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:17:13,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [91846ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:18:04,110][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91846273773ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:19:42,480][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/159744ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:19:55,991][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@40ab42ae, interval=1m}] took [159743ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:21:08,608][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/159743690818ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:21:43,657][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126428ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:22:22,491][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126428440165ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:22:53,711][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70816ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:23:34,066][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70815911139ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:24:07,103][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73640ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:24:58,887][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73640117604ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:25:45,835][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97499ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:25:54,099][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [97499ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:26:29,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97499154134ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:27:55,508][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/128481ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:29:12,385][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/128480674216ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:30:02,100][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127849ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:30:51,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127848838346ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:31:40,465][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6bf11951, interval=5s}] took [95946ms] which is above the warn threshold of [5000ms]
[2022-04-12T12:31:36,868][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95947ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:32:20,006][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95946863625ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:33:25,249][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/107516ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:34:25,124][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/107516773783ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T12:35:17,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/112303ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T12:35:23,510][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4119829, interval=30s}] took [112302ms] which is above the warn threshold of [5000ms]
