[2022-03-26T16:25:49,201][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-19-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-26T16:25:49,246][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-26T16:25:49,250][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-26T16:26:06,049][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-26T16:26:06,054][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-26T16:26:06,058][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-26T16:26:06,058][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-26T16:26:06,085][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-26T16:26:06,086][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-26T16:26:06,086][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-26T16:26:06,087][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-26T16:26:06,087][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-26T16:26:06,088][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-26T16:26:06,088][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-26T16:26:06,088][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-26T16:26:06,089][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-26T16:26:06,110][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-26T16:26:06,118][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-26T16:26:06,118][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-26T16:26:06,119][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-26T16:26:06,125][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-26T16:26:06,129][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-26T16:26:06,130][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-26T16:26:06,133][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-26T16:26:06,134][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-26T16:26:06,135][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-26T16:26:06,135][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-26T16:26:06,145][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-26T16:26:06,149][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-26T16:26:06,150][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-26T16:26:06,151][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-26T16:26:06,151][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-26T16:26:06,152][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-26T16:26:06,157][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-26T16:26:06,158][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-26T16:26:06,159][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-26T16:26:06,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-26T16:26:06,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-26T16:26:06,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-26T16:26:06,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-26T16:26:06,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-26T16:26:06,181][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-26T16:26:06,182][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-26T16:26:06,183][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-26T16:26:06,183][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-26T16:26:06,184][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-26T16:26:06,184][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-26T16:26:06,185][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-26T16:26:06,185][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-26T16:26:06,186][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-26T16:26:06,189][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-26T16:26:06,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-26T16:26:06,198][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-26T16:26:06,199][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-26T16:26:06,199][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-26T16:26:06,205][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-26T16:26:06,206][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-26T16:26:06,207][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-26T16:26:06,209][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-26T16:26:06,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-26T16:26:06,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-26T16:26:06,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-26T16:26:06,454][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.8gb], net total_space [125.8gb], types [ext4]
[2022-03-26T16:26:06,474][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-26T16:26:07,152][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-26T16:26:31,570][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-26T16:26:31,573][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-26T16:26:33,902][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-03-26T16:26:34,163][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-03-26T16:26:35,712][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-03-26T16:26:37,254][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-03-26T16:26:37,260][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-03-26T16:26:37,309][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-03-26T16:26:37,311][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-03-26T16:26:37,699][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-03-26T16:26:41,375][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-03-26T16:26:41,750][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 124, version: 3565, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-03-26T16:26:42,071][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 124, version: 3565, reason: Publication{term=124, version=3565}
[2022-03-26T16:26:42,244][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-03-26T16:26:42,250][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-03-26T16:26:44,781][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-03-26T16:26:44,789][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [29] indices into cluster_state
[2022-03-26T16:26:46,266][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-03-26T16:26:46,267][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-03-26T16:26:47,998][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-03-26T16:26:48,205][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-03-26T16:26:48,761][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-03-26T16:26:48,763][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-03-26T16:26:48,764][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-03-26T16:26:49,005][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-03-26T16:26:50,615][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-03-26T16:26:50,791][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-03-26T16:26:59,814][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-03-26T16:27:14,473][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][37] overhead, spent [292ms] collecting in the last [1s]
[2022-03-26T16:27:19,460][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-03-26T16:27:20,112][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-03-26T16:27:40,882][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.03.26][0]]]).
[2022-03-26T16:28:26,215][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 560 finished with response BulkByScrollResponse[took=230.2ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-03-26T16:28:28,850][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 585 finished with response BulkByScrollResponse[took=2.3s,timed_out=false,sliceId=null,updated=1040,created=0,deleted=0,batches=2,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-03-26T16:28:40,182][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-03-26T16:37:02,142][INFO ][o.e.c.m.MetadataDeleteIndexService] [tpotcluster-node-01] [logstash-1970.01.01/IhtdAHSoQaOsAEFxa1SkoQ] deleting index
[2022-03-26T16:40:24,440][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T16:46:04,234][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T16:47:53,202][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T16:57:46,413][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T17:04:21,681][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-1970.01.01] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-03-26T17:04:21,885][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-1970.01.01][0]]]).
[2022-03-26T17:04:21,993][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-1970.01.01/gy2Gp38tSFKDQsPqLiQS_A] update_mapping [_doc]
[2022-03-26T17:17:17,338][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T17:21:45,354][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T17:21:46,021][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T17:25:48,517][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T17:25:51,512][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T18:01:41,367][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.26/HPB6fZf2RRqxlSCxE9k2Cg] update_mapping [_doc]
[2022-03-26T18:23:55,073][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [6219ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:24:46,020][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7020][134] duration [950ms], collections [1]/[2.5s], total [950ms]/[6.8s], memory [1.3gb]->[192.6mb]/[2gb], all_pools {[young] [1.1gb]->[16mb]/[0b]}{[old] [185.6mb]->[185.6mb]/[2gb]}{[survivor] [4.5mb]->[6.9mb]/[0b]}
[2022-03-26T18:24:47,500][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][7020] overhead, spent [950ms] collecting in the last [2.5s]
[2022-03-26T18:24:49,009][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [18109ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:24:57,757][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7021][135] duration [3.3s], collections [1]/[19s], total [3.3s]/[10.1s], memory [192.6mb]->[268.6mb]/[2gb], all_pools {[young] [16mb]->[40mb]/[0b]}{[old] [185.6mb]->[185.6mb]/[2gb]}{[survivor] [6.9mb]->[8mb]/[0b]}
[2022-03-26T18:24:58,983][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [7570ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:24:57,754][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [5624ms] which is above the warn threshold of [5s]
[2022-03-26T18:25:05,762][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7022][136] duration [2.9s], collections [1]/[13.2s], total [2.9s]/[13s], memory [268.6mb]->[196.5mb]/[2gb], all_pools {[young] [40mb]->[8mb]/[0b]}{[old] [185.6mb]->[185.6mb]/[2gb]}{[survivor] [8mb]->[6.8mb]/[0b]}
[2022-03-26T18:25:28,427][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7029][137] duration [3.2s], collections [1]/[1.9s], total [3.2s]/[16.3s], memory [272.5mb]->[276.5mb]/[2gb], all_pools {[young] [80mb]->[0b]/[0b]}{[old] [185.6mb]->[185.6mb]/[2gb]}{[survivor] [6.8mb]->[8.6mb]/[0b]}
[2022-03-26T18:25:30,766][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][7029] overhead, spent [3.2s] collecting in the last [1.9s]
[2022-03-26T18:25:32,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [11629ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:25:46,217][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7033][138] duration [2s], collections [1]/[4.9s], total [2s]/[18.4s], memory [198.3mb]->[193.3mb]/[2gb], all_pools {[young] [24mb]->[0b]/[0b]}{[old] [185.6mb]->[186.1mb]/[2gb]}{[survivor] [8.6mb]->[7.1mb]/[0b]}
[2022-03-26T18:25:47,350][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][7033] overhead, spent [2s] collecting in the last [4.9s]
[2022-03-26T18:26:28,284][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [19678ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:26:33,337][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16386ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:28:19,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16386676336ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:28:33,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.2m/132161ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:28:40,687][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.2m/132161286409ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:28:00,286][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [41.8s/41868ms] ago, timed out [26.4s/26480ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [52354]
[2022-03-26T18:29:00,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.1s/30140ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:04,517][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.1s/30139118343ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:04,585][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [30139ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:29:11,686][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2s/11206ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:16,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2s/11206550439ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:23,290][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.4s/11417ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:28,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.4s/11416376921ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:34,855][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.7s/11767ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:38,423][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.7s/11767135632ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:42,894][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.3s/8370ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:43,856][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [11767ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:29:49,701][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.3s/8370569312ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:29:37,306][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [11767ms] which is above the warn threshold of [5s]
[2022-03-26T18:29:58,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15401ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:03,469][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15401025103ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:04,173][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [15401ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:30:10,954][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12369ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:25,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12368811831ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:33,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22885ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:40,685][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22885087006ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:47,216][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13308ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:30:53,764][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13308107917ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:31:01,613][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14811ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:31:01,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [13308ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:31:11,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14810902061ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:31:28,220][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26386ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:31:28,220][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@29cee04a, interval=5s}] took [26385ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:31:45,176][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26385440013ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:31:56,200][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26377ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:31:33,080][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [52354] timed out after [15388ms]
[2022-03-26T18:32:02,089][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26377521079ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:15,140][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@29cee04a, interval=5s}] took [14737ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:32:09,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14737ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:23,574][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14737333951ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:30,852][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.2s/21209ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:35,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.2s/21208348348ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:35,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [21208ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:32:43,349][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13020ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:43,202][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41268}] took [21208ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:32:53,551][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13020017529ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:32:59,681][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16051ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:33:13,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [16050ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:34:27,183][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16050902679ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:37:04,515][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/243183ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:38:45,639][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@29cee04a, interval=5s}] took [243183ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:40:18,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/243183614620ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:42:59,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/355408ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:44:36,381][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/354896432786ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:44:55,096][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [10.2m/614131ms] ago, timed out [5.9m/354896ms] ago, action [cluster:monitor/nodes/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [52540]
[2022-03-26T18:44:55,068][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/117093ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:44:58,841][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/117604661023ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:45:03,501][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.3s/8329ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:45:06,223][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.3s/8328980336ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:44:58,105][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve stats for node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][cluster:monitor/nodes/stats[n]] request_id [52540] timed out after [259235ms]
[2022-03-26T18:45:09,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5645ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:45:03,234][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [52541] timed out after [259235ms]
[2022-03-26T18:45:17,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [5644ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:45:19,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5644319831ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:45:34,695][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25119ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:45:46,779][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25119179013ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:45:59,070][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23372ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:04,761][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [23373ms] which is above the warn threshold of [5s]
[2022-03-26T18:46:04,398][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23372159884ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:10,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.4s/12446ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:12,184][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [12446ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:46:13,324][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.4s/12446367426ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:15,420][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5177ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:18,863][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5176432957ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:22,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1s/7179ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:14,513][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [13.4m/806647ms] ago, timed out [9.1m/547412ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [52541]
[2022-03-26T18:46:25,056][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1s/7179130981ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:25,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [7179ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:46:30,218][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.7s/7794ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:32,903][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.7s/7793519162ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:46:38,277][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [7804ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:46:37,944][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8s/7804ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:50:12,217][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8s/7804422317ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:50:29,421][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/230759ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:50:40,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/230759255415ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:50:53,024][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23933ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:05,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23932364937ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:18,996][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21472ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:30,484][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21472000930ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:36,382][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7054][139] duration [3.2m], collections [1]/[3.7m], total [3.2m]/[3.5m], memory [265.3mb]->[225.5mb]/[2gb], all_pools {[young] [76mb]->[56mb]/[0b]}{[old] [186.1mb]->[186.1mb]/[2gb]}{[survivor] [7.1mb]->[7.3mb]/[0b]}
[2022-03-26T18:51:46,572][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32205ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:48,142][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][7054] overhead, spent [3.2m] collecting in the last [3.7m]
[2022-03-26T18:51:50,265][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32205760197ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:53,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6841ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:51:52,913][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [308369ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:51:58,762][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6840857543ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:04,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10474ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:11,141][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10473664508ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:20,383][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@29cee04a, interval=5s}] took [14383ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:52:20,309][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14384ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:27,701][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14383724608ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:34,282][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15880ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:39,529][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15880410284ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:40,716][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [15880ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:52:23,588][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14384ms] which is above the warn threshold of [5s]
[2022-03-26T18:53:18,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9993ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:52:48,958][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@29cee04a, interval=5s}] took [9993ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:52:38,656][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [52607] timed out after [325684ms]
[2022-03-26T18:53:26,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9993089939ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:53:34,280][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.9s/49917ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:53:39,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.9s/49917143285ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:53:48,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14365ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:53:56,320][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14364398548ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:01,768][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][7057][140] duration [18.4s], collections [1]/[1.1m], total [18.4s]/[3.8m], memory [253.5mb]->[192.1mb]/[2gb], all_pools {[young] [60mb]->[4mb]/[0b]}{[old] [186.1mb]->[186.1mb]/[2gb]}{[survivor] [7.3mb]->[5.9mb]/[0b]}
[2022-03-26T18:54:03,620][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14435ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:07,648][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][7057] overhead, spent [18.4s] collecting in the last [1.1m]
[2022-03-26T18:54:09,085][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14435512579ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:14,108][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [28799ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:54:15,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12797ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:22,450][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12797027067ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:28,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.5s/12534ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:38,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.5s/12534021064ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:54:47,998][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19676ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:55:01,608][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19675546021ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:55:09,104][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [19675ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:55:10,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21942ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:55:19,552][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [8.5m/511608ms] ago, timed out [3m/185924ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [52607]
[2022-03-26T18:55:19,036][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21942627795ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:55:34,395][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [23663ms] which is above the warn threshold of [5s]
[2022-03-26T18:55:34,395][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23663ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:55:52,952][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23663039834ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:56:11,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38363ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:56:22,289][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [38362ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:56:32,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38362763270ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:56:46,940][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33855ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:56:57,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33854889527ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:57:07,467][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.8s/19861ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:57:19,071][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.8s/19861260895ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:56:56,244][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [52699] timed out after [41618ms]
[2022-03-26T18:57:30,400][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.2s/24260ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:57:40,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.2s/24260027462ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:57:56,203][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25396ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:58:11,754][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25395729936ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:58:24,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28713ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:58:38,654][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28713390533ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:58:54,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28s/28046ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:59:01,488][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [56758ms] which is above the warn threshold of [5000ms]
[2022-03-26T18:59:08,490][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28s/28045202295ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:59:22,726][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28866ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:59:39,312][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28865897726ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T18:59:52,618][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.3s/31382ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T18:59:59,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.3s/31381984912ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:00:09,957][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17354ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:00:20,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17354519639ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:00:33,265][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [38381ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:00:32,256][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21027ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:00:43,593][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21027075162ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:00:54,999][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23455ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:01:06,536][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23454944418ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:01:18,737][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [46983ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:01:19,541][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23528ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:01:32,297][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23528086617ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:01:43,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26048ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:01:48,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@125b07d0] took [26047ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:01:56,962][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26047968685ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:02:10,995][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26310ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:02:12,257][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5098/0x00000008017df048@4fc2682a] took [26309ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:02:22,376][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26309766149ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:02:34,251][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [7.6m/461744ms] ago, timed out [7m/420126ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{mZGL32cVRY2WNdwoltgwhw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [52699]
[2022-03-26T19:02:36,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26129ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:02:46,578][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26128595037ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:02:57,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [26128ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:02:58,849][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22325ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:03:13,644][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22325156309ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:03:25,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26699ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:03:42,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.6s/26699154047ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:03:58,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32264ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:04:00,310][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [32264ms] which is above the warn threshold of [5s]
[2022-03-26T19:04:10,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32264072190ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:04:21,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23490ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:04:35,103][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23490192479ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:04:52,281][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [50930ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:04:50,019][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27441ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:05:08,961][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27440763936ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:05:20,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.6s/31630ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:05:31,372][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.6s/31629737993ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:05:45,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24691ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:05:56,574][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24691826344ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:06:13,348][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27876ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:06:28,537][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27875761691ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:06:42,803][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [27875ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:06:48,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34313ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:07:00,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34312485440ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:07:12,318][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.5s/25581ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:07:30,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.5s/25580844266ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:07:53,776][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.7s/39788ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:08:11,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.7s/39788741365ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:08:21,400][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [39788ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:08:28,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33894ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:08:41,440][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33893548691ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:08:53,678][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.8s/26804ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:08:15,140][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [52800] timed out after [118510ms]
[2022-03-26T19:09:12,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.8s/26803786183ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:09:28,690][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35255ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:09:40,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35254984600ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:09:55,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26072ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:10:12,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26072688277ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:10:25,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.7s/30789ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:10:48,957][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.7s/30788411819ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:10:52,039][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1dcfc32, interval=1s}] took [30788ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:10:59,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.6s/33663ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:11:09,130][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@29cee04a, interval=5s}] took [33663ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:11:10,788][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.6s/33663390195ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:11:20,952][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21755ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:12:36,938][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-19-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-26T19:12:37,003][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-26T19:12:37,005][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-26T19:12:45,286][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-26T19:12:45,289][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-26T19:12:45,291][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-26T19:12:45,292][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-26T19:12:45,292][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-26T19:12:45,293][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-26T19:12:45,293][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-26T19:12:45,294][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-26T19:12:45,294][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-26T19:12:45,294][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-26T19:12:45,295][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-26T19:12:45,295][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-26T19:12:45,296][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-26T19:12:45,296][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-26T19:12:45,297][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-26T19:12:45,297][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-26T19:12:45,298][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-26T19:12:45,298][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-26T19:12:45,299][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-26T19:12:45,299][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-26T19:12:45,300][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-26T19:12:45,301][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-26T19:12:45,301][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-26T19:12:45,302][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-26T19:12:45,303][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-26T19:12:45,303][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-26T19:12:45,304][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-26T19:12:45,304][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-26T19:12:45,305][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-26T19:12:45,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-26T19:12:45,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-26T19:12:45,307][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-26T19:12:45,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-26T19:12:45,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-26T19:12:45,309][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-26T19:12:45,310][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-26T19:12:45,311][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-26T19:12:45,312][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-26T19:12:45,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-26T19:12:45,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-26T19:12:45,314][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-26T19:12:45,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-26T19:12:45,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-26T19:12:45,316][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-26T19:12:45,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-26T19:12:45,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-26T19:12:45,318][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-26T19:12:45,318][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-26T19:12:45,319][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-26T19:12:45,319][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-26T19:12:45,320][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-26T19:12:45,320][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-26T19:12:45,321][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-26T19:12:45,321][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-26T19:12:45,322][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-26T19:12:45,323][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-26T19:12:45,323][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-26T19:12:45,324][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-26T19:12:45,325][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-26T19:12:45,448][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.6gb], net total_space [125.8gb], types [ext4]
[2022-03-26T19:12:45,450][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-26T19:12:45,916][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-26T19:13:16,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5s/6550ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:13:28,389][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5s/6550196620ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:13:31,201][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19434ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:13:35,355][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19433699659ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:13:35,246][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@4293c20, interval=5s}] took [19433ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:13:36,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5784ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:13:37,198][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5783967110ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:15:03,039][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@4293c20, interval=5s}] took [27261ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:17:43,028][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3s/6381ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:17:03,250][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@293d6e43, interval=5s}] took [13842ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:18:36,938][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2s/6261911990ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:18:42,284][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/110060ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:18:48,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/110178381554ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:18:53,502][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10932ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:19:06,065][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10932797260ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:19:08,390][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15488ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:19:08,875][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15487409870ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:19:14,254][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-26T19:19:14,265][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-03-26T19:19:14,269][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-03-26T19:19:14,273][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-03-26T19:19:14,276][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-26T19:19:14,279][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-03-26T19:19:14,280][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-03-26T19:19:14,281][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-26T19:19:14,283][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-03-26T19:19:14,290][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-03-26T19:19:14,291][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-03-26T19:19:14,291][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-03-26T19:19:14,293][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-03-26T19:19:14,293][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-26T19:19:14,295][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-26T19:19:15,771][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-03-26T19:19:16,070][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-03-26T19:19:19,328][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-03-26T19:21:21,082][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-03-26T19:21:21,091][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-03-26T19:21:21,213][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-03-26T19:21:21,216][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-03-26T19:21:21,518][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-03-26T19:21:24,312][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-03-26T19:21:24,514][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{J4_GpKBzS86U_hXhAhpsyw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 125, version: 3634, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{J4_GpKBzS86U_hXhAhpsyw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-03-26T19:21:24,718][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{J4_GpKBzS86U_hXhAhpsyw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 125, version: 3634, reason: Publication{term=125, version=3634}
[2022-03-26T19:21:24,891][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-03-26T19:21:24,891][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-03-26T19:21:41,077][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7061ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:21:43,335][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7060978377ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:21:42,891][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1b452107, interval=1s}] took [14260ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:22:01,778][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1b452107, interval=1s}] took [7399ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:23:00,745][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7936ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:07,141][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7935991451ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:11,377][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.1s/12137ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:15,986][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.1s/12137084900ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:22,530][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.6s/10688ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:26,335][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.6s/10688555031ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:33,255][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10495ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:39,218][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4s/10494545555ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:44,695][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.8s/11856ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:49,925][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.8s/11856139433ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:54,316][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.8s/9849ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:23:59,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.8s/9848873960ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:06,278][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.8s/11805ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:17,569][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.8s/11804818621ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:25,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19643ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:31,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19643205840ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:36,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8s/10856ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:40,754][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8s/10855649212ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:45,465][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.9s/8949ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:48,999][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.9s/8949414979ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:52,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2s/7250ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:55,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2s/7249515346ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:24:58,590][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6s/6026ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:02,725][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6s/6026563257ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:12,192][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13603ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:17,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13602750190ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:21,654][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9009ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:28,103][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9009380377ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:36,046][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14408ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:42,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14407428664ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:49,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.8s/13848ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:25:56,017][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.8s/13848540433ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:04,931][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14687ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:12,290][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14686981265ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:21,718][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16896ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:28,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16895735704ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:35,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.1s/14122ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:44,566][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.1s/14121937213ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:26:54,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18667ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:01,355][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18666974601ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:09,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14072ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:17,660][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14072464007ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:25,842][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17002ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:34,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17001508853ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:42,265][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16254ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:50,925][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16254246522ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:27:59,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18049ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:09,312][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18048394552ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:19,292][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19353ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:27,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19353825358ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:37,411][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18329ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:44,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18328502739ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:53,039][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.5s/15577ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:29:01,680][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.5s/15577074060ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:28:42,850][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:45048}] took [375336ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:29:09,398][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16245ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:29:22,295][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16244688645ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:29:33,631][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24428ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:29:41,943][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24428145329ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:29:49,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15943ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:30:05,879][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15943023221ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:30:17,905][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27093ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:30:27,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27092846160ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:30:41,550][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.8s/23840ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:30:50,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.8s/23840754399ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:30:58,846][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18146ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:31:06,674][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18145247188ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:31:18,431][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.8s/18820ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:31:24,381][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.8s/18820439548ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:31:34,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16596ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:31:44,484][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16596374151ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:31:55,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.3s/20345ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:07,046][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.3s/20344323804ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:15,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.5s/20543ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:23,295][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.5s/20543740554ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:30,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15458ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:37,582][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15457079771ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:45,900][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15466ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:52,544][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15466164461ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:32:59,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13120ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:33:07,416][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13120033059ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:33:14,615][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.1s/15165ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:33:22,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.1s/15165486478ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:33:30,874][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16536ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:33:38,645][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16536094193ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:33:44,443][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13690ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:02,232][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13689830792ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:08,604][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5106/0x00000008017d94b0@5e577ddd] took [698874ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:34:08,676][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24949ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:15,229][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24948767497ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:19,305][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.1s/10131ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:13,375][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_cat/health][Netty4HttpChannel{localAddress=/127.0.0.1:9200, remoteAddress=/127.0.0.1:40238}] took [734826ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:34:26,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.1s/10130803613ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:31,575][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12326ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:34,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1b452107, interval=1s}] took [12326ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:34:37,951][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.3s/12326631908ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:42,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@21ed9a54] took [10945ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:34:43,663][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10946ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:48,568][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9s/10945404599ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:34:55,149][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.6s/11626ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:40:48,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.6s/11625898900ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:40:53,772][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1b452107, interval=1s}] took [11625ms] which is above the warn threshold of [5000ms]
[2022-03-26T19:43:39,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4m/508990ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:46:30,416][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4m/508600795910ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:52:11,555][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6m/517574ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:54:51,701][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6m/517711129657ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T19:57:49,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/317142ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T19:51:54,291][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [520227ms] which is above the warn threshold of [5s]
[2022-03-26T20:00:33,614][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/317391596714ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:03:27,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356881ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:06:20,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356755979726ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:09:14,193][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/349988ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:12:13,875][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/349974650571ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:15:11,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356604ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:17:58,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356369619562ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:20:58,718][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/340564ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:23:48,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/340568526269ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:26:27,222][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/332949ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:29:12,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/333193842906ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:32:42,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6m/360497ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:35:46,592][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6m/360136786508ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:43:48,804][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-19-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-26T20:43:48,835][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-26T20:43:48,838][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-26T20:43:56,760][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-26T20:43:56,766][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-26T20:43:56,768][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-26T20:43:56,769][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-26T20:43:56,771][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-26T20:43:56,772][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-26T20:43:56,772][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-26T20:43:56,773][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-26T20:43:56,774][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-26T20:43:56,775][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-26T20:43:56,776][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-26T20:43:56,777][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-26T20:43:56,778][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-26T20:43:56,779][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-26T20:43:56,781][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-26T20:43:56,782][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-26T20:43:56,783][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-26T20:43:56,784][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-26T20:43:56,784][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-26T20:43:56,788][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-26T20:43:56,788][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-26T20:43:56,789][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-26T20:43:56,790][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-26T20:43:56,791][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-26T20:43:56,793][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-26T20:43:56,793][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-26T20:43:56,794][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-26T20:43:56,795][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-26T20:43:56,795][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-26T20:43:56,797][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-26T20:43:56,798][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-26T20:43:56,799][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-26T20:43:56,801][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-26T20:43:56,801][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-26T20:43:56,803][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-26T20:43:56,803][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-26T20:43:56,804][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-26T20:43:56,805][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-26T20:43:56,808][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-26T20:43:56,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-26T20:43:56,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-26T20:43:56,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-26T20:43:56,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-26T20:43:56,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-26T20:43:56,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-26T20:43:56,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-26T20:43:56,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-26T20:43:56,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-26T20:43:56,820][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-26T20:43:56,821][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-26T20:43:56,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-26T20:43:56,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-26T20:43:56,823][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-26T20:43:56,824][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-26T20:43:56,826][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-26T20:43:56,828][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-26T20:43:56,828][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-26T20:43:56,829][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-26T20:43:56,830][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-26T20:43:57,010][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.7gb], net total_space [125.8gb], types [ext4]
[2022-03-26T20:43:57,014][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-26T20:43:57,507][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-26T20:45:17,065][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@63d02946, interval=5s}] took [5053ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:45:17,065][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.7s/8766ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:45:25,314][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.7s/8766057293ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:45:26,923][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24952ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:45:28,188][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24952710502ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:45:56,541][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-26T20:45:56,549][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-26T20:45:58,068][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-03-26T20:45:58,331][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-03-26T20:45:59,752][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-03-26T20:46:00,811][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-03-26T20:46:00,812][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-03-26T20:46:00,906][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-03-26T20:46:00,909][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-03-26T20:46:01,234][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-03-26T20:46:03,680][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-03-26T20:46:03,843][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{qHh-0D5WQ7--Zc8TXbrLIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 126, version: 3636, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{qHh-0D5WQ7--Zc8TXbrLIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-03-26T20:46:04,165][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{qHh-0D5WQ7--Zc8TXbrLIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 126, version: 3636, reason: Publication{term=126, version=3636}
[2022-03-26T20:46:04,449][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-03-26T20:46:04,453][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-03-26T20:46:08,284][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-03-26T20:46:08,355][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [29] indices into cluster_state
[2022-03-26T20:46:23,765][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [13.8s] publication of cluster state version [3638] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{qHh-0D5WQ7--Zc8TXbrLIw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-03-26T20:46:51,088][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5099/0x00000008017e1bb8@6b2e6534] took [11643ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:46:56,948][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:45444}] took [8133ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:47:23,984][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_cat/health][Netty4HttpChannel{localAddress=/127.0.0.1:9200, remoteAddress=/127.0.0.1:40648}] took [10007ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:48:10,994][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [6783ms] which is above the warn threshold of [5s]
[2022-03-26T20:48:38,196][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [9325ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:49:14,342][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:45458}] took [16687ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:49:57,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5099/0x00000008017e1bb8@52fcd29a] took [74248ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:50:12,247][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [7004ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:50:31,188][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [5404ms] which is above the warn threshold of [5s]
[2022-03-26T20:51:02,216][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5099/0x00000008017e1bb8@9ff1c23] took [32057ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:52:47,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5099/0x00000008017e1bb8@5ef9f710] took [6342ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:53:32,605][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [5318ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:54:00,577][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=126, version=3638}] took [7.1m] which is above the warn threshold of [30s]: [running task [Publication{term=126, version=3638}]] took [18ms], [connecting to new nodes] took [0ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@4627c212] took [0ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@6ee8e1c9] took [427075ms], [org.elasticsearch.script.ScriptService@6a4280fe] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@513c561f] took [0ms], [org.elasticsearch.snapshots.RestoreService@29f33978] took [0ms], [org.elasticsearch.ingest.IngestService@bc6326] took [70ms], [org.elasticsearch.action.ingest.IngestActionForwarder@7e8756bf] took [0ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4527/0x00000008016ccc80@4db87bde] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@7db0a3e8] took [31ms], [org.elasticsearch.tasks.TaskManager@1ef64a2b] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@5a80d5e4] took [29ms], [org.elasticsearch.cluster.InternalClusterInfoService@3f858f94] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@6b290296] took [0ms], [org.elasticsearch.indices.SystemIndexManager@11622613] took [525ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@4ecfcbbd] took [0ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x0000000801306e58@6040c7e9] took [62ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@4513c3b2] took [1ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@58023e74] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x0000000801406000@2acd2c11] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@2da79007] took [0ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@24c466ad] took [627ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@1e0fccc4] took [1ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@33c0e7ea] took [0ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@53c964ba] took [160ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@72c64516] took [93ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@76027d67] took [0ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@42c93bfa] took [43ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@513c561f] took [0ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@5a3d6bad] took [22ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@1a937b09] took [0ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@45d34ba5] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@437f7c32] took [1ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@591a3d6b] took [1ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@477cbbd7] took [0ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@3e0d960b] took [25ms], [org.elasticsearch.node.ResponseCollectorService@36f405c4] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@35ef7f68] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@17efc801] took [115ms], [org.elasticsearch.shutdown.PluginShutdownService@4500b939] took [0ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@26a7a6da] took [0ms], [org.elasticsearch.indices.store.IndicesStore@1b59a356] took [0ms], [org.elasticsearch.persistent.PersistentTasksNodeService@1947d5ed] took [0ms], [org.elasticsearch.license.LicenseService@4c4a67e] took [0ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@49db12e6] took [0ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@76f51521] took [0ms], [org.elasticsearch.gateway.GatewayService@495b6a41] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@dc40429] took [0ms]
[2022-03-26T20:54:01,904][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [7.8m/473374ms] which is longer than the warn threshold of [300000ms]; there are currently [2] pending tasks, the oldest of which has age [7.9m/475618ms]
[2022-03-26T20:53:59,984][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.performPhaseOnShard(AbstractSearchAsyncAction.java:320) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.run(AbstractSearchAsyncAction.java:256) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executePhase(AbstractSearchAsyncAction.java:466) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.start(AbstractSearchAsyncAction.java:211) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeSearch(TransportSearchAction.java:1048) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeLocalSearch(TransportSearchAction.java:763) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.lambda$executeRequest$6(TransportSearchAction.java:399) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:136) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.index.query.Rewriteable.rewriteAndFetch(Rewriteable.java:112) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.index.query.Rewriteable.rewriteAndFetch(Rewriteable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeRequest(TransportSearchAction.java:487) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:285) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:101) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:179) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:154) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:82) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:95) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.action.RestCancellableNodeClient.doExecute(RestCancellableNodeClient.java:81) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:407) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.action.search.RestSearchAction.lambda$prepareRequest$2(RestSearchAction.java:122) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:109) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:327) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.tryAllHandlers(RestController.java:393) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:245) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.dispatchRequest(AbstractHttpServerTransport.java:382) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.handleIncomingRequest(AbstractHttpServerTransport.java:461) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.incomingRequest(AbstractHttpServerTransport.java:357) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:32) [transport-netty4-client-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:18) [transport-netty4-client-7.17.0.jar:7.17.0]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at org.elasticsearch.http.netty4.Netty4HttpPipeliningHandler.channelRead(Netty4HttpPipeliningHandler.java:48) [transport-netty4-client-7.17.0.jar:7.17.0]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageCodec.channelRead(MessageToMessageCodec.java:111) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) [netty-handler-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:620) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:583) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) [netty-common-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.66.Final.jar:4.1.66.Final]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 79 more
[2022-03-26T20:54:00,004][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_7.17.0/_search, params: {rest_total_hits_as_int=true, size=20, index=.kibana_7.17.0, from=0}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.performPhaseOnShard(AbstractSearchAsyncAction.java:320) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.run(AbstractSearchAsyncAction.java:256) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executePhase(AbstractSearchAsyncAction.java:466) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.start(AbstractSearchAsyncAction.java:211) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeSearch(TransportSearchAction.java:1048) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeLocalSearch(TransportSearchAction.java:763) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.lambda$executeRequest$6(TransportSearchAction.java:399) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:136) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.index.query.Rewriteable.rewriteAndFetch(Rewriteable.java:112) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.index.query.Rewriteable.rewriteAndFetch(Rewriteable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeRequest(TransportSearchAction.java:487) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:285) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:101) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:179) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:154) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:82) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:95) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.action.RestCancellableNodeClient.doExecute(RestCancellableNodeClient.java:81) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:407) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.action.search.RestSearchAction.lambda$prepareRequest$2(RestSearchAction.java:122) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:109) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:327) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.tryAllHandlers(RestController.java:393) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:245) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.dispatchRequest(AbstractHttpServerTransport.java:382) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.handleIncomingRequest(AbstractHttpServerTransport.java:461) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.incomingRequest(AbstractHttpServerTransport.java:357) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:32) [transport-netty4-client-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:18) [transport-netty4-client-7.17.0.jar:7.17.0]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at org.elasticsearch.http.netty4.Netty4HttpPipeliningHandler.channelRead(Netty4HttpPipeliningHandler.java:48) [transport-netty4-client-7.17.0.jar:7.17.0]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageCodec.channelRead(MessageToMessageCodec.java:111) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) [netty-handler-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:620) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:583) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) [netty-common-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.66.Final.jar:4.1.66.Final]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 79 more
[2022-03-26T20:54:06,525][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_7.17.0/_search?from=0&rest_total_hits_as_int=true&size=20][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52548}] took [96965ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:54:06,525][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_task_manager/_search?ignore_unavailable=true&track_total_hits=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52542}] took [97966ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:54:13,544][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_task_manager/_search?ignore_unavailable=true&track_total_hits=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52552}] took [5982ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:54:13,854][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-26T20:54:16,094][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-03-26T20:54:16,640][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-03-26T20:55:21,424][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [25531ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:55:53,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.1s/14104ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:56:19,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.1s/14104282335ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:55:52,342][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [21460ms] which is above the warn threshold of [5s]
[2022-03-26T20:56:32,481][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.1s/39102ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:56:43,474][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.1s/39101408928ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:57:02,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31297ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:57:21,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31297597723ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:57:33,726][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.2s/33283ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:57:42,534][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.2s/33283176712ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:57:51,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17362ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:57:58,093][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17361682574ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:58:08,352][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17386ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:58:16,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17385795196ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:58:26,317][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5099/0x00000008017e1bb8@1b3acd2e] took [176837ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:58:25,045][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16947ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:58:32,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16947368087ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:58:42,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15732ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:58:56,672][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15732151604ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:59:10,295][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29098ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T20:59:15,836][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [29097ms] which is above the warn threshold of [5000ms]
[2022-03-26T20:59:17,540][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29097479474ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T20:59:57,857][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47952ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:09,720][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47951969464ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:20,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22837ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:32,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22837289517ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:43,034][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21373ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:57,948][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@62ba729d, interval=5s}] took [92161ms] which is above the warn threshold of [5000ms]
[2022-03-26T21:00:57,531][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:45530}] took [313628ms] which is above the warn threshold of [5000ms]
[2022-03-26T21:00:57,715][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21372576412ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:58,268][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17002ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:58,637][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17002250574ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:00:58,749][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=126, version=3640}] took [6m] which is above the warn threshold of [30s]: [running task [Publication{term=126, version=3640}]] took [0ms], [connecting to new nodes] took [26ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@4627c212] took [1ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@6ee8e1c9] took [29690ms], [org.elasticsearch.script.ScriptService@6a4280fe] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@513c561f] took [0ms], [org.elasticsearch.snapshots.RestoreService@29f33978] took [396ms], [org.elasticsearch.ingest.IngestService@bc6326] took [360ms], [org.elasticsearch.action.ingest.IngestActionForwarder@7e8756bf] took [140ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4527/0x00000008016ccc80@4db87bde] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@7db0a3e8] took [104ms], [org.elasticsearch.tasks.TaskManager@1ef64a2b] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@5a80d5e4] took [173ms], [org.elasticsearch.cluster.InternalClusterInfoService@3f858f94] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@6b290296] took [142ms], [org.elasticsearch.indices.SystemIndexManager@11622613] took [4634ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@4ecfcbbd] took [7ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x0000000801306e58@6040c7e9] took [1383ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@4513c3b2] took [215ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@58023e74] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x0000000801406000@2acd2c11] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@2da79007] took [117ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@24c466ad] took [209807ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@1e0fccc4] took [56ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@33c0e7ea] took [59ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@53c964ba] took [77715ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@72c64516] took [1227ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@76027d67] took [731ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@42c93bfa] took [32941ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@513c561f] took [0ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@5a3d6bad] took [558ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@1a937b09] took [0ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@45d34ba5] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@437f7c32] took [2ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@591a3d6b] took [26ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@477cbbd7] took [0ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@3e0d960b] took [23ms], [org.elasticsearch.node.ResponseCollectorService@36f405c4] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@35ef7f68] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@17efc801] took [0ms], [org.elasticsearch.shutdown.PluginShutdownService@4500b939] took [0ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@26a7a6da] took [0ms], [org.elasticsearch.indices.store.IndicesStore@1b59a356] took [0ms], [org.elasticsearch.persistent.PersistentTasksNodeService@1947d5ed] took [0ms], [org.elasticsearch.license.LicenseService@4c4a67e] took [0ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@49db12e6] took [0ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@76f51521] took [0ms], [org.elasticsearch.gateway.GatewayService@495b6a41] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@dc40429] took [0ms]
[2022-03-26T21:02:32,334][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5160ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:01:52,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [10733ms] which is above the warn threshold of [5000ms]
[2022-03-26T21:03:34,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5010660458ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:03:56,861][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97565ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:04:00,231][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@62ba729d, interval=5s}] took [97714ms] which is above the warn threshold of [5000ms]
[2022-03-26T21:04:35,683][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97714773845ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:05:36,915][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97780ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:07:18,974][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97779305794ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:08:29,399][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/171752ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:11:14,449][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/171752199061ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:13:53,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/322046ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:13:48,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@772193ee, interval=1s}] took [171752ms] which is above the warn threshold of [5000ms]
[2022-03-26T21:36:21,468][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/321613375081ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:41:09,155][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.2m/1635978ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:49:09,844][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.2m/1636116816193ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:51:34,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4m/625746ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T21:54:21,066][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.4m/626040262307ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T21:57:30,292][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2519779e, interval=30s}] took [339156ms] which is above the warn threshold of [5000ms]
[2022-03-26T21:57:55,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/339309ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T22:00:43,444][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/339156838516ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T22:05:26,980][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9m/479957ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T22:08:27,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9m/479959904975ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T22:11:46,814][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4m/387756ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T22:11:37,365][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:45544}] took [3402888ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:14:54,138][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4m/387480492064ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T22:25:38,210][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-19-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-26T22:25:38,324][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-26T22:25:38,327][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-26T22:32:06,585][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-26T22:32:06,593][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-26T22:32:06,594][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-26T22:32:06,596][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-26T22:32:06,598][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-26T22:32:06,600][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-26T22:32:06,601][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-26T22:32:06,602][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-26T22:32:06,603][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-26T22:32:06,604][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-26T22:32:06,605][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-26T22:32:06,606][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-26T22:32:06,607][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-26T22:32:06,608][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-26T22:32:06,609][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-26T22:32:06,618][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-26T22:32:06,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-26T22:32:06,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-26T22:32:06,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-26T22:32:06,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-26T22:32:06,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-26T22:32:06,623][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-26T22:32:06,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-26T22:32:06,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-26T22:32:06,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-26T22:32:06,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-26T22:32:06,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-26T22:32:06,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-26T22:32:06,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-26T22:32:06,628][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-26T22:32:06,628][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-26T22:32:06,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-26T22:32:06,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-26T22:32:06,630][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-26T22:32:06,631][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-26T22:32:06,631][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-26T22:32:06,632][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-26T22:32:06,632][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-26T22:32:06,633][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-26T22:32:06,633][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-26T22:32:06,634][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-26T22:32:06,634][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-26T22:32:06,635][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-26T22:32:06,635][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-26T22:32:06,636][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-26T22:32:06,636][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-26T22:32:06,637][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-26T22:32:06,638][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-26T22:32:06,638][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-26T22:32:06,639][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-26T22:32:06,639][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-26T22:32:06,640][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-26T22:32:06,640][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-26T22:32:06,641][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-26T22:32:06,641][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-26T22:32:06,642][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-26T22:32:06,642][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-26T22:32:06,643][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-26T22:32:06,644][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-26T22:32:06,793][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.7gb], net total_space [125.8gb], types [ext4]
[2022-03-26T22:32:06,795][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-26T22:32:07,206][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-26T22:33:36,327][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-26T22:33:36,414][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-26T22:35:14,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5916ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:37:36,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [11017ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:38:59,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5026ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:39:19,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [7872ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:39:49,441][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [7508ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:40:36,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [6417ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:40:52,833][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5375ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:41:34,976][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [6086ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:47:03,033][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [7439ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:47:27,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5586ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:48:09,618][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5608ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:48:28,337][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5838ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:48:51,247][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [6384ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:49:23,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [6510ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:49:59,802][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5336ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:50:19,561][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5072ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:51:28,301][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [6869ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:51:50,651][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [7137ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:52:13,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5728ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:52:56,343][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [8591ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:53:18,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5877ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:53:42,613][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5813ms] which is above the warn threshold of [5000ms]
[2022-03-26T22:51:42,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@2d6fdc14] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-03-26T22:59:12,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5838ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:01:46,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5956ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:02:55,465][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5108ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:06:13,486][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5185ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:06:59,181][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5604ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:07:33,006][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2d95d4b1, interval=1m}] took [7360ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:08:08,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [6945ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:08:52,935][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [5459ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:09:22,921][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [5065ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:11:32,810][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [6675ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:11:33,237][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@2d6fdc14] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-03-26T23:12:38,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [13838ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:12:42,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12712ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:05,247][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12711465791ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:15,047][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [35906ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:13:13,472][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35906ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:20,428][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35906407532ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:29,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15409ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:36,723][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.4s/15408774291ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:45,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16299ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:50,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.2s/16299273583ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:48,001][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [16299ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:13:58,540][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13444ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:13:58,540][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2d95d4b1, interval=1m}] took [13444ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:14:10,721][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13444273015ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:14:20,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec73ce, interval=30s}] took [20973ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:14:19,942][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.9s/20974ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:14:27,250][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.9s/20973877190ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:14:34,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15330ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:14:38,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [15329ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:14:41,204][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15329604029ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:14:48,176][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13615ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:14:50,793][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [13615ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:15:08,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.6s/13615468218ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:15:29,537][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.6s/38672ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:15:37,148][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [38671ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:15:48,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.6s/38671858335ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:16:10,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [39802ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:16:08,532][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.8s/39803ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:16:36,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.8s/39802727039ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:16:55,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [46481ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:16:55,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.4s/46481ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:17:15,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.4s/46481266083ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:17:36,281][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40341ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:17:43,816][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [40341ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:17:54,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40341067090ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:18:09,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34193ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:18:20,047][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [34192ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:18:24,998][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34192974456ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:18:43,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34341ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:18:45,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [34340ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:19:01,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34340517892ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:19:24,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40682ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:19:24,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [40682ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:19:39,878][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40682147887ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:19:50,686][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.5s/27580ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:19:53,614][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [27579ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:20:02,158][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.5s/27579811201ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:20:13,339][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22574ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:20:16,720][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [22574ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:20:24,680][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22574028808ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:20:35,549][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21491ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:20:45,512][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21491122880ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:20:46,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [21491ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:20:57,340][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.9s/20962ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:21:07,811][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.9s/20962407295ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:21:21,903][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24540ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:21:32,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24540104080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:21:40,235][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20083ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:21:42,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [20082ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:21:48,193][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20082233213ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:21:54,314][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14317ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:22:01,657][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14317848865ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:22:08,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.5s/13581ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:22:11,617][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [13580ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:22:19,028][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.5s/13580434384ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:22:29,892][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.9s/20980ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:22:33,389][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [20980ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:22:40,369][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.9s/20980572851ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:22:53,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [21788ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:22:51,364][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21789ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:23:10,285][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21788813044ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:23:24,745][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.9s/32908ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:23:27,891][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [32907ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:23:43,896][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.9s/32907546331ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:23:56,447][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.6s/31604ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:23:59,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [31604ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:24:10,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.6s/31604742398ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:24:29,221][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31489ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:24:35,073][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [31488ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:24:44,271][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31488867833ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:24:58,341][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.6s/29622ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:24:59,554][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [29621ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:25:09,122][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.6s/29621328099ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:25:21,539][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23522ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:25:20,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [23522ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:25:32,850][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23522409269ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:25:45,828][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24180ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:25:53,131][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [24179ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:26:01,791][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24179785612ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:26:19,557][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.6s/32677ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:26:20,390][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [32677ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:26:35,147][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.6s/32677621290ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:26:50,296][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.5s/31533ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:26:53,058][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [31532ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:27:05,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.5s/31532811627ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:27:22,269][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.4s/32480ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:27:22,269][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [32480ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:27:34,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.4s/32480121230ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:27:45,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23654ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:27:45,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [23653ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:27:56,373][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23653327888ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:28:05,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19520ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:28:13,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19520721722ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:27:47,338][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@2d6fdc14] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-03-26T23:28:28,167][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22551ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:28:30,345][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [22550ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:28:36,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22550831035ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:28:47,706][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21316ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:28:55,724][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21316008806ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:29:08,980][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20070ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:29:13,017][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [20070ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:29:24,670][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20070093427ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:29:43,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.5s/33501ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:29:47,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [33500ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:30:08,339][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.5s/33500664144ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:30:23,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.1s/41147ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:30:24,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [41147ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:30:39,578][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.1s/41147325256ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:31:00,515][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.7s/34700ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:31:04,461][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [34700ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:31:18,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.7s/34700068022ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:31:39,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40688ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:31:44,880][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec73ce, interval=30s}] took [40687ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:32:11,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40687349770ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:32:27,646][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.8s/47804ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:32:29,184][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [47803ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:32:42,898][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.8s/47803821543ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:32:58,871][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29026ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:33:14,425][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29026795152ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:33:31,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33787ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:33:33,556][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [33786ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:33:44,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33786946960ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:34:01,437][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30647ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:34:15,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30646852972ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:34:27,690][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27763ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:34:29,752][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [27762ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:34:39,163][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27762449947ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:34:52,177][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23149ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:34:54,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [23149ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:35:07,912][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23149332077ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:35:23,313][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [32027ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:35:23,313][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32s/32028ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:35:38,354][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32s/32027557562ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:35:51,794][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27457ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:35:52,325][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [27457ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:36:03,841][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27457079843ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:36:16,332][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.5s/25573ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:36:23,083][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.5s/25572991718ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:36:34,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18131ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:36:42,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18130893907ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:36:57,664][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22294ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:37:11,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22294244130ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:37:26,564][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29060ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:37:43,458][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29060607470ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:38:02,378][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [32003ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:37:57,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32s/32004ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:38:15,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32s/32003694246ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:38:28,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [30538ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:38:27,986][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30539ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:38:41,185][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30538949659ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:38:51,234][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24152ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:38:55,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [24151ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:39:03,136][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24151835228ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:39:13,034][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [21483ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:39:13,247][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21483ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:39:22,692][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21483277134ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:39:33,408][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18164ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:39:44,815][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18163608285ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:39:54,133][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23015ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:40:06,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23015052113ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:40:19,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23409ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:40:19,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [23409ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:40:33,869][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23409639393ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:40:47,564][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29519ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:40:49,974][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [29518ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:40:55,100][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29518662830ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:41:11,795][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.3s/24306ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:41:14,571][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [24305ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:41:21,188][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.3s/24305673206ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:41:29,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [17066ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:41:29,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17066ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:41:39,094][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17066278603ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:41:45,501][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16007ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:41:53,213][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16006609693ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:42:01,412][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16907ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:42:10,253][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.9s/16906917071ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:42:21,902][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [20218ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:42:22,939][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.2s/20218ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:42:29,366][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.2s/20218590317ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:42:40,502][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17780ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:42:43,169][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [17779ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:42:52,897][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17779989554ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:43:06,124][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [25947ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:43:06,391][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25948ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:43:21,313][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25947504248ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:43:33,914][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec73ce, interval=30s}] took [28422ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:43:34,071][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.4s/28422ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:43:47,062][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.4s/28422435928ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:43:58,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24581ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:44:01,273][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [24580ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:44:11,043][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24580891524ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:44:23,902][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2d95d4b1, interval=1m}] took [25396ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:44:24,039][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25396ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:44:35,814][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25396284094ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:44:48,297][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23513ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:44:50,486][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [23512ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:45:00,619][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23512959132ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:43:55,531][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@2d6fdc14] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-03-26T23:45:09,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21817ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:45:11,621][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [21817ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:45:18,313][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21817235351ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:45:29,618][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19s/19065ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:45:32,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [19064ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:45:42,277][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19s/19064787729ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:45:54,670][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24481ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:46:05,898][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24416360906ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:46:16,540][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22896ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:46:20,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [22960ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:46:28,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22960703902ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:46:39,228][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22810ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:46:38,485][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2d95d4b1, interval=1m}] took [22809ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:46:49,014][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22809967496ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:46:57,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.7s/18720ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:47:00,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [18720ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:47:08,082][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.7s/18720116866ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:47:20,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22300ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:47:20,473][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec73ce, interval=30s}] took [22299ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:47:32,468][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22299454443ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:47:40,200][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.2s/20235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:47:46,459][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.2s/20234668155ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:47:54,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14581ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:01,269][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14581431973ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:10,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15708ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:21,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15707674707ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:39,540][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [27778ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:48:37,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27778ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:48,910][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27778785783ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:57,869][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.1s/20130ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:48:57,869][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@60ec73ce, interval=30s}] took [20129ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:49:09,544][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.1s/20129086139ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:49:24,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24968ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:49:24,195][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [24968ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:49:44,603][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24968259021ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:50:01,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38s/38015ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:50:03,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [38014ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:50:12,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38s/38014946480ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:50:23,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21074ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:50:25,638][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [21074ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:50:34,357][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21074085293ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:50:47,050][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25139ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:50:47,050][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [25139ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:51:00,882][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25139318754ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:51:29,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.1s/42158ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:51:40,173][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.1s/42158071124ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:51:52,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [22418ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:51:52,786][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22419ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:51:59,911][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22418942792ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:52:08,241][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15214ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:52:17,687][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15213762379ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:52:26,762][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19115ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:52:29,974][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [19114ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:52:35,889][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19114731978ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:04,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [30815ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:52:58,958][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.8s/30815ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:11,305][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.8s/30815802138ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:20,721][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23658ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:22,676][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [23599ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:53:30,222][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.5s/23599960747ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:37,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.4s/16435ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:44,227][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.4s/16492856582ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:53:51,367][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14330ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:54:00,346][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14329749735ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:54:11,303][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.7s/18798ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:54:13,828][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [18797ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:54:21,399][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.7s/18797560809ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:54:32,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@2d95d4b1, interval=1m}] took [23338ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:54:33,229][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23338ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:54:41,583][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23338101606ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:55:00,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [25699ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:55:00,058][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.6s/25699ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:55:17,334][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.6s/25699130603ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:55:35,663][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.8s/34817ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:55:36,952][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [34817ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:55:52,314][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.8s/34817471574ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:56:20,237][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.3s/44327ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:56:25,197][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [44327ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:56:37,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.3s/44327047964ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:56:52,379][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32725ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:56:54,172][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [32724ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:57:11,449][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.7s/32724651392ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:57:31,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.8s/36895ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:57:32,184][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [36895ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:57:53,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.8s/36895193077ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:58:07,631][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.7s/38785ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:58:13,514][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [38784ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:58:22,976][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.7s/38784650642ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:58:39,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.8s/31890ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:58:41,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@69754329, interval=5s}] took [31889ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:58:53,131][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.8s/31889748138ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:59:13,030][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.6s/32614ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:59:15,389][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@527e8959, interval=5s}] took [32614ms] which is above the warn threshold of [5000ms]
[2022-03-26T23:59:26,619][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.6s/32614799599ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-26T23:59:40,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27400ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-26T23:59:54,970][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27399562024ns] on relative clock which is above the warn threshold of [5000ms]
