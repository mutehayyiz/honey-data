[2022-04-13T16:05:02,657][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-13T16:05:02,671][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-13T16:05:02,674][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-13T16:05:09,865][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-13T16:05:09,866][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-13T16:05:09,866][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-13T16:05:09,867][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-13T16:05:09,868][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-13T16:05:09,868][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-13T16:05:09,869][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-13T16:05:09,869][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-13T16:05:09,870][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-13T16:05:09,870][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-13T16:05:09,870][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-13T16:05:09,871][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-13T16:05:09,871][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-13T16:05:09,872][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-13T16:05:09,872][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-13T16:05:09,873][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-13T16:05:09,873][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-13T16:05:09,874][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-13T16:05:09,874][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-13T16:05:09,875][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-13T16:05:09,875][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-13T16:05:09,876][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-13T16:05:09,876][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-13T16:05:09,876][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-13T16:05:09,877][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-13T16:05:09,877][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-13T16:05:09,878][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-13T16:05:09,878][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-13T16:05:09,879][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-13T16:05:09,879][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-13T16:05:09,879][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-13T16:05:09,880][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-13T16:05:09,880][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-13T16:05:09,880][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-13T16:05:09,881][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-13T16:05:09,881][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-13T16:05:09,882][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-13T16:05:09,882][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-13T16:05:09,882][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-13T16:05:09,883][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-13T16:05:09,883][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-13T16:05:09,884][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-13T16:05:09,884][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-13T16:05:09,885][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-13T16:05:09,885][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-13T16:05:09,886][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-13T16:05:09,886][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-13T16:05:09,886][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-13T16:05:09,887][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-13T16:05:09,887][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-13T16:05:09,888][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-13T16:05:09,888][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-13T16:05:09,888][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-13T16:05:09,889][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-13T16:05:09,889][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-13T16:05:09,889][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-13T16:05:09,890][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-13T16:05:09,890][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-13T16:05:09,891][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-13T16:05:09,954][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.9gb], net total_space [125.8gb], types [ext4]
[2022-04-13T16:05:09,955][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-13T16:05:10,200][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-13T16:05:20,742][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-13T16:05:20,745][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-13T16:05:21,790][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-13T16:05:21,911][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-13T16:05:22,656][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-13T16:05:23,375][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-13T16:05:23,375][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-13T16:05:23,411][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-13T16:05:23,413][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-13T16:05:23,619][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-13T16:05:26,321][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-13T16:05:26,426][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{0ZQ5VQUpToKe8icNRIen_Q}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 243, version: 9435, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{0ZQ5VQUpToKe8icNRIen_Q}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-13T16:05:26,574][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{0ZQ5VQUpToKe8icNRIen_Q}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 243, version: 9435, reason: Publication{term=243, version=9435}
[2022-04-13T16:05:26,684][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-13T16:05:26,685][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-13T16:05:27,675][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-13T16:05:27,688][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [50] indices into cluster_state
[2022-04-13T16:05:28,328][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-13T16:05:28,329][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-13T16:05:28,922][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-ASN.mmdb]
[2022-04-13T16:05:29,370][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-13T16:05:29,400][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-13T16:05:29,401][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-13T16:05:29,968][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-13T16:05:30,092][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-13T16:05:31,461][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-13T16:05:31,505][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-ASN.mmdb]
[2022-04-13T16:05:31,520][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-City.mmdb]
[2022-04-13T16:05:31,911][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-13T16:05:31,912][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-13T16:05:32,995][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-13T16:05:36,577][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0]]]).
[2022-04-13T16:05:37,487][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-13T16:05:37,506][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-City.mmdb]
[2022-04-13T16:05:37,507][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-Country.mmdb]
[2022-04-13T16:05:38,108][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-13T16:05:38,136][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-Country.mmdb]
[2022-04-13T16:05:38,253][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-13T16:05:38,254][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-13T16:05:39,068][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-13T16:05:39,069][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-13T16:05:48,815][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-04-13T16:05:48,959][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-04-13T16:06:31,359][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 1003 finished with response BulkByScrollResponse[took=368ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-13T16:06:33,510][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 1035 finished with response BulkByScrollResponse[took=2.1s,timed_out=false,sliceId=null,updated=922,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-13T16:06:41,088][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-04-13T16:09:59,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5s/5533ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:10:46,966][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@298fbfce, interval=1s}] took [30724ms] which is above the warn threshold of [5000ms]
[2022-04-13T16:10:49,938][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3s/5307234539ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:10:50,261][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/165302ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:10:50,262][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/165681146754ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:10:53,531][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@7662e599, interval=5s}] took [168902ms] which is above the warn threshold of [5000ms]
[2022-04-13T16:10:59,565][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:10:59,777][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:11:00,017][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:11:00,152][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:11:00,455][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:11:02,598][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:11:23,607][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:12:27,692][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:13:17,772][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:13:32,787][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:14:10,823][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:14:10,882][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:14:30,850][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:16:06,968][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:16:07,069][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:23:27,306][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:23:53,322][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:26:28,204][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:33:40,764][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:37:02,059][INFO ][o.e.c.m.MetadataDeleteIndexService] [tpotcluster-node-01] [logstash-1970.01.01/1pKOC-ZcQWeDHaGkNPDT3w] deleting index
[2022-04-13T16:39:54,052][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:39:54,144][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:39:54,223][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:41:01,122][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T16:43:31,651][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@298fbfce, interval=1s}] took [5413ms] which is above the warn threshold of [5000ms]
[2022-04-13T16:44:10,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@298fbfce, interval=1s}] took [7462ms] which is above the warn threshold of [5000ms]
[2022-04-13T16:44:34,799][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@298fbfce, interval=1s}] took [14013ms] which is above the warn threshold of [5000ms]
[2022-04-13T16:45:21,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6s/6609ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:45:30,292][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6s/6609663082ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:45:54,142][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45736ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:49:55,176][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.5s/45586753208ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:47:41,178][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@298fbfce, interval=1s}] took [45586ms] which is above the warn threshold of [5000ms]
[2022-04-13T16:50:54,516][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/301946ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:50:10,200][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [1.4m/88052ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@619e5adf]], which exceeds the warn threshold of [10s]
[2022-04-13T16:51:42,153][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/302095007080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:17,773][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [10.6s/10647ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@c2ceff9e], ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@1369a8d6], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.09-000003], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a802557b]], which exceeds the warn threshold of [10s]
[2022-04-13T16:53:20,675][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.4m/145827ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:35,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.4m/145827113682ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:39,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19439ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:42,750][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19438487016ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:48,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.7s/8702ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:54,852][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.7s/8702756883ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:53:44,494][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [19438ms] which is above the warn threshold of [5s]
[2022-04-13T16:54:08,821][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.7s/19700ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:54:41,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19699813319ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:55:14,553][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66698ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:55:48,157][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66577244419ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T16:57:00,670][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/105014ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T16:59:47,472][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/105134168863ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:01:04,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@7662e599, interval=5s}] took [105134ms] which is above the warn threshold of [5000ms]
[2022-04-13T17:03:35,046][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/393478ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T17:24:38,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/393062908396ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:29:48,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.2m/1573753ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T17:32:44,998][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.2m/1573984289982ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:35:52,404][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/347979ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T17:35:27,149][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [21.3s/21334ms] to compute cluster state update for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@1369a8d6]], which exceeds the warn threshold of [10s]
[2022-04-13T17:38:52,653][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/347688515153ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:41:44,758][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/367828ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T17:45:51,238][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/368122236372ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:48:53,392][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/428900ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T17:51:44,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/429080835072ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:53:41,815][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287540ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T17:56:27,145][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287539100475ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T17:59:10,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/329482ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:00:45,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/329481964108ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:03:03,943][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/233967ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:05:52,352][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/233836240899ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:08:40,203][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/334720ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:23:29,025][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-13T18:23:29,237][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-13T18:23:29,239][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-13T18:25:11,798][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-13T18:25:11,802][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-13T18:25:11,803][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-13T18:25:11,803][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-13T18:25:11,804][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-13T18:25:11,804][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-13T18:25:11,804][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-13T18:25:11,805][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-13T18:25:11,805][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-13T18:25:11,806][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-13T18:25:11,806][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-13T18:25:11,806][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-13T18:25:11,807][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-13T18:25:11,807][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-13T18:25:11,808][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-13T18:25:11,808][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-13T18:25:11,809][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-13T18:25:11,809][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-13T18:25:11,809][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-13T18:25:11,810][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-13T18:25:11,810][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-13T18:25:11,811][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-13T18:25:11,811][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-13T18:25:11,811][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-13T18:25:11,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-13T18:25:11,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-13T18:25:11,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-13T18:25:11,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-13T18:25:11,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-13T18:25:11,814][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-13T18:25:11,814][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-13T18:25:11,815][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-13T18:25:11,815][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-13T18:25:11,815][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-13T18:25:11,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-13T18:25:11,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-13T18:25:11,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-13T18:25:11,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-13T18:25:11,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-13T18:25:11,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-13T18:25:11,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-13T18:25:11,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-13T18:25:11,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-13T18:25:11,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-13T18:25:11,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-13T18:25:11,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-13T18:25:11,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-13T18:25:11,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-13T18:25:11,820][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-13T18:25:11,820][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-13T18:25:11,820][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-13T18:25:11,820][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-13T18:25:11,821][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-13T18:25:11,821][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-13T18:25:11,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-13T18:25:11,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-13T18:25:11,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-13T18:25:11,823][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-13T18:25:11,824][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-13T18:25:11,903][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.8gb], net total_space [125.8gb], types [ext4]
[2022-04-13T18:25:11,903][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-13T18:25:12,364][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-13T18:25:21,488][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-13T18:25:21,494][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-13T18:25:21,494][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-13T18:25:21,498][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-13T18:25:21,498][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-13T18:25:21,499][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-13T18:25:21,499][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-13T18:25:21,500][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-13T18:25:21,500][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-13T18:25:21,501][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-13T18:25:21,501][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-13T18:25:21,502][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-13T18:25:21,503][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-13T18:25:21,504][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-13T18:25:21,504][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-13T18:25:22,483][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-13T18:25:22,633][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-13T18:25:23,404][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-13T18:25:24,077][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-13T18:25:24,077][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-13T18:25:24,182][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-13T18:25:24,184][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-13T18:25:24,433][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-13T18:25:26,775][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-13T18:25:26,950][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{6NRldrkrRnC8nr7qeDff3g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 244, version: 9518, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{6NRldrkrRnC8nr7qeDff3g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-13T18:25:27,121][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{6NRldrkrRnC8nr7qeDff3g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 244, version: 9518, reason: Publication{term=244, version=9518}
[2022-04-13T18:25:27,261][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-13T18:25:27,263][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-13T18:25:28,068][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-13T18:25:28,077][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [49] indices into cluster_state
[2022-04-13T18:25:28,870][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-13T18:25:28,878][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-13T18:26:02,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16585ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:29:34,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/225417ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:29:38,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/241700492582ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:29:47,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13184ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:29:53,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13183902208ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:29:58,346][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8s/10899ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:29:58,473][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8s/10899792760ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:30:20,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20063ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:30:33,521][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20063667447ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:30:45,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.6s/25663ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:30:51,118][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.6s/25662781121ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:30:56,114][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10786ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:06,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10786042486ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:14,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18238ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:22,269][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18237934390ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:29,786][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14963ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:36,768][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14963320198ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:45,344][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15241ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:50,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15240489270ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:31:58,799][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.8s/13840ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:32:11,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.8s/13839821821ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:32:21,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22422ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:32:28,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22422310883ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:32:38,034][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16660ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:32:18,661][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:40710}] took [374766ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:32:48,328][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16659904603ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:33:09,377][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31780ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:33:24,266][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31779710569ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:33:31,280][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21960ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:33:39,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21960738686ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:33:50,384][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17958ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:34:04,195][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17957656508ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:34:18,559][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.6s/27627ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:34:34,289][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.6s/27627123346ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:34:48,839][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.3s/31310ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:35:03,223][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.3s/31310297227ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:35:19,657][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30615ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:35:34,896][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30614519098ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:35:46,831][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.6s/27672ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:35:56,895][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.6s/27672384380ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:05,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18298ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:12,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18297585175ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:22,364][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17583ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:30,153][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17582880791ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:37,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14648ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:45,074][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14648230591ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:53,866][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16542ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:36:59,716][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16541799884ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:16,564][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22865ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:21,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.8s/22865374956ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:27,759][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.1s/11165ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:33,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.1s/11165135624ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:40,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6s/12659ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:46,235][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6s/12658776109ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:50,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5s/10590ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:37:55,404][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5s/10590119744ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:02,910][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12027ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:09,847][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12027197125ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:15,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12729ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:30,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12728630420ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:38,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23064ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:31,204][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:40748}] took [12729ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:38:44,301][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23063387634ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:38:54,365][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14856ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:02,864][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14856161510ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:09,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15930ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:18,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15930684466ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:27,195][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17550ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:29,687][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:40748}] took [33481ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:39:35,353][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17549815390ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:46,706][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19331ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:39:54,012][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19330981703ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:02,048][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15322ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:10,295][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15321452629ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:18,366][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16657ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:22,584][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16657293247ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:30,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.3s/11320ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:36,477][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.3s/11319603188ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:47,893][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18210ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:40:58,176][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18210421739ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:04,645][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16610ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:11,166][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16610102768ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:18,689][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14472ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:21,917][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14472285058ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:25,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2s/7267ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:29,235][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2s/7266790312ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:35,783][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9344ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:41,514][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9343884919ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:49,471][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13413ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:41:57,871][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13412839281ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:09,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19976ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:16,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19976461531ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:25,228][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.6s/15630ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:13,888][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5102/0x00000008017e1708@e21106f] took [754038ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:42:33,462][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.6s/15629465256ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:42,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16867ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:48,309][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_license][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:40748}] took [113579ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:42:48,430][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16866904257ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:42:55,907][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13998ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:00,885][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.9s/13997937897ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:05,301][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7s/9786ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:09,450][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7s/9786010492ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:17,853][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12036ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:25,995][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12036759750ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:35,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17354ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:46,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@181f2f92, interval=1s}] took [29390ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:43:47,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17353246279ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:54,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20033ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:43:44,909][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [29390ms] which is above the warn threshold of [5s]
[2022-04-13T18:43:59,226][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20032915255ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:44:05,967][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.1s/11116ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:44:06,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38a869db, interval=5s}] took [11116ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:44:13,967][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.1s/11116349924ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:44:24,149][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18532ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:44:35,675][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18532398967ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:44:46,421][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22347ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:44:56,367][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.3s/22346793214ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:06,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19312ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:15,947][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@2591939c, interval=5s}] took [60190ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:45:18,311][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.3s/19311793459ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:28,302][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21608ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:36,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21607877202ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:44,527][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16588ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:50,262][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16587933561ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:45:56,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:46:02,523][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12235344648ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:46:11,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14396ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:46:27,206][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14395687196ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:46:33,528][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21886ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:46:47,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21886281542ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:47:15,098][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@181f2f92, interval=1s}] took [21886ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:47:19,607][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.1s/44106ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:47:40,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.1s/44105745087ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:48:10,930][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51281ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:48:39,001][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51281125518ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:49:28,976][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74248ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:50:19,536][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@2591939c, interval=5s}] took [74248ms] which is above the warn threshold of [5000ms]
[2022-04-13T18:50:44,435][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74248181722ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:51:59,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/151721ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:52:37,762][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/151721033608ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:53:20,666][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/84186ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:53:57,925][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/84185777495ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T18:54:40,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78009ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:59:24,970][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78009292220ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:03:14,452][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4m/509544ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T18:58:55,041][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [78010ms] which is above the warn threshold of [5s]
[2022-04-13T19:07:02,253][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4m/509044300882ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:10:37,941][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/442020ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:13:42,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/442519601722ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:13:26,572][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@181f2f92, interval=1s}] took [442519ms] which is above the warn threshold of [5000ms]
[2022-04-13T19:15:03,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/270204ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:19:09,135][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/270203877870ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:22:16,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/430958ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:26:05,925][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/430397266650ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:29:44,501][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4m/448963ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:32:10,695][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4m/449383541240ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:33:50,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/241844ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:33:50,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38a869db, interval=5s}] took [241984ms] which is above the warn threshold of [5000ms]
[2022-04-13T19:36:07,964][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/241984502385ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:37:04,152][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.3m/203021ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:36:39,809][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [79] timed out after [241837ms]
[2022-04-13T19:37:53,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.3m/203021123163ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:40:11,518][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/172080ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:40:41,061][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/172079291023ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:40:56,452][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60371ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:41:12,180][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60370909841ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:41:50,404][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.3s/52314ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:42:11,131][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.3s/52314339213ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:42:36,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47954ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:42:52,809][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47953713517ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:43:11,070][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.5s/33532ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:43:28,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.5s/33532762939ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:43:45,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35218ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:43:25,289][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [33533ms] which is above the warn threshold of [5s]
[2022-04-13T19:44:17,734][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35217668076ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:44:19,529][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@181f2f92, interval=1s}] took [68750ms] which is above the warn threshold of [5000ms]
[2022-04-13T19:44:40,924][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54s/54041ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:44:59,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54s/54041170818ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:45:19,185][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37777ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:45:44,136][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37776305133ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:46:01,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.6s/44616ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:46:22,516][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.6s/44616334244ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:46:43,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.4s/41449ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:47:04,320][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.4s/41448836080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:47:27,685][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42557ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:47:42,088][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42557083688ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:47:57,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31274ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:48:15,984][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31274699081ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:48:35,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39s/39060ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:48:50,910][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39s/39059769570ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:49:04,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27865ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:49:25,932][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27865122618ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:49:50,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.5s/44565ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:50:43,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.5s/44564857585ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:51:13,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/83372ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:51:46,728][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/83371519255ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:52:16,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63717ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:52:43,967][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63717136590ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:53:18,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.8s/57810ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:53:44,059][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.8s/57809962778ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:54:08,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53s/53048ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:54:37,697][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53s/53047884623ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:55:35,213][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87313ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:56:13,811][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87312958719ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:56:40,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63273ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:57:11,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63273548353ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:57:41,368][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62905ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:58:17,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62904640485ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T19:58:47,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66451ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T19:59:31,765][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66450940723ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:00:11,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/82920ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:00:48,249][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/82920532126ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:01:38,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87548ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:02:09,661][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87547269465ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:02:49,824][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70490ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:03:31,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70490232677ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:04:09,350][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79951ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:04:48,944][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79950828467ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:05:43,722][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91126ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:06:33,298][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91126619461ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:07:23,638][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99948ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:08:29,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99947231679ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:09:28,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126713ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:10:30,792][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126713797309ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:13:22,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/224971ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:17:05,982][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/224970419146ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:13:01,072][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [1.4h/5235087ms] ago, timed out [1.3h/4993250ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{6NRldrkrRnC8nr7qeDff3g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [79]
[2022-04-13T20:20:21,715][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.7m/405165ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:23:55,539][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.7m/404700277817ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:27:18,955][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5102/0x00000008017e1708@71525548] took [1949020ms] which is above the warn threshold of [5000ms]
[2022-04-13T20:27:33,292][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/451173ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:31:42,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/451164587416ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:35:07,080][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453348ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:39:08,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453313348369ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:41:02,483][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@181f2f92, interval=1s}] took [453313ms] which is above the warn threshold of [5000ms]
[2022-04-13T20:43:16,129][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8m/468460ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:47:10,646][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8m/468816806147ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:50:48,888][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8m/473619ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T20:54:23,680][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.8m/473222341031ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T20:58:04,390][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2m/432316ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T21:01:45,363][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2m/432197942558ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T21:05:24,658][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/443584ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T21:09:07,492][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/443606871063ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T21:12:47,040][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/441457ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T21:18:21,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/441911547046ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T21:11:24,940][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [443607ms] which is above the warn threshold of [5s]
[2022-04-13T21:23:26,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5m/630553ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T21:27:20,775][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5m/630081803767ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T21:30:47,584][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/451852ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T21:33:59,506][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/452116259758ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:11:34,306][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-13T23:11:34,352][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-13T23:11:34,354][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-13T23:11:42,359][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-13T23:11:42,361][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-13T23:11:42,362][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-13T23:11:42,363][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-13T23:11:42,364][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-13T23:11:42,365][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-13T23:11:42,365][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-13T23:11:42,366][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-13T23:11:42,367][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-13T23:11:42,367][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-13T23:11:42,368][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-13T23:11:42,368][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-13T23:11:42,369][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-13T23:11:42,370][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-13T23:11:42,370][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-13T23:11:42,377][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-13T23:11:42,378][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-13T23:11:42,379][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-13T23:11:42,379][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-13T23:11:42,380][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-13T23:11:42,382][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-13T23:11:42,382][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-13T23:11:42,383][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-13T23:11:42,383][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-13T23:11:42,384][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-13T23:11:42,384][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-13T23:11:42,384][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-13T23:11:42,385][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-13T23:11:42,385][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-13T23:11:42,386][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-13T23:11:42,386][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-13T23:11:42,387][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-13T23:11:42,387][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-13T23:11:42,389][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-13T23:11:42,390][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-13T23:11:42,390][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-13T23:11:42,391][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-13T23:11:42,391][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-13T23:11:42,392][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-13T23:11:42,392][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-13T23:11:42,393][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-13T23:11:42,393][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-13T23:11:42,394][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-13T23:11:42,394][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-13T23:11:42,394][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-13T23:11:42,395][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-13T23:11:42,395][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-13T23:11:42,396][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-13T23:11:42,396][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-13T23:11:42,396][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-13T23:11:42,397][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-13T23:11:42,397][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-13T23:11:42,398][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-13T23:11:42,398][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-13T23:11:42,398][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-13T23:11:42,399][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-13T23:11:42,399][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-13T23:11:42,400][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-13T23:11:42,401][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-13T23:11:42,477][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.8gb], net total_space [125.8gb], types [ext4]
[2022-04-13T23:11:42,478][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-13T23:11:42,875][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-13T23:11:58,519][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-13T23:11:58,531][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-13T23:12:00,022][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-13T23:12:00,193][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-13T23:12:01,273][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-13T23:12:02,469][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-13T23:12:02,470][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-13T23:12:02,538][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-13T23:12:02,540][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-13T23:12:02,859][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-13T23:12:07,137][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-13T23:12:07,334][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{QN4wGnPiSgOSfodlfFCgwg}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 245, version: 9525, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{QN4wGnPiSgOSfodlfFCgwg}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-13T23:12:07,658][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{QN4wGnPiSgOSfodlfFCgwg}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 245, version: 9525, reason: Publication{term=245, version=9525}
[2022-04-13T23:12:07,870][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-13T23:12:07,871][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-13T23:12:09,193][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-13T23:12:09,206][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [49] indices into cluster_state
[2022-04-13T23:12:10,105][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-13T23:12:10,107][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-13T23:12:11,461][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-13T23:12:11,765][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-13T23:12:12,413][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-13T23:12:12,418][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-13T23:12:12,422][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-13T23:12:12,775][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-13T23:12:13,511][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-13T23:12:13,773][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-13T23:12:13,837][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:13,963][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:14,005][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:14,022][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:16,398][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:16,418][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:16,642][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-13T23:12:17,831][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-13T23:12:27,196][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.13][0], [.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0]]]).
[2022-04-13T23:12:55,062][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-1970.01.01] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-13T23:12:55,199][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-1970.01.01][0]]]).
[2022-04-13T23:12:55,392][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-1970.01.01/BByN9-ZNSay2Jx7Y4INJ4w] update_mapping [_doc]
[2022-04-13T23:12:55,708][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:12:55,923][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:12:55,948][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:12:56,376][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:12:56,656][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:12:58,781][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:12:59,976][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:00,179][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:00,668][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:01,043][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:01,285][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:04,913][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:05,441][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:05,874][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:13:06,733][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.13/2jchCQaGRwmkA3wgGNpNNQ] update_mapping [_doc]
[2022-04-13T23:16:06,071][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:32964}] took [5967ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:16:06,071][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:32990}] took [11481ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:16:16,534][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@608f1e05, interval=1s}] took [6551ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:17:00,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@6759d9c2, interval=1m}] took [11246ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:17:38,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5646ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:18:42,874][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5673728693ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:18:54,027][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/129925ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:18:57,794][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_7.17.0/_search?from=0&rest_total_hits_as_int=true&size=20][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:32946}] took [130167ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:19:22,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/130167230330ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:19:45,112][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.7s/51733ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:19:45,112][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@2b444273, interval=5s}] took [130167ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:19:54,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.7s/51732233286ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:20:01,440][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15961ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:20:02,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@608f1e05, interval=1s}] took [15961ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:20:09,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15961105892ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:20:34,159][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.5s/31593ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:20:50,625][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.5s/31592981355ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:21:16,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.9s/34989ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:21:37,908][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.9s/34989119207ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:21:56,667][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.3s/48327ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:22:12,428][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.3s/48326800021ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:22:25,524][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.2s/28299ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:23:41,792][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.2s/28299485527ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:24:18,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113635ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:24:18,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7aa00afa, interval=5s}] took [113634ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:24:51,009][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113634382122ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:22:29,046][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [1954] timed out after [20725ms]
[2022-04-13T23:25:10,537][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.5s/51587ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:25:32,682][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.5s/51587776833ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:25:43,392][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@2b444273, interval=5s}] took [51587ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:26:26,468][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76172ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:26:39,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76171716113ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:27:12,045][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.3s/45397ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:27:46,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.3s/45396629136ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:27:55,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@608f1e05, interval=1s}] took [45396ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:28:07,019][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.7s/54704ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:28:30,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.7s/54704086816ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:29:02,681][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.4s/56446ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:29:27,470][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.4s/56446074879ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:29:35,721][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33084ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:29:45,933][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33s/33084581445ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:29:26,641][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [56446ms] which is above the warn threshold of [5s]
[2022-04-13T23:29:53,079][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.7s/16728ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:30:00,674][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.7s/16727573577ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:30:08,051][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15706ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:30:26,167][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.7s/15705892990ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:31:07,914][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7aa00afa, interval=5s}] took [41212ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:31:04,327][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.2s/41212ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:31:42,440][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.2s/41212187396ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:33:07,099][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.2m/136064ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:34:11,669][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017d1bb8@1738f83d] took [136063ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:34:10,828][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.2m/136063613477ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:35:57,393][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/171275ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:37:04,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@608f1e05, interval=1s}] took [171275ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:38:15,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.8m/171275100433ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:39:00,133][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/183004ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:39:24,724][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/183004634600ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:39:47,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47s/47024ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:40:17,384][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47s/47023758987ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:40:44,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.1s/57179ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:41:18,993][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.1s/57178365549ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:41:42,615][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.7s/57789ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:42:14,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.7s/57789618714ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:43:11,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/88516ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:43:53,684][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/88515590747ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:44:35,483][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79858ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:45:30,019][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79858589280ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:46:08,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/98035ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:46:38,369][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/98035155392ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:47:07,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.2s/58216ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:47:51,853][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.2s/58215230414ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:48:38,537][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91646ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:49:35,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91645844903ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:50:47,292][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127865ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:51:58,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127864987957ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:53:21,238][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/154376ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:54:06,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/154376113244ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:55:27,522][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/119859ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:56:18,364][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/119859547831ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:57:18,355][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/116897ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:58:37,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/116648022280ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-13T23:59:36,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.2m/137397ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-13T23:59:40,453][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@608f1e05, interval=1s}] took [137645ms] which is above the warn threshold of [5000ms]
[2022-04-13T23:59:26,155][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [116648ms] which is above the warn threshold of [5s]
[2022-04-14T01:34:01,907][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-14T01:34:01,919][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-14T01:34:01,920][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-14T01:58:33,155][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-14T01:58:33,159][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-14T01:58:33,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-14T01:58:33,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-14T01:58:33,161][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-14T01:58:33,162][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-14T01:58:33,162][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-14T01:58:33,162][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-14T01:58:33,163][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-14T01:58:33,163][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-14T01:58:33,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-14T01:58:33,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-14T01:58:33,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-14T01:58:33,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-14T01:58:33,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-14T01:58:33,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-14T01:58:33,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-14T01:58:33,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-14T01:58:33,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-14T01:58:33,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-14T01:58:33,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-14T01:58:33,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-14T01:58:33,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-14T01:58:33,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-14T01:58:33,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-14T01:58:33,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-14T01:58:33,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-14T01:58:33,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-14T01:58:33,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-14T01:58:33,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-14T01:58:33,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-14T01:58:33,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-14T01:58:33,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-14T01:58:33,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-14T01:58:33,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-14T01:58:33,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-14T01:58:33,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-14T01:58:33,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-14T01:58:33,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-14T01:58:33,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-14T01:58:33,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-14T01:58:33,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-14T01:58:33,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-14T01:58:33,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-14T01:58:33,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-14T01:58:33,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-14T01:58:33,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-14T01:58:33,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-14T01:58:33,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-14T01:58:33,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-14T01:58:33,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-14T01:58:33,179][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-14T01:58:33,179][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-14T01:58:33,179][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-14T01:58:33,180][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-14T01:58:33,180][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-14T01:58:33,180][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-14T01:58:33,181][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-14T01:58:33,181][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-14T01:58:33,257][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.8gb], net total_space [125.8gb], types [ext4]
[2022-04-14T01:58:33,258][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-14T01:58:33,639][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-14T01:58:43,060][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-14T01:58:43,071][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-14T01:58:43,072][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-14T01:58:43,073][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-14T01:58:43,073][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-14T01:58:43,074][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-14T01:58:43,074][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-14T01:58:43,075][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-14T01:58:43,076][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-14T01:58:43,076][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-14T01:58:43,077][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-14T01:58:43,078][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-14T01:58:43,078][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-14T01:58:43,079][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-14T01:58:43,080][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-14T01:58:44,291][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-14T01:58:44,455][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-14T01:58:45,390][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-14T01:58:46,110][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-14T01:58:46,113][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-14T01:58:46,213][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-14T01:58:46,215][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-14T01:58:46,517][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-14T01:58:49,298][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-14T01:58:49,494][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 246, version: 9614, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-14T01:58:49,683][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 246, version: 9614, reason: Publication{term=246, version=9614}
[2022-04-14T01:58:49,905][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-14T01:58:49,910][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-14T01:58:50,983][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-14T01:58:51,008][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [50] indices into cluster_state
[2022-04-14T01:58:52,457][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-14T01:58:52,462][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-14T01:59:07,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8s/10892ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T01:59:15,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8s/10891674340ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T01:59:16,335][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.6s/11681ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T01:59:18,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.6s/11681362452ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T01:59:24,553][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41722}] took [19839ms] which is above the warn threshold of [5000ms]
[2022-04-14T01:59:35,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017d8d70@4f251edc] took [13142ms] which is above the warn threshold of [5000ms]
[2022-04-14T01:59:47,580][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3s/5370ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T01:59:48,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3s/5369957032ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T01:59:54,648][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [28427ms] which is above the warn threshold of [10s]; wrote global metadata [false] and metadata for [1] indices and skipped [49] unchanged indices
[2022-04-14T01:59:57,360][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [31.4s] publication of cluster state version [9618] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-04-14T02:00:01,661][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [72] timed out after [15129ms]
[2022-04-14T02:00:04,577][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [29.3s/29377ms] ago, timed out [14.2s/14248ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [72]
[2022-04-14T02:00:29,253][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7085ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:00:29,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@415532ad, interval=1s}] took [7285ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:00:29,675][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7085385556ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:00:36,992][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41722}] took [68041ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:00:37,138][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=246, version=9618}] took [37.3s] which is above the warn threshold of [30s]: [running task [Publication{term=246, version=9618}]] took [0ms], [connecting to new nodes] took [0ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@4556b7d] took [0ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@5dec30b5] took [6571ms], [org.elasticsearch.script.ScriptService@4998b0d] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@3484f4a9] took [0ms], [org.elasticsearch.snapshots.RestoreService@1ba57fc7] took [0ms], [org.elasticsearch.ingest.IngestService@27f08d9e] took [91ms], [org.elasticsearch.action.ingest.IngestActionForwarder@6ff9ab8e] took [26ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4526/0x00000008016cf960@7ccb2b64] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@4ca0287d] took [118ms], [org.elasticsearch.tasks.TaskManager@6f9fd00a] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@4d18a3ac] took [31ms], [org.elasticsearch.cluster.InternalClusterInfoService@6589f19e] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@376f0968] took [23ms], [org.elasticsearch.indices.SystemIndexManager@4bf93a] took [641ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@60143059] took [0ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x00000008012dee58@4a72f23e] took [222ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@6fd5c8c5] took [0ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@52232ec] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x0000000801402000@6e87cf80] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@71d3db3b] took [64ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@2bb2a936] took [22038ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@788f42ff] took [0ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@23e0c3b9] took [0ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@21fae580] took [1000ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@5263be48] took [233ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@66e3b204] took [0ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@433b486a] took [3514ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@3484f4a9] took [153ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@359b7368] took [1721ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@7ac51a6d] took [36ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@76c2a4b6] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@4f462ceb] took [544ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@793b4ed9] took [27ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@3aa9c8e9] took [0ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@613b4389] took [0ms], [org.elasticsearch.node.ResponseCollectorService@42d584f1] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@653547d6] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@11af3519] took [0ms], [org.elasticsearch.shutdown.PluginShutdownService@2a330bae] took [0ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@6b926c9c] took [0ms], [org.elasticsearch.indices.store.IndicesStore@650fa146] took [1ms], [org.elasticsearch.persistent.PersistentTasksNodeService@56cde0d4] took [0ms], [org.elasticsearch.license.LicenseService@6f150abe] took [0ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@f06fb78] took [0ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@6d953845] took [0ms], [org.elasticsearch.gateway.GatewayService@540aac] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@3f600100] took [0ms]
[2022-04-14T02:00:45,120][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@415532ad, interval=1s}] took [5833ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:00:49,744][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [11337ms] which is above the warn threshold of [10s]; wrote global metadata [false] and metadata for [3] indices and skipped [47] unchanged indices
[2022-04-14T02:00:51,479][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [13.1s] publication of cluster state version [9619] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-04-14T02:01:37,128][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@415532ad, interval=1s}] took [6318ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:02:05,258][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@415532ad, interval=1s}] took [12062ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:02:31,232][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9069ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:02:42,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9s/9068568653ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:02:43,849][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12796ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:02:43,900][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7s/12796100240ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:02:43,561][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017d8d70@6eaeacf9] took [23758ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:03:15,768][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_cat/health][Netty4HttpChannel{localAddress=/127.0.0.1:9200, remoteAddress=/127.0.0.1:49274}] took [31387ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:03:23,134][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017d8d70@94e5bf] took [6394ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:04:03,671][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@4a3797fb, interval=5s}] took [5174ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:04:08,259][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41746}] took [39371ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:04:08,259][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41732}] took [72427ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:04:08,259][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41748}] took [50117ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:04:13,196][ERROR][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] exception during geoip databases update
javax.net.ssl.SSLHandshakeException: Remote host terminated the handshake
	at sun.security.ssl.SSLSocketImpl.handleEOF(SSLSocketImpl.java:1715) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1514) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1416) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:451) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:422) ~[?:?]
	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:574) ~[?:?]
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:183) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1653) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1577) ~[?:?]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) ~[?:?]
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:308) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.lambda$get$0(HttpClient.java:55) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at java.security.AccessController.doPrivileged(AccessController.java:554) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.doPrivileged(HttpClient.java:97) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.get(HttpClient.java:49) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.getBytes(HttpClient.java:40) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.fetchDatabasesOverview(GeoIpDownloader.java:135) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.updateDatabases(GeoIpDownloader.java:123) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.runDownloader(GeoIpDownloader.java:260) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:97) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:43) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.persistent.NodePersistentTasksExecutor$1.doRun(NodePersistentTasksExecutor.java:42) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
	Suppressed: java.net.SocketException: Broken pipe
		at sun.nio.ch.NioSocketImpl.implWrite(NioSocketImpl.java:420) ~[?:?]
		at sun.nio.ch.NioSocketImpl.write(NioSocketImpl.java:440) ~[?:?]
		at sun.nio.ch.NioSocketImpl$2.write(NioSocketImpl.java:826) ~[?:?]
		at java.net.Socket$SocketOutputStream.write(Socket.java:1045) ~[?:?]
		at sun.security.ssl.SSLSocketOutputRecord.encodeAlert(SSLSocketOutputRecord.java:82) ~[?:?]
		at sun.security.ssl.TransportContext.fatal(TransportContext.java:400) ~[?:?]
		at sun.security.ssl.TransportContext.fatal(TransportContext.java:312) ~[?:?]
		at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:463) ~[?:?]
		at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:422) ~[?:?]
		at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:574) ~[?:?]
		at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:183) ~[?:?]
		at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1653) ~[?:?]
		at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1577) ~[?:?]
		at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) ~[?:?]
		at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:308) ~[?:?]
		at org.elasticsearch.ingest.geoip.HttpClient.lambda$get$0(HttpClient.java:55) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at java.security.AccessController.doPrivileged(AccessController.java:554) ~[?:?]
		at org.elasticsearch.ingest.geoip.HttpClient.doPrivileged(HttpClient.java:97) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.HttpClient.get(HttpClient.java:49) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.HttpClient.getBytes(HttpClient.java:40) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloader.fetchDatabasesOverview(GeoIpDownloader.java:135) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloader.updateDatabases(GeoIpDownloader.java:123) ~[ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloader.runDownloader(GeoIpDownloader.java:260) [ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:97) [ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:43) [ingest-geoip-7.17.0.jar:7.17.0]
		at org.elasticsearch.persistent.NodePersistentTasksExecutor$1.doRun(NodePersistentTasksExecutor.java:42) [elasticsearch-7.17.0.jar:7.17.0]
		at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
		at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
		at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: java.io.EOFException: SSL peer shut down incorrectly
	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:483) ~[?:?]
	at sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:472) ~[?:?]
	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:160) ~[?:?]
	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:111) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1506) ~[?:?]
	... 25 more
[2022-04-14T02:04:20,338][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=246, version=9620}] took [3.2m] which is above the warn threshold of [30s]: [running task [Publication{term=246, version=9620}]] took [0ms], [connecting to new nodes] took [44ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@4556b7d] took [0ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@5dec30b5] took [19190ms], [org.elasticsearch.script.ScriptService@4998b0d] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@3484f4a9] took [0ms], [org.elasticsearch.snapshots.RestoreService@1ba57fc7] took [0ms], [org.elasticsearch.ingest.IngestService@27f08d9e] took [120ms], [org.elasticsearch.action.ingest.IngestActionForwarder@6ff9ab8e] took [41ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4526/0x00000008016cf960@7ccb2b64] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@4ca0287d] took [0ms], [org.elasticsearch.tasks.TaskManager@6f9fd00a] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@4d18a3ac] took [40ms], [org.elasticsearch.cluster.InternalClusterInfoService@6589f19e] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@376f0968] took [0ms], [org.elasticsearch.indices.SystemIndexManager@4bf93a] took [4112ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@60143059] took [0ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x00000008012dee58@4a72f23e] took [126ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@6fd5c8c5] took [0ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@52232ec] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x0000000801402000@6e87cf80] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@71d3db3b] took [30ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@2bb2a936] took [51088ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@788f42ff] took [73ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@23e0c3b9] took [0ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@21fae580] took [25840ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@5263be48] took [285ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@66e3b204] took [0ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@433b486a] took [2870ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@3484f4a9] took [75ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@359b7368] took [2715ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@7ac51a6d] took [0ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@76c2a4b6] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@4f462ceb] took [812ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@793b4ed9] took [1290ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@3aa9c8e9] took [0ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@613b4389] took [164ms], [org.elasticsearch.node.ResponseCollectorService@42d584f1] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@653547d6] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@11af3519] took [0ms], [org.elasticsearch.shutdown.PluginShutdownService@2a330bae] took [0ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@6b926c9c] took [89ms], [org.elasticsearch.indices.store.IndicesStore@650fa146] took [0ms], [org.elasticsearch.persistent.PersistentTasksNodeService@56cde0d4] took [0ms], [org.elasticsearch.license.LicenseService@6f150abe] took [0ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@f06fb78] took [0ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@6d953845] took [85845ms], [org.elasticsearch.gateway.GatewayService@540aac] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@3f600100] took [0ms]
[2022-04-14T02:09:27,618][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [2.9m/175538ms] to compute cluster state update for [shard-started StartedShardEntry{shardId [[.apm-agent-configuration][0]], allocationId [MmPKadzLTwmgJSF2njqHDQ], primary term [158], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.apm-agent-configuration][0]], allocationId [MmPKadzLTwmgJSF2njqHDQ], primary term [158], message [after existing store recovery; bootstrap_history_uuid=false]}], shard-started StartedShardEntry{shardId [[.apm-custom-link][0]], allocationId [nNOliZZRQti8of1JzhXQwA], primary term [154], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.apm-custom-link][0]], allocationId [nNOliZZRQti8of1JzhXQwA], primary term [154], message [after existing store recovery; bootstrap_history_uuid=false]}], shard-started StartedShardEntry{shardId [[.kibana_7.16.2_001][0]], allocationId [UdncvSDVTUC-GicH4cNO0w], primary term [209], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.kibana_7.16.2_001][0]], allocationId [UdncvSDVTUC-GicH4cNO0w], primary term [209], message [after existing store recovery; bootstrap_history_uuid=false]}], shard-started StartedShardEntry{shardId [[.async-search][0]], allocationId [npy0692qTwWUl7SFIZsu4w], primary term [153], message [after existing store recovery; bootstrap_history_uuid=false]}[StartedShardEntry{shardId [[.async-search][0]], allocationId [npy0692qTwWUl7SFIZsu4w], primary term [153], message [after existing store recovery; bootstrap_history_uuid=false]}]], which exceeds the warn threshold of [10s]
[2022-04-14T02:09:42,208][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10790ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:11:24,007][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10789830144ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:11:40,560][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.4m/144865ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:11:48,764][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][92][30] duration [748ms], collections [1]/[2.1s], total [748ms]/[41.7s], memory [258.4mb]->[89.3mb]/[2gb], all_pools {[young] [184mb]->[0b]/[0b]}{[old] [65.6mb]->[65.6mb]/[2gb]}{[survivor] [8.8mb]->[23.7mb]/[0b]}
[2022-04-14T02:11:56,213][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.4m/144864973800ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:12:14,316][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][92] overhead, spent [748ms] collecting in the last [2.1s]
[2022-04-14T02:12:18,134][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.4s/35489ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:12:33,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@415532ad, interval=1s}] took [474485ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:12:45,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.4s/35488963894ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:13:04,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.7s/47700ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:13:18,673][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.7s/47700106053ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:13:34,021][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.8s/29842ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:13:47,809][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@4a3797fb, interval=5s}] took [29842ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:13:48,982][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.8s/29842013705ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:14:04,543][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31439ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:14:04,543][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@494e65f9, interval=5s}] took [31439ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:14:12,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31439254082ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:14:25,341][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.9s/18924ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:14:44,367][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.9s/18923497575ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:14:54,317][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.9s/30953ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:15:08,896][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.9s/30953047493ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:15:18,660][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.7s/24768ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:15:29,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.7s/24768884300ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:15:37,407][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:41770}] took [601483ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:16:03,018][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21512ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:16:23,858][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21511139739ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:16:46,554][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64954ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:17:00,892][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64954487942ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:18:08,671][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80446ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:19:40,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80445610730ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:20:11,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/124758ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:20:52,656][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/124757828597ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:21:55,038][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97433ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:22:26,696][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/97433087088ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:22:45,159][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55426ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:23:11,627][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55426760811ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:23:38,725][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.4s/52484ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:24:16,819][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.4s/52483573935ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:26:33,775][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/174152ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:28:00,939][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/174151942927ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:29:04,797][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/151260ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:29:40,291][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/151260052529ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:30:03,677][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.8s/59861ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:30:38,378][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.8s/59860580196ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:31:32,338][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87882ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:32:17,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/87882781856ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:34:02,666][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.4m/145855ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:34:37,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.4m/145698835300ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:34:55,506][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.2s/59245ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:35:14,209][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.4s/59401023286ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:35:29,444][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.1s/33122ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:35:58,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.1s/33121551026ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:36:17,761][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.6s/48612ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:36:38,820][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.6s/48612734619ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:36:58,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017d8d70@3cd46087] took [1331647ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:37:00,042][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41530ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:37:18,349][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41529634962ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:38:03,545][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48125ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:38:38,201][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48124963899ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:39:12,859][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/81116ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:39:36,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/81100784887ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:39:57,453][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.8s/47815ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:40:36,512][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.8s/47830339968ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:41:08,948][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [47831ms] which is above the warn threshold of [5s]
[2022-04-14T02:41:08,948][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/65033ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:41:54,209][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/65033278585ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:42:16,093][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/72969ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:42:30,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/72968396715ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:43:09,569][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.7s/54746ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:43:29,725][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.7s/54745836326ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:44:04,365][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@415532ad, interval=1s}] took [54745ms] which is above the warn threshold of [5000ms]
[2022-04-14T02:44:12,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63142ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:44:52,376][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63142577677ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:45:27,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76398ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:45:43,296][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76397383920ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:46:35,698][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68156ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:47:03,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68155951757ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:47:21,615][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.5s/44544ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:47:39,181][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.5s/44544776261ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:48:06,237][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.4s/43429ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:49:11,333][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.4s/43428550431ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:50:05,157][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/120089ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:50:20,943][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/120088662440ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:50:40,119][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35281ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:50:55,361][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35281623463ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:51:08,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29085ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:51:28,653][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29s/29085204503ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:52:48,017][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99652ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:52:59,188][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99651512695ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:53:13,007][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.8s/24891ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:53:55,189][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [1775991ms] which is above the warn threshold of [10s]; wrote global metadata [false] and metadata for [4] indices and skipped [46] unchanged indices
[2022-04-14T02:53:54,568][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.8s/24891318253ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:54:24,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:55:28,330][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64915485537ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:54:54,176][INFO ][o.e.c.c.C.CoordinatorPublication] [tpotcluster-node-01] after [38.9m] publication of cluster state version [9621] is still waiting for {tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{2FgSdrvnSUKcMpJdgOZcwA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true} [SENT_PUBLISH_REQUEST]
[2022-04-14T02:56:17,729][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/118082ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T02:57:28,940][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/118082413143ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T02:59:07,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/167091ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:03:31,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/167090427893ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:04:36,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/332490ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:06:09,161][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/332490486543ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:07:12,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/152285ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:07:44,847][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/152285194748ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:08:22,459][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67555ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:08:49,117][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67554705446ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:09:40,618][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80894ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:10:48,167][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/80893898500ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:11:43,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/114161ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:13:13,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113822224945ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:15:44,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.1m/250023ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:17:45,585][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.1m/250231572112ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:20:03,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/258435ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:23:15,144][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/258565139338ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:25:58,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/352121ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:28:50,996][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/352121275251ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:32:55,006][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/394467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:36:08,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/394467154414ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:43:26,644][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8m/650581ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:46:58,247][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.8m/649967158759ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:50:58,946][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453748ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T03:55:20,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453752955659ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T03:59:43,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6m/516124ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T04:04:57,098][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6m/516389524765ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T04:21:17,449][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.1m/966062ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T04:31:31,222][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16m/965838777843ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T04:37:08,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4m/1286435ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T04:41:43,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4m/1286647990682ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T04:45:33,094][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1m/487984ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T04:49:18,188][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1m/487651075486ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T04:49:03,614][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5103/0x00000008017d8d70@18f01f76] took [6837310ms] which is above the warn threshold of [5000ms]
[2022-04-14T04:53:11,192][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9m/477672ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T04:56:40,881][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9m/478190913794ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T05:00:44,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/452020ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T05:04:30,363][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/451718131073ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T05:08:14,085][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4m/447328ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T05:15:55,553][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-14T05:15:55,620][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-14T05:15:55,622][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-14T05:16:00,128][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-14T05:16:00,131][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-14T05:16:00,132][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-14T05:16:00,132][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-14T05:16:00,133][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-14T05:16:00,133][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-14T05:16:00,134][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-14T05:16:00,134][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-14T05:16:00,135][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-14T05:16:00,135][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-14T05:16:00,135][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-14T05:16:00,136][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-14T05:16:00,136][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-14T05:16:00,137][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-14T05:16:00,138][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-14T05:16:00,138][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-14T05:16:00,138][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-14T05:16:00,139][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-14T05:16:00,139][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-14T05:16:00,140][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-14T05:16:00,140][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-14T05:16:00,141][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-14T05:16:00,141][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-14T05:16:00,142][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-14T05:16:00,142][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-14T05:16:00,142][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-14T05:16:00,143][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-14T05:16:00,143][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-14T05:16:00,144][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-14T05:16:00,144][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-14T05:16:00,144][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-14T05:16:00,145][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-14T05:16:00,145][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-14T05:16:00,146][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-14T05:16:00,146][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-14T05:16:00,146][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-14T05:16:00,147][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-14T05:16:00,147][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-14T05:16:00,147][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-14T05:16:00,148][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-14T05:16:00,148][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-14T05:16:00,149][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-14T05:16:00,149][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-14T05:16:00,150][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-14T05:16:00,150][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-14T05:16:00,150][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-14T05:16:00,151][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-14T05:16:00,151][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-14T05:16:00,151][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-14T05:16:00,151][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-14T05:16:00,152][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-14T05:16:00,152][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-14T05:16:00,152][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-14T05:16:00,153][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-14T05:16:00,153][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-14T05:16:00,153][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-14T05:16:00,154][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-14T05:16:00,154][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-14T05:16:00,155][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-14T05:16:00,221][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.8gb], net total_space [125.8gb], types [ext4]
[2022-04-14T05:16:00,221][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-14T05:16:00,592][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-14T05:16:11,989][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-14T05:16:13,013][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-14T05:20:26,321][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@d7c2bc8, interval=5s}] took [6639ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:23:32,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@397fbf18, interval=5s}] took [16888ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:25:55,271][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@d7c2bc8, interval=5s}] took [9770ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:26:19,222][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@397fbf18, interval=5s}] took [5939ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:26:44,741][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@d7c2bc8, interval=5s}] took [7653ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:27:55,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@397fbf18, interval=5s}] took [7259ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:28:47,896][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@d7c2bc8, interval=5s}] took [19551ms] which is above the warn threshold of [5000ms]
[2022-04-14T05:32:39,375][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5068ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T05:55:38,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5068158694ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T05:59:44,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7e2d1d23, interval=1m}] took [1717495ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:00:41,820][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.6m/1717862ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:04:41,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.6m/1717495475271ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:10:23,003][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3a6eea81, interval=30s}] took [608144ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:09:53,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.1m/607778ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:17:57,350][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.1m/608144398846ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:21:54,010][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12m/721615ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:22:33,278][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@d7c2bc8, interval=5s}] took [721303ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:25:52,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12m/721303163598ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:31:07,136][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2m/557092ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:42:58,515][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-14T06:42:58,527][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-14T06:42:58,528][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-14T06:43:03,209][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-14T06:43:03,213][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-14T06:43:03,213][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-14T06:43:03,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-14T06:43:03,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-14T06:43:03,215][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-14T06:43:03,215][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-14T06:43:03,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-14T06:43:03,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-14T06:43:03,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-14T06:43:03,217][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-14T06:43:03,217][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-14T06:43:03,218][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-14T06:43:03,218][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-14T06:43:03,219][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-14T06:43:03,219][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-14T06:43:03,219][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-14T06:43:03,220][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-14T06:43:03,220][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-14T06:43:03,221][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-14T06:43:03,221][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-14T06:43:03,221][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-14T06:43:03,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-14T06:43:03,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-14T06:43:03,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-14T06:43:03,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-14T06:43:03,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-14T06:43:03,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-14T06:43:03,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-14T06:43:03,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-14T06:43:03,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-14T06:43:03,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-14T06:43:03,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-14T06:43:03,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-14T06:43:03,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-14T06:43:03,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-14T06:43:03,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-14T06:43:03,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-14T06:43:03,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-14T06:43:03,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-14T06:43:03,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-14T06:43:03,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-14T06:43:03,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-14T06:43:03,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-14T06:43:03,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-14T06:43:03,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-14T06:43:03,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-14T06:43:03,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-14T06:43:03,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-14T06:43:03,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-14T06:43:03,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-14T06:43:03,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-14T06:43:03,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-14T06:43:03,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-14T06:43:03,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-14T06:43:03,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-14T06:43:03,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-14T06:43:03,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-14T06:43:03,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-14T06:43:03,328][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.8gb], net total_space [125.8gb], types [ext4]
[2022-04-14T06:43:03,329][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-14T06:43:03,778][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-14T06:44:04,773][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-14T06:44:04,781][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-14T06:44:15,525][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7901ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:44:21,309][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7900981992ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:44:22,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7965ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:44:22,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7964843771ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:45:08,376][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-14T06:45:08,550][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-14T06:45:09,356][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-14T06:45:10,305][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-14T06:45:10,317][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-14T06:45:10,520][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-14T06:45:10,885][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-14T06:45:13,269][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-14T06:46:25,258][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@76a6779a] took [7739ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:47:03,258][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [6174ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:47:32,632][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21399ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:47:53,135][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21399031785ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:48:02,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34171ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:48:14,604][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34171374311ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:48:26,323][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23475ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:48:38,592][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [57645ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:48:38,592][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.4s/23474349383ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:48:53,872][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27820ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:49:04,734][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27819743391ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:49:20,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.8s/25843ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:49:33,535][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.8s/25843196376ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:49:50,185][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.5s/27579ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:49:58,709][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [53422ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:50:01,490][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.5s/27579203836ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:13,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26779ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:23,821][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26778575037ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:27,064][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14539ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:26,078][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [54358ms] which is above the warn threshold of [5s]
[2022-04-14T06:50:29,485][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.5s/14539497036ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:28,481][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [14539ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:50:32,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5240ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:32,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c392ecb, interval=1m}] took [5240ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:50:35,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5240139536ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:38,938][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [5863ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:50:38,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8s/5863ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:42,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8s/5863233986ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:44,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1s/6159ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:46,552][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1s/6158774098ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:50:47,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6158ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:51:30,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6184ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:51:47,868][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][49][9] duration [952ms], collections [1]/[2.8s], total [952ms]/[1.4s], memory [286.2mb]->[69mb]/[2gb], all_pools {[young] [216mb]->[8mb]/[0b]}{[old] [46.3mb]->[57mb]/[2gb]}{[survivor] [23.9mb]->[12mb]/[0b]}
[2022-04-14T06:51:48,458][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][49] overhead, spent [952ms] collecting in the last [2.8s]
[2022-04-14T06:51:48,523][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6102ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:52:26,226][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [25479ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:52:49,501][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [7116ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:53:21,688][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [5956ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:53:58,608][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5097ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:54:11,276][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5s/5097361292ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:54:23,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24159ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:54:29,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [32384ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:54:31,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.1s/24158415496ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:54:43,430][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c392ecb, interval=1m}] took [21767ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:54:43,772][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21767ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:54:53,550][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21767753982ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:55:09,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24944ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:55:23,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.9s/24943884471ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:55:24,966][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [24944ms] which is above the warn threshold of [5s]
[2022-04-14T06:55:34,332][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.4s/25402ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:55:53,545][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.4s/25402063084ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:56:01,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [25402ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:56:18,549][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.5s/43569ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:56:36,819][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.5s/43568649657ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:57:03,209][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43856ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:57:25,730][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43856367892ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:57:46,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.7s/43763ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:57:46,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [43856ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:58:02,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.7s/43762849976ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:58:24,077][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.8s/35854ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:58:30,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [35853ms] which is above the warn threshold of [5000ms]
[2022-04-14T06:58:52,055][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.8s/35853602677ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T06:59:15,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.1s/50143ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T06:59:39,136][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.1s/50143316744ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:00:09,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.3s/54367ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:00:33,217][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [54366ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:00:43,373][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.3s/54366515165ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:01:08,959][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60263ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:01:10,206][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [60263ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:01:35,297][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60263486027ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:02:03,842][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@76a6779a] took [51886ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:02:01,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.8s/51887ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:02:26,666][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.8s/51886684022ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:02:51,157][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.9s/48931ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:03:13,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.9s/48931700548ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:03:42,456][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.9s/50951ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:03:49,459][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [99882ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:04:02,984][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.9s/50950627307ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:04:26,803][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [46167ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:04:26,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.1s/46168ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:04:50,478][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.1s/46167849127ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:05:09,262][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.7s/42775ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:05:28,623][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.7s/42775204386ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:05:53,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@dcfacba, interval=1m}] took [44464ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:05:52,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.4s/44465ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:06:08,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.4s/44464433724ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:06:26,839][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34331ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:05:45,020][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [42776ms] which is above the warn threshold of [5s]
[2022-04-14T07:06:37,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34331845745ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:06:47,004][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [34331ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:06:47,004][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22501ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:06:59,245][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.5s/22500993456ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:07:22,124][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.4s/34491ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:07:40,106][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.4s/34490710091ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:07:39,988][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [34490ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:07:47,395][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25186ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:07:56,463][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25186000794ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:06,546][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.2s/19276ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:15,505][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.2s/19275993567ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:25,195][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18626ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:27,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [37901ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:08:35,048][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18625605158ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:45,317][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [18616ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:08:44,058][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18616ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:53,007][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18616342172ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:09:02,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.1s/17105ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:09:12,355][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.1s/17104652416ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:09:28,177][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25367ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:09:36,604][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [42471ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:09:40,533][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25367276858ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:09:53,763][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27442ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:09:53,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@dcfacba, interval=1m}] took [27442ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:10:06,435][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27442213253ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:10:22,875][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@27a9f50c, interval=30s}] took [26803ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:10:21,376][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.8s/26804ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:10:36,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.8s/26803606801ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:10:54,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.3s/33387ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:10:23,693][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [27443ms] which is above the warn threshold of [5s]
[2022-04-14T07:11:07,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.3s/33387322783ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:11:23,265][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [33387ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:11:33,729][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.9s/37968ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:11:47,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.9s/37967566290ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:11:50,007][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@27a9f50c, interval=30s}] took [18867ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:11:49,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.8s/18867ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:11:52,118][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.8s/18867489057ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:11:56,975][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7171ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:12:31,971][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5796ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:12:34,082][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5795752974ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:08:28,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@cfd077b] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-14T07:13:13,717][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [13033ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:14:03,757][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][99][10] duration [1.5s], collections [1]/[1.5s], total [1.5s]/[2.9s], memory [153mb]->[153mb]/[2gb], all_pools {[young] [84mb]->[84mb]/[0b]}{[old] [57mb]->[57mb]/[2gb]}{[survivor] [12mb]->[12mb]/[0b]}
[2022-04-14T07:14:04,544][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][99] overhead, spent [1.5s] collecting in the last [1.5s]
[2022-04-14T07:14:05,228][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5353ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:14:31,732][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6008ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:14:59,764][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5203ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:15:35,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [13815ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:16:34,437][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [32345ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:16:27,698][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [19515ms] which is above the warn threshold of [5s]
[2022-04-14T07:17:51,869][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [44065ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:18:18,678][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [8815ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:18:46,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8697ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:19:39,067][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [35802ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:20:11,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [11608ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:20:15,023][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [13948ms] which is above the warn threshold of [5s]
[2022-04-14T07:20:42,004][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [11886ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:21:11,181][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [10005ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:21:32,022][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7003ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:21:56,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9405ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:22:20,723][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [10309ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:22:43,578][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [10806ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:23:02,306][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [9806ms] which is above the warn threshold of [5s]
[2022-04-14T07:23:04,736][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8204ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:23:21,276][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [5921ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:23:35,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9794ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:23:53,733][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8004ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:24:04,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [7439ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:24:14,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6803ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:24:26,008][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5748ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:24:48,990][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [14408ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:25:04,395][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5915ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:25:21,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7404ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:25:47,757][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [13207ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:25:45,064][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14207ms] which is above the warn threshold of [5s]
[2022-04-14T07:26:02,918][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [5803ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:26:26,732][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [13362ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:27:02,761][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [13215ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:27:53,095][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [32163ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:28:50,802][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [33200ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:29:12,622][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [5324ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:29:41,079][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [30769ms] which is above the warn threshold of [5s]
[2022-04-14T07:29:36,571][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [7314ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:30:28,949][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [31003ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:28:21,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@cfd077b] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-14T07:30:55,082][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7808ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:31:34,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [23882ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:31:59,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9605ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:32:22,065][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [5134ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:32:49,025][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [11183ms] which is above the warn threshold of [5s]
[2022-04-14T07:32:43,908][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9964ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:33:19,933][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [13207ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:33:50,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8004ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:34:13,226][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9459ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:34:33,637][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7013ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:34:46,847][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5125ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:35:15,887][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7072ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:35:28,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5260ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:35:43,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8204ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:36:02,163][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [5803ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:36:17,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6244ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:36:37,817][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9269ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:36:51,856][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [6003ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:37:12,396][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [12006ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:37:36,231][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9668ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:37:36,348][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [12340ms] which is above the warn threshold of [5s]
[2022-04-14T07:37:55,029][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9513ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:38:11,707][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8354ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:38:35,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [9360ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:39:04,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [11806ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:39:35,234][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [14131ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:39:55,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8780ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:40:17,835][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [11836ms] which is above the warn threshold of [5s]
[2022-04-14T07:40:19,947][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6722ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:40:34,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6668ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:40:49,106][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [6003ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:41:22,411][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [19097ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:41:42,193][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [5459ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:42:13,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [16310ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:42:43,927][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [11110ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:43:03,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [8801ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:43:06,768][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [11325ms] which is above the warn threshold of [5s]
[2022-04-14T07:43:46,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [24512ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:44:37,770][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [30021ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:45:36,745][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [30514ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:46:14,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [16182ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:46:17,335][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14068ms] which is above the warn threshold of [5s]
[2022-04-14T07:46:56,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [22555ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:46:30,282][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@cfd077b] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-14T07:47:22,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [15079ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:47:51,160][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [14966ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:48:14,125][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4s/6445ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:48:33,133][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4s/6445087662ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:48:47,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.8s/36890ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:48:52,038][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [36889ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:48:55,008][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.8s/36889242549ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:49:04,077][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17067ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:49:08,675][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [17068ms] which is above the warn threshold of [5s]
[2022-04-14T07:49:13,228][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17067577211ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:49:21,717][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17486ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:49:34,635][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [17486ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:49:31,900][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17486084733ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:49:43,314][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21324ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:49:44,392][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@27a9f50c, interval=30s}] took [21323ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:49:53,261][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21323889621ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:50:01,095][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c392ecb, interval=1m}] took [18686ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:50:01,535][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18687ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:50:07,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18686474230ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:50:17,856][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15353ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:50:28,759][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15353701648ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:50:36,733][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [15353ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:50:37,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21023ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:50:51,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21022432854ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:51:02,724][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.8s/23893ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:51:08,917][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [23892ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:51:13,093][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.8s/23892996505ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:51:22,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19614ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:51:25,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [19614ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:51:33,636][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19614812420ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:51:43,918][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21568ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:51:57,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21567105691ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:52:10,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25976ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:52:20,733][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25976202890ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:52:22,087][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [47543ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:52:29,570][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.4s/20488ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:52:35,328][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.4s/20488230113ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:52:46,021][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15852ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:52:50,007][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [15852ms] which is above the warn threshold of [5s]
[2022-04-14T07:52:57,424][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15851738317ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:53:05,120][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [35856ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:53:05,120][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20004ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:53:15,904][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20004426535ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:53:25,345][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.7s/19708ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:53:25,051][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [19707ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:53:40,768][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.7s/19707684517ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:53:53,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.9s/27911ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:01,648][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.9s/27911573739ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:01,765][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [27911ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:54:04,925][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.5s/12551ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:06,091][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [12550ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:54:07,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.5s/12550797136ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:12,451][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3s/7331ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:14,125][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7330ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:54:16,260][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3s/7330385233ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:19,893][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1s/7146ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:28,285][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1s/7146638175ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:29,549][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [7146ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:54:35,503][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15207ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:41,426][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15206383641ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:49,606][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14735ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:54:54,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [14735ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:54:56,882][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.7s/14735547055ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:05,149][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15363ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:07,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [15362ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:55:13,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15362443433ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:22,440][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16804ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:30,003][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [16803ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:55:30,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8s/16803862236ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:39,212][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17375ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:47,220][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17375257243ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:54,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14874ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:55:54,748][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14874ms] which is above the warn threshold of [5s]
[2022-04-14T07:56:01,644][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.8s/14873866840ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:56:03,197][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [14873ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:56:09,904][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15s/15035ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:56:09,637][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@76a6779a] took [15035ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:56:19,980][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15s/15035609548ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:56:27,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [18143ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:56:27,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18143ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:56:38,091][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18143147242ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:56:49,532][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21371ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:56:59,992][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21370537191ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:57:02,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [21370ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:57:10,574][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21901ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:57:19,570][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21901340482ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:57:32,442][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.6s/20628ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:57:45,711][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [20627ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:57:46,106][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.6s/20627872216ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:57:59,761][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27868ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:58:01,451][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7c392ecb, interval=1m}] took [27867ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:58:09,276][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27867545789ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:58:23,271][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:58:35,139][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23235541921ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:58:50,301][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26568ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:58:57,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [49803ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:58:58,455][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26568143393ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:59:08,068][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18591ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:59:13,796][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [18590ms] which is above the warn threshold of [5000ms]
[2022-04-14T07:59:18,885][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18590162706ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:59:29,897][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [22223ms] which is above the warn threshold of [5s]
[2022-04-14T07:59:29,897][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22222ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T07:59:45,802][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.2s/22222604478ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T07:59:57,870][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.2s/27243ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:00:10,413][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.2s/27242515627ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:00:10,414][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [27242ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:00:21,882][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24430ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:00:23,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@76a6779a] took [24430ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:00:31,706][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24430290966ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:00:39,165][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17408ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:00:39,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [17407ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:00:54,665][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.4s/17407935031ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:01:07,046][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26528ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:01:25,969][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26528444133ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:01:41,441][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35953ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:01:50,364][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [62481ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:01:56,505][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35952956364ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:02:12,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [30695ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:02:12,732][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30696ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:02:34,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30695648567ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:02:57,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43618ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:03:07,666][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [43618ms] which is above the warn threshold of [5s]
[2022-04-14T08:03:16,512][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43617926329ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:03:27,882][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [43617ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:03:44,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.2s/46212ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:04:02,390][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.2s/46212153999ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:04:20,260][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35940ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:04:37,610][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.9s/35939493385ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:04:56,459][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [35939ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:04:56,548][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38232ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:05:18,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38232397355ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:05:38,802][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.4s/40471ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:06:06,388][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.4s/40471384324ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:06:27,726][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [40471ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:06:28,051][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.4s/50448ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:04:13,108][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@cfd077b] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-14T08:06:53,290][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.4s/50447624495ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:07:19,696][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.3s/49308ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:07:49,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.3s/49308339014ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:07:49,143][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [49309ms] which is above the warn threshold of [5s]
[2022-04-14T08:08:16,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.2s/58217ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:08:20,381][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [107525ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:08:36,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.2s/58216747743ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:08:58,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40509ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:09:17,792][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40509488406ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:09:37,967][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40657ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:09:53,809][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [81166ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:09:53,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40656602074ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:10:21,884][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.3s/45318ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:10:23,655][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@5f32f6c1, interval=5s}] took [45317ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:10:33,444][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.3s/45317897884ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:10:47,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25798ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:11:00,798][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25797714780ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:11:12,491][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24078ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:11:24,405][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [49876ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:11:32,849][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24078334954ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:11:52,806][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40743ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:11:55,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@652050fb, interval=5s}] took [40742ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:12:04,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40742952354ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:12:21,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27703ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:12:47,453][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27702951750ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:13:07,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [27702ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:13:07,817][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.3s/47335ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:13:29,077][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.3s/47334762302ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:13:56,837][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47934ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:14:23,378][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47934623685ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:14:50,938][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.3s/51355ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:14:57,821][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [99289ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:15:15,062][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.3s/51355137052ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:15:39,036][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.7s/48724ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:16:04,647][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.7s/48723899497ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:16:29,184][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [49551ms] which is above the warn threshold of [5s]
[2022-04-14T08:16:26,738][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.5s/49552ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:16:54,656][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.5s/49551284678ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:16:49,348][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [49551ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:17:21,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.8s/52886ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:17:51,295][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.8s/52886128208ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-14T08:18:22,821][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64294ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-14T08:18:49,247][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@497ca50e, interval=1s}] took [64293ms] which is above the warn threshold of [5000ms]
[2022-04-14T08:18:48,366][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64293747648ns] on relative clock which is above the warn threshold of [5000ms]
