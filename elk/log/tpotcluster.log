[2022-04-04T16:08:07,309][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-04T16:08:07,331][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-04T16:08:07,331][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-04T16:08:14,761][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-04T16:08:14,762][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-04T16:08:14,763][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-04T16:08:14,763][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-04T16:08:14,764][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-04T16:08:14,764][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-04T16:08:14,765][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-04T16:08:14,765][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-04T16:08:14,766][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-04T16:08:14,767][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-04T16:08:14,767][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-04T16:08:14,768][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-04T16:08:14,768][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-04T16:08:14,769][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-04T16:08:14,769][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-04T16:08:14,770][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-04T16:08:14,775][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-04T16:08:14,775][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-04T16:08:14,776][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-04T16:08:14,776][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-04T16:08:14,777][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-04T16:08:14,777][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-04T16:08:14,777][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-04T16:08:14,778][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-04T16:08:14,778][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-04T16:08:14,779][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-04T16:08:14,779][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-04T16:08:14,780][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-04T16:08:14,780][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-04T16:08:14,780][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-04T16:08:14,781][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-04T16:08:14,781][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-04T16:08:14,781][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-04T16:08:14,782][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-04T16:08:14,782][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-04T16:08:14,783][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-04T16:08:14,783][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-04T16:08:14,783][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-04T16:08:14,784][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-04T16:08:14,784][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-04T16:08:14,785][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-04T16:08:14,785][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-04T16:08:14,785][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-04T16:08:14,786][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-04T16:08:14,786][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-04T16:08:14,787][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-04T16:08:14,787][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-04T16:08:14,787][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-04T16:08:14,792][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-04T16:08:14,792][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-04T16:08:14,793][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-04T16:08:14,793][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-04T16:08:14,794][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-04T16:08:14,794][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-04T16:08:14,795][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-04T16:08:14,795][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-04T16:08:14,796][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-04T16:08:14,796][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-04T16:08:14,797][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-04T16:08:14,888][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [105.6gb], net total_space [125.8gb], types [ext4]
[2022-04-04T16:08:14,889][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-04T16:08:15,192][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-04T16:08:26,100][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-04T16:08:26,104][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-04T16:08:27,051][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-04T16:08:27,162][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-04T16:08:27,862][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-04T16:08:28,632][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-04T16:08:28,633][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-04T16:08:28,670][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-04T16:08:28,672][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-04T16:08:28,884][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-04T16:08:30,971][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-04T16:08:31,103][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 201, version: 7170, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-04T16:08:31,269][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 201, version: 7170, reason: Publication{term=201, version=7170}
[2022-04-04T16:08:31,377][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-04T16:08:31,378][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-04T16:08:32,300][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-04T16:08:32,306][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [37] indices into cluster_state
[2022-04-04T16:08:33,014][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-04T16:08:33,015][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-04T16:08:33,629][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-ASN.mmdb]
[2022-04-04T16:08:34,081][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-04T16:08:34,084][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-04T16:08:34,090][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-04T16:08:34,830][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-04T16:08:34,904][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-04T16:08:36,548][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-04T16:08:36,577][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-ASN.mmdb]
[2022-04-04T16:08:36,589][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-City.mmdb]
[2022-04-04T16:08:36,965][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-04T16:08:36,989][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-04T16:08:37,890][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-04T16:08:39,592][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-ilm-history-5-2022.03.12-000001][0]]]).
[2022-04-04T16:08:41,313][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-04T16:08:41,325][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-City.mmdb]
[2022-04-04T16:08:41,327][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-Country.mmdb]
[2022-04-04T16:08:41,976][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-04T16:08:41,999][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-Country.mmdb]
[2022-04-04T16:08:42,167][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-04T16:08:42,169][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-04T16:08:42,805][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-04T16:08:42,806][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-04T16:08:52,684][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-04-04T16:08:52,870][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-04-04T16:09:36,267][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 871 finished with response BulkByScrollResponse[took=585.6ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-04T16:09:39,061][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 891 finished with response BulkByScrollResponse[took=3s,timed_out=false,sliceId=null,updated=1028,created=0,deleted=0,batches=2,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-04T16:09:46,349][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-04-04T16:10:17,352][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-2022.04.04] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-04T16:10:17,615][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-2022.04.04][0]]]).
[2022-04-04T16:10:17,941][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:18,037][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:18,047][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:18,063][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:18,320][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:33,766][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:36,995][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:47,732][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:48,014][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:48,173][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:49,378][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:10:50,810][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:06,547][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:06,737][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:07,856][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:08,039][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:32,023][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:32,107][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:33,046][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:33,125][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:34,075][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:34,173][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:34,184][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:34,305][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:34,375][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:40,638][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:11:56,026][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:14:08,831][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:16:03,249][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:16:18,264][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:49,059][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:49,280][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:49,401][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:49,480][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:49,543][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:49,636][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:17:50,448][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:19:49,484][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:21:40,555][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:22:15,587][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:28:00,585][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:33:18,785][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:33:18,884][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:33:18,960][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:33:19,065][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:33:19,089][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:36:34,190][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T16:37:11,846][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_all/_settings?expand_wildcards=open%2Cclosed][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.1:40528}] took [7401ms] which is above the warn threshold of [5000ms]
[2022-04-04T16:38:34,934][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [5931ms] which is above the warn threshold of [5000ms]
[2022-04-04T16:39:22,761][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7s/9741ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:43:07,642][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7s/9741431358ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:43:35,752][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/269456ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:44:41,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/269455526717ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:45:12,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/101901ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:46:43,522][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/101901173230ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:48:47,965][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.6m/216264ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:50:00,859][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.6m/216264378815ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:50:20,835][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93193ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:50:37,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93096028806ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:51:51,070][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90284ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:52:06,864][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90380217583ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:52:17,606][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26716ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:53:05,182][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26716455966ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:53:35,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76659ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:55:13,553][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/76659168792ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:53:44,171][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [26717ms] which is above the warn threshold of [5s]
[2022-04-04T16:55:54,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/139880ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:56:16,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/139879703406ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:56:35,268][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.8s/38828ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:56:57,151][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.8s/38828504887ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:57:16,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.9s/42977ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:57:33,645][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.9s/42976796494ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:57:46,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.7s/30738ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:57:57,210][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.7s/30737680945ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:58:17,561][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30514ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:58:32,658][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30514317768ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T16:58:47,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.3s/30356ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T16:59:19,809][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.3s/30355938894ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:00:53,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126194ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:01:17,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126193552490ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:01:16,695][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@26d47e70, interval=5s}] took [126193ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:01:20,831][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@67aa83d3, interval=5s}] took [27982ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:01:20,804][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.9s/27983ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:01:26,400][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.9s/27982990803ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:01:30,163][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.4s/9475ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:01:44,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.4s/9475555569ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:09,078][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.4s/38494ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:14,212][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [38493ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:02:17,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.4s/38493638085ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:39,696][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30555ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:12,912][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [38493ms] which is above the warn threshold of [5s]
[2022-04-04T17:02:43,114][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30554748514ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:44,651][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_cluster/state/metadata/.apm-agent-configuration,.apm-custom-link,.async-search,.kibana_7.16.2_001,.kibana_7.17.0_001,.kibana_task_manager_7.16.2_001,.kibana_task_manager_7.17.0_001,.tasks,logstash-1970.01.01,logstash-2022.03.13,logstash-2022.03.14,logstash-2022.03.15,logstash-2022.03.16,logstash-2022.03.17,logstash-2022.03.18,logstash-2022.03.19,logstash-2022.03.20,logstash-2022.03.21,logstash-2022.03.22,logstash-2022.03.23,logstash-2022.03.24,logstash-2022.03.25,logstash-2022.03.26,logstash-2022.03.27,logstash-2022.03.28,logstash-2022.03.29,logstash-2022.03.30,logstash-2022.03.31,logstash-2022.04.01,logstash-2022.04.02,logstash-2022.04.03,logstash-2022.04.04][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.1:40528}] took [1522956ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:02:45,559][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1s/6118ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:46,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1s/6118231182ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:56,678][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2s/6229ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:56,845][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:44774}] took [11125ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:02:57,568][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [6229ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:02:58,034][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2s/6229365615ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:02:49,782][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [23.7m/1426584ms] ago, timed out [1.4m/84642ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [13137]
[2022-04-04T17:03:07,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.1s/11109ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:22,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [11108ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:03:22,384][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.1s/11108278030ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:26,763][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@67aa83d3, interval=5s}] took [17876ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:03:25,801][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.8s/17876ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:29,450][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.8s/17876592731ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:33,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8s/8024ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:37,064][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8s/8023543515ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:52,978][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.2s/19229ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:56,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.2s/19229398331ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:03:56,322][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [19229ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:04:01,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@451d2502, interval=1m}] took [8668ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:04:01,871][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6s/8669ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:04:06,246][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.6s/8668875824ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:04:10,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2s/9264ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:04:10,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@26d47e70, interval=5s}] took [9264ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:04:12,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.2s/9264159509ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:04:03,289][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/.apm-agent-configuration,.apm-custom-link,.async-search,.kibana_7.16.2_001,.kibana_7.17.0_001,.kibana_task_manager_7.16.2_001,.kibana_task_manager_7.17.0_001,.tasks,logstash-1970.01.01,logstash-2022.03.13,logstash-2022.03.14,logstash-2022.03.15,logstash-2022.03.16,logstash-2022.03.17,logstash-2022.03.18,logstash-2022.03.19,logstash-2022.03.20,logstash-2022.03.21,logstash-2022.03.22,logstash-2022.03.23,logstash-2022.03.24,logstash-2022.03.25,logstash-2022.03.26,logstash-2022.03.27,logstash-2022.03.28,logstash-2022.03.29,logstash-2022.03.30,logstash-2022.03.31,logstash-2022.04.01,logstash-2022.04.02,logstash-2022.04.03,logstash-2022.04.04/_stats/store,docs][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.1:40540}] took [8669ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:04:12,711][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [13137] timed out after [1341942ms]
[2022-04-04T17:04:34,728][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9365ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:04:38,183][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [11966ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:04:38,425][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3s/9364396127ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:04:57,359][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:04:57,822][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:04:58,000][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:04:58,009][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:04:58,482][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:04:59,176][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:04:59,305][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:05:05,312][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:05:05,895][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.04/wEdvpaoYSXeRKrjiLgl3Ig] update_mapping [_doc]
[2022-04-04T17:05:25,076][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1768][36] duration [1.1s], collections [1]/[2.8s], total [1.1s]/[2.4s], memory [1.3gb]->[207.9mb]/[2gb], all_pools {[young] [1.1gb]->[0b]/[0b]}{[old] [197.7mb]->[197.7mb]/[2gb]}{[survivor] [5mb]->[10.1mb]/[0b]}
[2022-04-04T17:05:26,084][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1768] overhead, spent [1.1s] collecting in the last [2.8s]
[2022-04-04T17:05:27,159][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [9578ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:05:29,868][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1770] overhead, spent [646ms] collecting in the last [1.1s]
[2022-04-04T17:05:32,316][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1771][38] duration [1s], collections [1]/[2.6s], total [1s]/[4.1s], memory [220.6mb]->[207.2mb]/[2gb], all_pools {[young] [12mb]->[0b]/[0b]}{[old] [205.9mb]->[205.9mb]/[2gb]}{[survivor] [2.6mb]->[1.3mb]/[0b]}
[2022-04-04T17:05:32,612][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1771] overhead, spent [1s] collecting in the last [2.6s]
[2022-04-04T17:05:41,640][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [6030ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:06:13,893][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1778][39] duration [2.2s], collections [1]/[3.5s], total [2.2s]/[6.4s], memory [295.2mb]->[210.4mb]/[2gb], all_pools {[young] [88mb]->[0b]/[0b]}{[old] [205.9mb]->[205.9mb]/[2gb]}{[survivor] [1.3mb]->[4.4mb]/[0b]}
[2022-04-04T17:06:15,061][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1778] overhead, spent [2.2s] collecting in the last [3.5s]
[2022-04-04T17:06:25,408][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [5423ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:07:12,741][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [28004ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:11:22,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017ea020@19ed9812] took [188780ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:12:25,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10747ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:12:24,787][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:45584}] took [22415ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:11:43,633][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:45580}] took [12526ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:12:53,519][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.7s/10746530555ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:13:05,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47956ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:13:18,428][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.9s/47956186367ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:13:32,458][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26981ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:13:40,955][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26980603717ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:13:52,593][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19565ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:14:09,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19565791434ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:14:10,070][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@67aa83d3, interval=5s}] took [19565ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:13:36,615][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:45582}] took [26980ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:14:21,385][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.1s/29146ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:14:38,832][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.1s/29145893445ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:15:31,122][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68637ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:14:23,070][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [29146ms] which is above the warn threshold of [5s]
[2022-04-04T17:15:51,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68637139438ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:16:07,357][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.1s/37190ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:16:50,129][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.1s/37189761097ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:17:48,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/101536ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:18:02,441][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [138725ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:18:17,467][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/101535969927ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:19:08,081][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78630ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:20:22,142][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78630037614ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:21:08,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/119489ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:23:33,677][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/119489165939ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:23:51,669][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/164774ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:24:08,566][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/164774132379ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:26:10,541][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43650ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:26:17,498][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43649999898ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:26:27,301][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/111999ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:26:35,972][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:33118}] took [439911ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:26:36,078][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/111998260661ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:27:11,263][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.2s/44244ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:27:52,732][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [44.2s/44244655187ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:01,118][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.1s/50196ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:06,451][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.1s/50195498363ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:08,560][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:33110}] took [50195ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:28:11,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.9s/8985ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:04,047][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [13628] timed out after [915415ms]
[2022-04-04T17:28:13,978][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.9s/8984729677ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:29,122][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18633ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:36,640][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:45586}] took [18634ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:28:42,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18633661913ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:28:54,306][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.4s/25448ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:29:26,549][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.4s/25447638287ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:29:46,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52s/52099ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:29:52,688][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@451d2502, interval=1m}] took [52099ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:29:59,545][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52s/52099364439ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:30:13,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26513ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:30:28,392][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.5s/26513162573ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:30:56,910][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.6s/41680ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:31:19,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.6s/41679339936ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:31:36,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40541ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:31:09,897][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [41679ms] which is above the warn threshold of [5s]
[2022-04-04T17:31:40,287][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1783][40] duration [1m], collections [1]/[14.3m], total [1m]/[1.2m], memory [242.4mb]->[243.3mb]/[2gb], all_pools {[young] [36mb]->[32mb]/[0b]}{[old] [205.9mb]->[205.9mb]/[2gb]}{[survivor] [4.4mb]->[5.3mb]/[0b]}
[2022-04-04T17:31:49,362][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40541648713ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:31:58,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [82220ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:32:03,858][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.1s/28180ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:32:19,940][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.1s/28179574852ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:32:34,991][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31142ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:32:44,872][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31141572596ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:32:53,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19118ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:33:09,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19118258501ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:33:21,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27054ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:33:29,487][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27s/27054436662ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:33:31,352][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017ea020@1e5c2a57] took [27054ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:33:34,892][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14357ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:33:43,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14356930488ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:33:56,045][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.7s/20726ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:06,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.7s/20725969807ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:13,533][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.2s/17207ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:23,647][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.2s/17206508767ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:28,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [17206ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:34:31,996][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18679ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:36,595][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18678964660ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:46,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14442ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:34:57,632][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.4s/14442756600ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:35:06,036][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19633ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:35:09,107][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@67aa83d3, interval=5s}] took [19632ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:35:13,636][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.6s/19632716029ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:35:25,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19434ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:35:38,971][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19434009833ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:35:58,879][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.3s/33310ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:36:25,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.3s/33309814725ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:36:36,897][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38370ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:36:40,912][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [71680ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:36:13,288][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [33310ms] which is above the warn threshold of [5s]
[2022-04-04T17:36:52,469][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38370449888ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:52:18,545][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.6m/941849ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:52:21,061][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.6m/941848721409ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:52:18,545][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [13726] timed out after [85411ms]
[2022-04-04T17:52:24,290][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [41.2m/2472792ms] ago, timed out [25.9m/1557377ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [13628]
[2022-04-04T17:52:23,995][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5s/5537ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:52:24,583][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5s/5536665331ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:52:33,860][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1786][41] duration [14.9m], collections [1]/[16.5m], total [14.9m]/[16.1m], memory [259.3mb]->[258.8mb]/[2gb], all_pools {[young] [52mb]->[48mb]/[0b]}{[old] [205.9mb]->[205.9mb]/[2gb]}{[survivor] [5.3mb]->[4.8mb]/[0b]}
[2022-04-04T17:52:36,760][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1786] overhead, spent [14.9m] collecting in the last [16.5m]
[2022-04-04T17:52:38,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [12807ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:52:39,326][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [19.3m/1158817ms] ago, timed out [17.8m/1073406ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [13726]
[2022-04-04T17:53:28,131][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.2s/47287ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:53:38,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.2s/47287531328ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:53:45,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17674ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:53:53,343][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17673451824ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:53:40,367][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [47888ms] which is above the warn threshold of [5s]
[2022-04-04T17:54:01,558][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16034ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:54:04,675][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][1787][42] duration [36.3s], collections [1]/[13.8s], total [36.3s]/[16.7m], memory [258.8mb]->[298.8mb]/[2gb], all_pools {[young] [48mb]->[0b]/[0b]}{[old] [205.9mb]->[205.9mb]/[2gb]}{[survivor] [4.8mb]->[4.7mb]/[0b]}
[2022-04-04T17:54:08,960][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16s/16034082805ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:54:15,228][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][1787] overhead, spent [36.3s] collecting in the last [13.8s]
[2022-04-04T17:54:18,642][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17057ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:54:23,524][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [98252ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:54:26,441][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17057006150ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:54:36,517][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17900ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:54:38,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@26d47e70, interval=5s}] took [17900ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:54:45,135][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17900061666ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:54:54,769][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18352ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:02,413][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18352383537ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:12,240][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.2s/17294ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:19,621][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.2s/17293979736ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:25,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13308ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:34,422][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13308033099ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:42,619][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16668ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:55:56,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [16667ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:55:56,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16667219280ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:56:06,221][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23932ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:56:18,545][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23932195655ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:56:37,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31709ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:56:56,872][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31708916148ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:57:14,285][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.7s/35782ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:57:26,680][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.7s/35782489547ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:57:49,173][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.3s/35321ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:58:06,682][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.3s/35320749451ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:58:14,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [35320ms] which is above the warn threshold of [5000ms]
[2022-04-04T17:58:23,554][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34333ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:58:36,566][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34332731637ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:58:47,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24063ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:01,583][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24s/24063289769ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:13,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26167ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:23,671][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26166903554ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:31,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18571ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:09,156][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [13842] timed out after [85616ms]
[2022-04-04T17:59:42,496][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18570769955ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:58,828][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26403ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:00:10,213][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26403012443ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T17:59:38,230][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [44737ms] which is above the warn threshold of [5s]
[2022-04-04T18:00:25,966][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27322ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:00:42,749][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27322542441ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:00:55,793][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.8s/29892ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:01:06,845][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [57214ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:01:10,257][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.8s/29891720142ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:01:24,510][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.9s/28980ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:01:37,275][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.9s/28980055345ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:01:54,734][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28866ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:02:06,590][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28866437565ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:02:23,333][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.6s/29663ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:02:38,015][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.6s/29662917778ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:02:54,484][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28814ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:02:56,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017ea020@4915e650] took [28813ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:03:06,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28813755871ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:03:19,683][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27439ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:03:33,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27438881572ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:03:45,077][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25753ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:04:03,747][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25753250949ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:04:09,405][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [25753ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:04:16,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.8s/30833ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:04:28,010][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.8s/30833156211ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:04:39,653][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23211ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:04:52,182][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23210481390ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:05:06,211][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26712ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:05:20,304][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26711820219ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:05:29,061][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [9.8m/593741ms] ago, timed out [8.4m/508125ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [13842]
[2022-04-04T18:05:43,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37s/37035ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:05:23,622][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [26712ms] which is above the warn threshold of [5s]
[2022-04-04T18:06:11,147][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37s/37035349720ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:06:19,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.8s/36882ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:06:27,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.8s/36881779119ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:06:37,861][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17941ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:06:50,814][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17941337358ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:06:57,570][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19998ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:07:08,746][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19997909080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:07:21,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23784ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:07:21,719][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017ea020@12b63aa8] took [23784ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:07:32,125][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23784077858ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:07:40,189][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18516ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:07:49,420][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.5s/18515982589ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:07:58,277][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17673ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:08:01,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [36188ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:08:05,871][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.6s/17672636680ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:08:15,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17579ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:08:17,990][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@26d47e70, interval=5s}] took [17579ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:08:26,354][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.5s/17579313899ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:08:37,599][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21554ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:08:40,467][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@67aa83d3, interval=5s}] took [21553ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:08:48,398][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21553878090ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:08:57,946][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21031ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:09:12,806][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21s/21031219501ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:09:23,375][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25310ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:09:35,007][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25310303968ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:09:51,195][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27759ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:10:02,430][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27758301906ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:10:18,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.2s/27265ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:10:32,448][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.2s/27265617257ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:10:53,737][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27122ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:11:15,773][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27121327091ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:11:24,745][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [27121ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:11:33,321][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.7s/47787ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:11:48,383][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.7s/47787048396ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:12:04,180][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.4s/30463ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:12:05,821][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@67aa83d3, interval=5s}] took [30463ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:12:21,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.4s/30463017791ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:12:39,159][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35s/35018ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:12:23,899][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [14007] timed out after [173205ms]
[2022-04-04T18:12:54,121][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35s/35018464866ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:12:25,385][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [30463ms] which is above the warn threshold of [5s]
[2022-04-04T18:13:20,087][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41s/41018ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:13:36,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41s/41017708560ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:13:57,904][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.9s/37997ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:14:13,831][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.9s/37997529966ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:14:33,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.7s/34759ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:14:58,526][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.7s/34758291466ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:15:16,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.5s/43511ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:15:34,324][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.5s/43511446866ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:15:40,357][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [43511ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:16:01,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.1s/43155ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:16:28,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.1s/43155212334ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:16:48,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48166ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:17:10,061][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.1s/48165740181ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:17:28,043][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40553ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:17:43,605][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40553338740ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:18:00,970][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.4s/32402ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:18:17,551][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.4s/32401898022ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:18:42,949][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.4s/42460ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:19:01,692][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.4s/42459924965ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:18:59,596][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017ea020@72dbb473] took [42459ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:19:23,514][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40374ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:19:40,199][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40373965500ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:20:03,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.1s/39105ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:20:25,211][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.1s/39104617058ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:20:48,316][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40762ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:21:14,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40761932024ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:21:45,137][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/61643ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:20:41,471][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [13m/784360ms] ago, timed out [10.1m/611155ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{fQ3QzbzCT3q6oRtMWvm2JQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [14007]
[2022-04-04T18:22:05,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/61643464930ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:22:30,826][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45702ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:22:48,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.7s/45701637386ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:23:17,073][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.3s/46353ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:23:36,395][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.3s/46352956835ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:24:21,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63735ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:25:01,022][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63735067184ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:25:47,116][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79185ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:26:04,206][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [79184ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:26:32,895][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79184662515ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:27:47,371][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127215ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:28:45,584][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/127215336118ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:29:23,405][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/96089ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:30:04,942][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/96088589917ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:31:04,325][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99821ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:32:14,565][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99821815689ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:33:01,838][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/118320ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:34:05,457][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/118319182518ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:36:23,944][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.3m/201398ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:37:51,580][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.3m/201397994181ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:39:24,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/180532ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:40:12,312][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/180532665910ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:40:58,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/88135ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:42:53,638][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/88134721466ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:43:37,893][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/166231ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:44:01,638][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/166231049372ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:44:34,578][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.2s/56225ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:46:19,269][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.2s/56225232434ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:46:49,813][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/130120ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:47:14,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/130119701001ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:47:34,606][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.4s/50428ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:48:35,685][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.4s/50427959823ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:49:45,081][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126814ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:50:42,803][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.1m/126814198694ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:50:39,923][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017ea020@4b82d07d] took [126814ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:51:37,076][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/116047ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:52:07,282][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/116046972337ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:53:14,851][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/96915ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:53:55,417][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/96915002772ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:54:33,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78326ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:55:20,979][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/78325864501ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:56:08,848][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95624ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:56:02,409][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@300797df, interval=1s}] took [78325ms] which is above the warn threshold of [5000ms]
[2022-04-04T18:57:06,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95624450037ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T18:58:55,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/165677ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T18:59:45,810][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.7m/165676870689ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:01:51,385][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/176379ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:03:57,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/176378460972ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:05:43,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/232004ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:02:09,138][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [342055ms] which is above the warn threshold of [5s]
[2022-04-04T19:07:48,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/231744533697ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:10:05,044][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/261139ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:12:43,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/260871492204ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:15:19,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/314291ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:18:31,874][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2m/314523540219ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:22:57,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.6m/456861ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:27:18,516][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.6m/456717467346ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:32:52,471][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9m/595769ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:37:19,572][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9m/595770995381ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:41:21,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4m/509180ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:45:01,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4m/509146794334ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:47:55,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/394082ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:49:50,590][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.5m/394408344863ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:53:00,309][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/304492ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T19:56:05,079][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/304634990104ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T19:58:45,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/345137ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T20:01:31,909][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/344855409527ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T20:00:04,898][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [52s/52034ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@470bfe7f]], which exceeds the warn threshold of [10s]
[2022-04-04T20:04:58,124][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356421ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T20:07:57,889][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356149644022ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-04T20:07:59,303][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [27.6s/27666ms] to compute cluster state update for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.03.12-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@ea1b8370], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@6ea052ce], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a75b6627]], which exceeds the warn threshold of [10s]
[2022-04-04T20:10:57,860][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/367818ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-04T20:11:34,298][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [26.8s/26895ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.03.12-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@ea1b8370], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@6ea052ce], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a75b6627]], which exceeds the warn threshold of [10s]
