[2022-04-02T18:50:08,705][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-02T18:50:08,720][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-02T18:50:08,721][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-02T18:50:15,800][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-02T18:50:15,801][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-02T18:50:15,801][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-02T18:50:15,802][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-02T18:50:15,802][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-02T18:50:15,803][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-02T18:50:15,804][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-02T18:50:15,804][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-02T18:50:15,805][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-02T18:50:15,806][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-02T18:50:15,806][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-02T18:50:15,806][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-02T18:50:15,807][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-02T18:50:15,807][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-02T18:50:15,808][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-02T18:50:15,808][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-02T18:50:15,808][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-02T18:50:15,809][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-02T18:50:15,809][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-02T18:50:15,809][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-02T18:50:15,810][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-02T18:50:15,810][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-02T18:50:15,810][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-02T18:50:15,811][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-02T18:50:15,811][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-02T18:50:15,811][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-02T18:50:15,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-02T18:50:15,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-02T18:50:15,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-02T18:50:15,812][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-02T18:50:15,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-02T18:50:15,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-02T18:50:15,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-02T18:50:15,813][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-02T18:50:15,814][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-02T18:50:15,814][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-02T18:50:15,814][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-02T18:50:15,815][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-02T18:50:15,815][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-02T18:50:15,815][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-02T18:50:15,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-02T18:50:15,816][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-02T18:50:15,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-02T18:50:15,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-02T18:50:15,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-02T18:50:15,817][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-02T18:50:15,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-02T18:50:15,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-02T18:50:15,818][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-02T18:50:15,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-02T18:50:15,819][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-02T18:50:15,820][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-02T18:50:15,821][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-02T18:50:15,821][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-02T18:50:15,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-02T18:50:15,822][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-02T18:50:15,823][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-02T18:50:15,823][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-02T18:50:15,824][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-02T18:50:15,892][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [102.6gb], net total_space [125.8gb], types [ext4]
[2022-04-02T18:50:15,896][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-02T18:50:16,123][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-02T18:50:27,130][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-02T18:50:27,135][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-02T18:50:28,109][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-02T18:50:28,208][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-02T18:50:28,845][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-02T18:50:29,526][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-02T18:50:29,527][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-02T18:50:29,554][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-02T18:50:29,556][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-02T18:50:29,729][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-02T18:50:31,549][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-02T18:50:31,647][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{btoQDx8lSciJa5azZGNf0A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 195, version: 5430, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{btoQDx8lSciJa5azZGNf0A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-02T18:50:31,798][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{btoQDx8lSciJa5azZGNf0A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 195, version: 5430, reason: Publication{term=195, version=5430}
[2022-04-02T18:50:31,898][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-02T18:50:31,899][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-02T18:50:33,014][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-02T18:50:33,024][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [36] indices into cluster_state
[2022-04-02T18:50:33,811][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-02T18:50:33,812][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-02T18:50:34,480][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-02T18:50:34,778][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-02T18:50:34,826][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-02T18:50:34,839][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-02T18:50:34,844][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-02T18:50:35,234][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-02T18:50:35,291][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-02T18:50:35,384][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-02T18:50:37,680][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-02T18:50:38,760][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0]]]).
[2022-04-02T18:50:52,950][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-04-02T18:50:53,109][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-04-02T18:51:34,611][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 515 finished with response BulkByScrollResponse[took=286.9ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-02T18:51:36,421][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 512 finished with response BulkByScrollResponse[took=2.1s,timed_out=false,sliceId=null,updated=1033,created=0,deleted=0,batches=2,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-02T18:51:42,986][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-04-02T18:55:55,487][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [40283ms] which is above the warn threshold of [5000ms]
[2022-04-02T18:55:56,151][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5s/5543ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T18:56:02,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8s/5862567050ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T18:56:02,647][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/124467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T18:56:02,647][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/124621791285ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T18:56:04,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@65209e29, interval=5s}] took [126111ms] which is above the warn threshold of [5000ms]
[2022-04-02T19:03:26,590][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:06:46,167][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:09:54,537][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:16:02,549][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:17:25,042][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:22:15,773][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:24:25,885][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:24:25,970][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:24:26,074][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:24:26,185][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:24:29,838][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:26:37,896][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:29:54,101][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:43:34,343][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:46:39,704][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:51:18,885][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:51:51,602][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:54:30,785][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T19:57:44,121][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:18:33,455][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:24:11,623][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:28:07,768][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:28:07,883][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:28:08,728][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:31:57,149][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:31:57,267][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:31:57,275][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:32:04,108][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T20:37:50,326][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][6202][110] duration [989ms], collections [1]/[3s], total [989ms]/[3.4s], memory [1.3gb]->[209.3mb]/[2gb], all_pools {[young] [1.1gb]->[40mb]/[0b]}{[old] [195mb]->[195mb]/[2gb]}{[survivor] [8.7mb]->[10.2mb]/[0b]}
[2022-04-02T20:37:50,392][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][6202] overhead, spent [989ms] collecting in the last [3s]
[2022-04-02T20:39:00,165][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [35533ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:39:21,902][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [6560ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:39:41,389][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [6224ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:39:50,639][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [6480ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:40:13,434][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [5399ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:40:41,021][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [23564ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:41:15,423][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@33346fc5, interval=5s}] took [14129ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:41:53,038][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9s/5965ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:42:04,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9s/5965013112ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:42:13,281][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22195ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:42:23,656][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22195367570ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:42:39,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26421ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:42:54,181][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26420562335ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:42:58,795][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19448ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:43:00,613][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [19448ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:43:02,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19448004827ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:43:04,544][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9s/5990ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:43:05,754][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@65209e29, interval=5s}] took [5989ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:43:09,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9s/5989801912ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:43:14,065][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.4s/9406ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:43:22,944][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.4s/9405876054ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:44:09,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [9405ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:44:16,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62236ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:43:17,609][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [5990ms] which is above the warn threshold of [5s]
[2022-04-02T20:44:28,627][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62236441080ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:44:33,005][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15965ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:44:38,059][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15964484801ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:44:40,602][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2s/8248ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:44:53,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2s/8248356256ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:45:11,180][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.3s/30324ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:45:23,442][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [30324ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:45:24,180][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.3s/30324104189ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:45:12,251][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [4.7m/286195ms] ago, timed out [4.3m/263929ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{btoQDx8lSciJa5azZGNf0A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [45464]
[2022-04-02T20:45:30,443][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19557ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:45:34,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [19556ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:45:36,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19556560911ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:45:44,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.7s/13759ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:45:57,733][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.7s/13759431531ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:05,725][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21715ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:05,728][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [13759ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:46:14,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21715299967ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:24,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18090ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:30,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18089837210ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:36,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.1s/12173ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:24,769][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:44520}] took [33316ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:46:41,249][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.1s/12172903236ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:46,083][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7s/9763ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:46:55,590][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7s/9762646044ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:06,064][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19957ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:06,214][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [41893ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:47:13,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19957685333ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:18,045][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12225ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:23,951][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.2s/12224193075ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:28,368][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [45464] timed out after [22266ms]
[2022-04-02T20:47:28,688][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.6s/10646ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:40,558][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.6s/10646455089ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:45,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17040ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:38,870][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [10646ms] which is above the warn threshold of [5s]
[2022-04-02T20:47:52,094][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17s/17040346849ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:47:54,492][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [17040ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:47:55,272][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9572ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:01,117][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5s/9571345975ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:08,993][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13156ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:16,799][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.1s/13156500575ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:21,799][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13350ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:22,847][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [26506ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:48:25,029][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.3s/13350136757ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:27,552][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5758ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:31,019][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5107/0x00000008017e3db8@3d2ef2ec] took [5757ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:48:30,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5757980671ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:25,029][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.3:44546}] took [13350ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:48:40,909][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7004ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:44,298][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [12827ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:48:45,005][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7004273459ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:48:54,857][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14316ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:01,867][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14315880252ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:09,691][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14935ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:27,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [14934ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:49:28,014][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14934896962ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:31,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21832ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:32,907][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5107/0x00000008017e3db8@323e04e5] took [21831ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:49:33,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21831426225ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:43,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.7s/11738ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:45,666][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.6s/10651793500ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:49:52,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.6s/7681ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:50:52,329][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.6s/7681223130ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:50:48,420][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][6236][114] duration [5.7s], collections [1]/[25.7s], total [5.7s]/[9.3s], memory [754mb]->[205.3mb]/[2gb], all_pools {[young] [556mb]->[32mb]/[0b]}{[old] [197.3mb]->[197.3mb]/[2gb]}{[survivor] [8.6mb]->[8mb]/[0b]}
[2022-04-02T20:51:29,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95950ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:51:34,282][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [117224ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:51:48,638][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/95949709515ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:52:25,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.3s/56392ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:52:44,382][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.3s/56392465257ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:52:23,484][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [17.3s/17385ms] to compute cluster state update for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a390e4d8]], which exceeds the warn threshold of [10s]
[2022-04-02T20:52:56,624][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [56392ms] which is above the warn threshold of [5s]
[2022-04-02T20:52:59,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33862ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:53:17,576][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.8s/33861523749ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:53:35,905][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.8s/32806ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:53:50,237][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.8s/32806620920ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:54:36,166][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64096ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:54:48,042][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64095371957ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:55:02,763][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25784ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:55:09,093][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [89880ms] which is above the warn threshold of [5000ms]
[2022-04-02T20:55:14,374][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.7s/25784655207ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:54:57,943][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [45742] timed out after [117224ms]
[2022-04-02T20:55:38,526][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.1s/28103ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:55:59,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.1s/28103129694ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:56:17,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.6s/41695ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:56:41,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.6s/41694501975ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:57:18,262][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66054ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:58:09,718][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66054033971ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:58:38,753][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/81075ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T20:58:55,854][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/81075194913ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T20:59:54,005][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [9.1m/547091ms] ago, timed out [7.1m/429867ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{btoQDx8lSciJa5azZGNf0A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [45742]
[2022-04-02T21:00:08,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79142ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:00:44,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79141567200ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:00:52,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.4s/54489ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:00:57,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.4s/54489769304ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:01:06,485][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14021ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:01:11,078][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.search.SearchService$Reaper@76b5e366, interval=1m}] took [14020ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:01:14,764][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14s/14020830399ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:01:21,619][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14934ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:01:27,155][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [14933ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:01:27,280][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.9s/14933927095ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:01:25,480][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [14934ms] which is above the warn threshold of [5s]
[2022-04-02T21:01:32,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:01:35,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9915438740ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:02:05,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.6s/34620ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:02:05,701][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:46022}] took [34620ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:02:08,051][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][6240][115] duration [20.4s], collections [1]/[2s], total [20.4s]/[29.7s], memory [289.3mb]->[204.5mb]/[2gb], all_pools {[young] [84mb]->[0b]/[0b]}{[old] [197.3mb]->[197.3mb]/[2gb]}{[survivor] [8mb]->[7.2mb]/[0b]}
[2022-04-02T21:02:07,974][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.6s/34620167317ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:02:09,299][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][6240] overhead, spent [20.4s] collecting in the last [2s]
[2022-04-02T21:02:10,726][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [39649ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:02:14,490][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [45828] timed out after [42051ms]
[2022-04-02T21:04:00,538][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67948ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:04:14,999][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [71066ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:05:16,341][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67948810757ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:05:59,042][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/122855ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:07:21,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@33346fc5, interval=5s}] took [122854ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:07:21,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/122854541566ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:08:56,618][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/175683ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:10:28,547][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/175683230897ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:11:35,760][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/159719ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:11:54,485][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@65209e29, interval=5s}] took [335401ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:12:48,122][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.6m/159718745328ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:14:36,521][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/180168ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:15:25,700][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.9m/179937037201ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:16:00,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/85819ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:15:51,884][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [12s/12089ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a390e4d8]], which exceeds the warn threshold of [10s]
[2022-04-02T21:17:35,023][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [17.6s/17681ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.03.12-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@1f0c157a]], which exceeds the warn threshold of [10s]
[2022-04-02T21:16:52,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86050147305ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:20:01,372][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/235245ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:19:57,521][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [11.2s/11287ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@7bfc9089], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@dc4bf831]], which exceeds the warn threshold of [10s]
[2022-04-02T21:22:11,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/234916067151ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:23:23,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.4m/204831ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:25:34,793][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.4m/204903714907ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:27:53,244][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/265295ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:30:24,911][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][6251][116] duration [50.3s], collections [1]/[19.8m], total [50.3s]/[1.3m], memory [284.5mb]->[211.3mb]/[2gb], all_pools {[young] [84mb]->[8mb]/[0b]}{[old] [197.3mb]->[197.3mb]/[2gb]}{[survivor] [7.2mb]->[6mb]/[0b]}
[2022-04-02T21:31:26,563][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/265150102468ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:31:46,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@740c386, interval=1s}] took [470053ms] which is above the warn threshold of [5000ms]
[2022-04-02T21:29:32,061][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [470054ms] which is above the warn threshold of [5s]
[2022-04-02T21:33:44,191][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/356634ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:36:09,143][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [10.5s/10574ms] to compute cluster state update for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@dc4bf831]], which exceeds the warn threshold of [10s]
[2022-04-02T21:36:37,931][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/357034607777ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:39:57,936][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/367741ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:43:01,160][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/367238821983ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:44:21,014][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [43.8s/43820ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a390e4d8]], which exceeds the warn threshold of [10s]
[2022-04-02T21:45:33,213][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/333952ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:47:49,984][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/334225459729ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:50:06,257][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273890ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:52:17,807][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273725606271ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:54:52,066][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/269278ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T21:55:01,107][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [1.4m/88141ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@7bfc9089]], which exceeds the warn threshold of [10s]
[2022-04-02T21:57:06,577][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/269264907554ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T21:58:03,650][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [15.2s/15261ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@7bfc9089]], which exceeds the warn threshold of [10s]
[2022-04-02T21:59:27,226][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.8m/291787ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T22:01:44,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.8m/291698692768ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T22:04:00,638][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.6m/280919ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T22:06:20,025][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.6m/281285566800ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T22:08:40,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/272485ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T22:09:09,694][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@33346fc5, interval=5s}] took [272612ms] which is above the warn threshold of [5000ms]
[2022-04-02T22:10:29,635][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [13.9s/13932ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@7bfc9089], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@dc4bf831]], which exceeds the warn threshold of [10s]
[2022-04-02T22:10:53,123][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/272612988516ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T22:13:27,397][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/285770ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T22:13:53,909][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [14.1s/14107ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@7bfc9089], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@dc4bf831]], which exceeds the warn threshold of [10s]
[2022-04-02T22:16:02,016][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/285461148244ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T22:18:58,048][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/337590ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T22:16:18,484][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [285461ms] which is above the warn threshold of [5s]
[2022-04-02T22:20:56,282][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/337747362271ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T22:19:23,291][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [16.9s/16972ms] to compute cluster state update for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.03.12-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@1f0c157a], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@a390e4d8], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@7bfc9089], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@dc4bf831]], which exceeds the warn threshold of [10s]
[2022-04-02T22:25:32,648][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-02T22:25:32,666][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-02T22:25:32,667][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-02T22:25:47,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-02T22:25:47,218][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-02T22:25:47,219][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-02T22:25:47,219][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-02T22:25:47,220][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-02T22:25:47,220][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-02T22:25:47,220][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-02T22:25:47,221][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-02T22:25:47,221][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-02T22:25:47,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-02T22:25:47,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-02T22:25:47,222][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-02T22:25:47,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-02T22:25:47,223][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-02T22:25:47,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-02T22:25:47,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-02T22:25:47,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-02T22:25:47,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-02T22:25:47,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-02T22:25:47,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-02T22:25:47,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-02T22:25:47,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-02T22:25:47,226][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-02T22:25:47,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-02T22:25:47,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-02T22:25:47,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-02T22:25:47,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-02T22:25:47,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-02T22:25:47,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-02T22:25:47,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-02T22:25:47,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-02T22:25:47,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-02T22:25:47,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-02T22:25:47,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-02T22:25:47,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-02T22:25:47,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-02T22:25:47,231][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-02T22:25:47,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-02T22:25:47,232][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-02T22:25:47,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-02T22:25:47,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-02T22:25:47,233][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-02T22:25:47,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-02T22:25:47,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-02T22:25:47,234][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-02T22:25:47,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-02T22:25:47,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-02T22:25:47,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-02T22:25:47,236][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-02T22:25:47,236][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-02T22:25:47,236][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-02T22:25:47,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-02T22:25:47,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-02T22:25:47,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-02T22:25:47,237][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-02T22:25:47,238][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-02T22:25:47,238][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-02T22:25:47,238][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-02T22:25:47,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-02T22:25:47,332][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [102.5gb], net total_space [125.8gb], types [ext4]
[2022-04-02T22:25:47,334][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-02T22:25:51,606][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-02T22:43:46,929][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-02T22:43:46,936][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-02T22:43:46,943][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-02T22:43:46,956][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-02T22:43:46,958][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-02T22:43:46,959][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-02T22:43:46,961][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-02T22:43:46,963][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-02T22:43:46,967][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-02T22:43:46,970][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-02T22:43:46,972][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-02T22:43:46,973][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-02T22:43:46,974][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-02T22:43:46,975][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-02T22:43:46,976][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-02T22:43:48,547][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-02T22:43:48,716][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-02T22:43:50,007][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-02T22:43:51,432][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-02T22:43:51,434][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-02T22:43:51,537][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-02T22:43:51,550][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-02T22:43:51,799][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-02T22:43:55,377][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-02T22:43:55,601][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kgFaJvoDSiy5I9I6ieV-1g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 196, version: 5502, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kgFaJvoDSiy5I9I6ieV-1g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-02T22:43:55,904][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kgFaJvoDSiy5I9I6ieV-1g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 196, version: 5502, reason: Publication{term=196, version=5502}
[2022-04-02T22:43:56,132][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-02T22:43:56,133][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-02T22:43:58,515][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-02T22:43:58,523][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [36] indices into cluster_state
[2022-04-02T22:44:00,208][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-02T22:44:00,209][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-02T22:44:00,278][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-02T22:44:01,373][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-04-02T22:44:01,505][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-04-02T22:44:02,081][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-04-02T22:44:02,245][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-02T22:44:02,248][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-02T22:44:02,252][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-02T22:44:02,995][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-02T22:44:03,133][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-02T22:44:07,309][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-02T22:44:09,465][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[.ds-.logs-deprecation.elasticsearch-default-2022.03.12-000001][0]]]).
[2022-04-02T22:44:49,022][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T22:44:54,788][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T22:44:55,126][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T22:44:55,317][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.02/glFu8EL8QBe3Ih2vkfS-Tw] update_mapping [_doc]
[2022-04-02T23:06:12,870][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5119ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:06:34,425][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5119442313ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:06:12,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [5016ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:06:44,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31788ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:06:46,555][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31787784113ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:07:04,224][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [7373ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:07:26,161][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [8326ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:07:35,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [5770ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:07:51,131][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [7774ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:08:15,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [5855ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:08:48,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.4s/8427ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:08:58,241][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9s/9995ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:09:33,865][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17785978430ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:10:21,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [17785ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:10:29,901][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/84319ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:11:32,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/84318420083ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:13:57,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/212496ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:14:44,388][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.5m/212496060861ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:15:08,066][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73255ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:15:38,138][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73255597571ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:16:06,430][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53.7s/53745ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:16:02,513][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [11.3s/11345ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@4a1aa539], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@aa6a0ce1]], which exceeds the warn threshold of [10s]
[2022-04-02T23:16:28,044][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53.7s/53744445680ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:16:43,226][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.9s/40950ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:16:57,394][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.9s/40949732586ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:17:14,655][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31403ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:17:34,332][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31403070983ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:18:02,096][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [72618ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:17:55,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.2s/41215ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:18:37,447][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.2s/41215884635ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:19:09,687][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73705ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:17:40,982][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [10074] timed out after [31168ms]
[2022-04-02T23:18:14,996][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [41216ms] which is above the warn threshold of [5s]
[2022-04-02T23:20:03,441][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73704974817ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:20:28,997][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79557ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:20:54,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/79556936588ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:21:31,770][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63108ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:21:47,370][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/63107868944ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:22:13,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41506ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:22:42,348][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41505938916ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:22:54,024][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40624ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:23:31,570][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.6s/40623764284ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:23:52,016][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.5s/57507ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:24:07,505][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.5s/57507497546ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:24:47,955][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.7s/39786ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:25:14,274][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.7s/39785527707ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:25:15,830][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [13.7s/13740ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@4a1aa539]], which exceeds the warn threshold of [10s]
[2022-04-02T23:25:32,264][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60289ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:25:47,896][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60288772533ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:26:05,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31796ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:26:19,332][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31796221342ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:26:44,097][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40s/40062ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:26:58,463][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40s/40061949654ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:27:16,643][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.6s/32695ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:27:35,954][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.6s/32694580925ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:27:55,604][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39260ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:28:02,399][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [71955ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:28:13,037][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39260976801ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:28:30,220][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34342ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:28:48,622][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@513ce5ec, interval=5s}] took [34341ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:29:58,493][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.3s/34341561064ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:30:23,780][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113560ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:30:43,446][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.8m/113559783024ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:31:03,461][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38236ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:31:21,451][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5108/0x00000008017d9978@27d2e6fb] took [38235ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:31:22,949][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38235865630ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:31:41,001][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.3s/39381ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:32:00,499][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.3s/39380997189ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:32:43,796][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/61877ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:31:41,793][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [39381ms] which is above the warn threshold of [5s]
[2022-04-02T23:33:28,880][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/61877024479ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:33:42,517][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.7s/59785ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:34:15,223][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.7s/59785405867ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:34:42,010][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.6s/58675ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:34:56,204][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [58.6s/58674874378ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:35:00,803][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [58674ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:34:23,033][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [25.8m/1552558ms] ago, timed out [25.3m/1521390ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kgFaJvoDSiy5I9I6ieV-1g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [10074]
[2022-04-02T23:35:12,116][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31s/31024ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:35:32,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31s/31023891969ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:35:47,876][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.5s/35586ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:36:10,958][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.5s/35585814245ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:36:34,964][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.2s/47262ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:36:52,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.2s/47262297581ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:37:15,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.4s/40446ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:37:33,629][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40327417966ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:37:52,070][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.6s/34648ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:38:14,907][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.7s/34766726148ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:38:40,458][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.3s/43366ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:39:08,282][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.3s/43365714106ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:39:13,325][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [43365ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:39:31,027][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51263ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:38:58,446][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [10292] timed out after [286328ms]
[2022-04-02T23:39:47,241][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.2s/51262791123ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:40:00,327][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.7s/35714ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:40:12,049][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.7s/35714523991ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:40:34,357][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33719ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:40:50,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33719159060ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:41:04,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.9s/29919ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:40:31,952][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [35714ms] which is above the warn threshold of [5s]
[2022-04-02T23:41:24,721][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.9s/29918743474ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:41:59,334][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41535ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:42:29,524][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.5s/41535098111ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:42:50,773][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/65453ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:42:52,186][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [65453ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:43:08,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/65453165479ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:43:32,379][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40745ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:43:41,058][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@513ce5ec, interval=5s}] took [40744ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:44:03,050][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.7s/40744248314ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:44:27,262][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55s/55027ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:43:46,833][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_nodes?filter_path=nodes.*.version%2Cnodes.*.http.publish_address%2Cnodes.*.ip][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:49334}] took [65453ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:44:59,344][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55s/55027315349ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:45:21,860][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.5s/54524ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:45:29,758][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5108/0x00000008017d9978@26820d3f] took [54524ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:45:35,121][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.5s/54524152093ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:46:34,950][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/72627ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:47:32,279][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/72627293075ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:48:05,984][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90211ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:48:48,908][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/90210893795ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:49:22,256][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/72202ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:49:49,453][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/72201549425ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:50:30,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74026ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:50:59,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74025719379ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:51:24,267][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.6s/52692ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:51:51,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.6s/52692358725ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:52:38,735][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1d547b4b, interval=1s}] took [52692ms] which is above the warn threshold of [5000ms]
[2022-04-02T23:53:04,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99611ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:51:31,962][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [19.4m/1169015ms] ago, timed out [14.7m/882687ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{kgFaJvoDSiy5I9I6ieV-1g}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [10292]
[2022-04-02T23:54:05,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.6m/99611094192ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:55:24,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/140577ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:56:21,948][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [25.6s/25603ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@4a1aa539]], which exceeds the warn threshold of [10s]
[2022-04-02T23:56:36,685][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.3m/140577220224ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-02T23:59:17,359][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.1m/188835ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-02T23:59:10,053][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [16s/16016ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.03.12-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@ed2a2a2a], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@71aef988], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@aa6a0ce1]], which exceeds the warn threshold of [10s]
[2022-04-02T23:59:04,128][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [329412ms] which is above the warn threshold of [5s]
[2022-04-03T01:56:19,309][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-03T01:56:19,419][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-03T01:56:19,419][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-03T01:56:38,132][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-03T01:56:38,156][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-03T01:56:38,157][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-03T01:56:38,157][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-03T01:56:38,158][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-03T01:56:38,158][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-03T01:56:38,159][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-03T01:56:38,159][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-03T01:56:38,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-03T01:56:38,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-03T01:56:38,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-03T01:56:38,161][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-03T01:56:38,161][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-03T01:56:38,162][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-03T01:56:38,162][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-03T01:56:38,163][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-03T01:56:38,163][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-03T01:56:38,163][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-03T01:56:38,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-03T01:56:38,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-03T01:56:38,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-03T01:56:38,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-03T01:56:38,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-03T01:56:38,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-03T01:56:38,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-03T01:56:38,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-03T01:56:38,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-03T01:56:38,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-03T01:56:38,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-03T01:56:38,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-03T01:56:38,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-03T01:56:38,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-03T01:56:38,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-03T01:56:38,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-03T01:56:38,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-03T01:56:38,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-03T01:56:38,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-03T01:56:38,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-03T01:56:38,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-03T01:56:38,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-03T01:56:38,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-03T01:56:38,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-03T01:56:38,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-03T01:56:38,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-03T01:56:38,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-03T01:56:38,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-03T01:56:38,174][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-03T01:56:38,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-03T01:56:38,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-03T01:56:38,175][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-03T01:56:38,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-03T01:56:38,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-03T01:56:38,176][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-03T01:56:38,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-03T01:56:38,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-03T01:56:38,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-03T01:56:38,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-03T01:56:38,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-03T01:56:38,179][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-03T01:56:38,593][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [104.2gb], net total_space [125.8gb], types [ext4]
[2022-04-03T01:56:38,594][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-03T01:56:40,363][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-03T03:46:48,639][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-03T03:46:48,650][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-03T03:46:48,651][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-03T03:46:53,601][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-03T03:46:53,608][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-03T03:46:53,608][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-03T03:46:53,609][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-03T03:46:53,609][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-03T03:46:53,609][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-03T03:46:53,610][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-03T03:46:53,610][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-03T03:46:53,610][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-03T03:46:53,611][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-03T03:46:53,611][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-03T03:46:53,612][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-03T03:46:53,612][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-03T03:46:53,612][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-03T03:46:53,613][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-03T03:46:53,613][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-03T03:46:53,614][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-03T03:46:53,614][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-03T03:46:53,614][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-03T03:46:53,615][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-03T03:46:53,615][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-03T03:46:53,615][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-03T03:46:53,616][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-03T03:46:53,616][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-03T03:46:53,617][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-03T03:46:53,617][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-03T03:46:53,617][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-03T03:46:53,617][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-03T03:46:53,618][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-03T03:46:53,618][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-03T03:46:53,618][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-03T03:46:53,619][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-03T03:46:53,619][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-03T03:46:53,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-03T03:46:53,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-03T03:46:53,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-03T03:46:53,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-03T03:46:53,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-03T03:46:53,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-03T03:46:53,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-03T03:46:53,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-03T03:46:53,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-03T03:46:53,623][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-03T03:46:53,623][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-03T03:46:53,623][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-03T03:46:53,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-03T03:46:53,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-03T03:46:53,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-03T03:46:53,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-03T03:46:53,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-03T03:46:53,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-03T03:46:53,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-03T03:46:53,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-03T03:46:53,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-03T03:46:53,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-03T03:46:53,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-03T03:46:53,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-03T03:46:53,628][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-03T03:46:53,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-03T03:46:53,720][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [105.8gb], net total_space [125.8gb], types [ext4]
[2022-04-03T03:46:53,721][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-03T03:46:54,186][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-03T03:51:54,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5122ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-03T04:22:48,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5206350281ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-03T04:26:37,105][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.6m/2321452ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-03T04:31:26,891][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.6m/2321328097311ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-03T04:34:53,892][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.3m/502283ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-03T04:38:24,154][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.3m/502576501756ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-03T04:42:34,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/443144ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-03T04:46:46,927][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/442834350838ns] on relative clock which is above the warn threshold of [5000ms]
