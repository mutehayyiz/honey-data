[2022-04-12T15:39:20,893][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T15:39:20,916][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T15:39:20,917][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T15:39:28,893][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T15:39:28,895][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T15:39:28,895][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T15:39:28,896][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T15:39:28,897][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T15:39:28,897][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T15:39:28,898][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T15:39:28,898][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T15:39:28,899][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T15:39:28,899][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T15:39:28,900][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T15:39:28,900][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T15:39:28,901][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T15:39:28,904][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T15:39:28,905][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T15:39:28,906][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T15:39:28,907][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T15:39:28,907][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T15:39:28,908][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T15:39:28,908][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T15:39:28,909][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T15:39:28,909][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T15:39:28,911][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T15:39:28,911][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T15:39:28,912][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T15:39:28,912][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T15:39:28,913][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T15:39:28,913][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T15:39:28,914][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T15:39:28,914][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T15:39:28,914][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T15:39:28,915][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T15:39:28,916][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T15:39:28,917][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T15:39:28,922][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T15:39:28,923][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T15:39:28,924][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T15:39:28,924][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T15:39:28,925][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T15:39:28,925][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T15:39:28,926][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T15:39:28,927][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T15:39:28,927][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T15:39:28,928][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T15:39:28,928][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T15:39:28,929][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T15:39:28,929][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T15:39:28,930][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T15:39:28,930][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T15:39:28,931][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T15:39:28,931][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T15:39:28,932][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T15:39:28,932][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T15:39:28,934][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T15:39:28,934][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T15:39:28,935][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T15:39:28,935][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T15:39:28,936][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T15:39:28,950][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T15:39:29,058][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.6gb], net total_space [125.8gb], types [ext4]
[2022-04-12T15:39:29,059][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T15:39:29,699][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-12T15:39:40,464][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-12T15:39:40,467][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-12T15:39:41,598][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-12T15:39:41,735][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-12T15:39:42,504][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-12T15:39:43,413][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-12T15:39:43,414][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-12T15:39:43,447][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-12T15:39:43,449][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-12T15:39:43,703][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-12T15:39:46,432][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-12T15:39:46,558][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{Z0Qk8kWZT4y-rOg6XUjqQw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 233, version: 9100, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{Z0Qk8kWZT4y-rOg6XUjqQw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-12T15:39:46,760][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{Z0Qk8kWZT4y-rOg6XUjqQw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 233, version: 9100, reason: Publication{term=233, version=9100}
[2022-04-12T15:39:46,884][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-12T15:39:46,885][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-12T15:39:47,580][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-12T15:39:47,586][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [48] indices into cluster_state
[2022-04-12T15:39:48,309][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-12T15:39:48,310][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-12T15:39:49,174][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-ASN.mmdb]
[2022-04-12T15:39:49,537][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-12T15:39:49,549][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-12T15:39:49,550][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-12T15:39:49,927][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-12T15:39:50,006][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-12T15:39:53,026][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-12T15:39:53,049][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-ASN.mmdb]
[2022-04-12T15:39:53,069][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-City.mmdb]
[2022-04-12T15:39:53,563][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-12T15:39:53,632][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-12T15:39:53,634][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-12T15:40:00,184][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.11][0]]]).
[2022-04-12T15:40:01,281][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-12T15:40:01,317][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-City.mmdb]
[2022-04-12T15:40:01,319][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-Country.mmdb]
[2022-04-12T15:40:02,905][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-12T15:40:02,975][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-Country.mmdb]
[2022-04-12T15:40:03,256][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-12T15:40:03,263][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-12T15:40:04,540][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-12T15:40:04,542][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-12T15:40:06,128][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-04-12T15:40:06,303][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-04-12T15:40:52,616][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 1008 finished with response BulkByScrollResponse[took=143.3ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-12T15:40:55,050][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 1035 finished with response BulkByScrollResponse[took=2.3s,timed_out=false,sliceId=null,updated=1009,created=0,deleted=0,batches=2,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-04-12T15:41:04,591][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-04-12T15:41:31,923][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-2022.04.12] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-12T15:41:32,167][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-2022.04.12][0]]]).
[2022-04-12T15:41:32,360][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:32,468][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:35,230][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:49,227][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:49,320][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:49,483][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:59,262][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:41:59,362][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:00,264][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:00,375][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:08,288][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:35,370][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:35,548][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:35,643][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:35,734][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:36,338][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:36,492][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:36,531][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:36,612][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:36,618][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:38,540][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:51,372][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:51,442][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:42:56,389][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:43:07,586][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:44:03,710][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:44:25,405][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:44:49,539][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:44:56,440][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:45:06,590][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:45:07,572][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:45:21,578][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:45:31,607][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:50:16,847][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:50:39,868][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:53:00,735][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:53:00,819][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:53:01,001][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:53:01,081][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:53:01,090][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:53:59,766][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:54:01,779][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:54:02,786][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:54:03,793][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:55:21,128][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T15:57:30,235][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:02:52,573][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:05:44,817][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:09:49,964][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:17:53,385][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:18:26,455][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:18:26,602][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:19:37,548][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:22:56,737][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:22:56,874][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:22:56,950][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:22:57,091][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:22:57,163][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:23:53,749][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:23:53,843][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:37:03,242][INFO ][o.e.c.m.MetadataDeleteIndexService] [tpotcluster-node-01] [logstash-1970.01.01/9Y6aaqQuTfir-K-bt-BQiw] deleting index
[2022-04-12T16:37:55,966][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-1970.01.01] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-12T16:37:56,083][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-1970.01.01][0]]]).
[2022-04-12T16:37:56,137][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-1970.01.01/1pKOC-ZcQWeDHaGkNPDT3w] update_mapping [_doc]
[2022-04-12T16:38:47,736][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:39:14,702][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T16:43:03,873][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T17:00:49,472][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T17:00:53,673][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T17:01:04,460][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T17:02:04,560][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T17:02:51,347][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][4972][89] duration [703ms], collections [1]/[1.1s], total [703ms]/[3.5s], memory [1.3gb]->[253.3mb]/[2gb], all_pools {[young] [1.1gb]->[0b]/[0b]}{[old] [245.3mb]->[245.3mb]/[2gb]}{[survivor] [5.8mb]->[7.9mb]/[0b]}
[2022-04-12T17:02:52,180][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][4972] overhead, spent [703ms] collecting in the last [1.1s]
[2022-04-12T17:02:55,644][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][4974][92] duration [947ms], collections [1]/[1.3s], total [947ms]/[5.5s], memory [255mb]->[255.5mb]/[2gb], all_pools {[young] [56mb]->[0b]/[0b]}{[old] [247.1mb]->[247.1mb]/[2gb]}{[survivor] [7.9mb]->[8.3mb]/[0b]}
[2022-04-12T17:02:55,928][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][4974] overhead, spent [947ms] collecting in the last [1.3s]
[2022-04-12T17:03:08,294][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][4985] overhead, spent [423ms] collecting in the last [1s]
[2022-04-12T17:03:09,872][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][4986] overhead, spent [430ms] collecting in the last [1.5s]
[2022-04-12T17:03:34,572][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [7197ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:03:54,827][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [5864ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:04:04,159][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [6517ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:04:16,857][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [9364ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:04:35,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [12306ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:05:33,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [32190ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:09:56,759][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4s/6465ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:20:46,689][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9s/5993646151ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:22:16,237][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8m/1011397ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:22:56,853][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3d3fe2de, interval=5s}] took [1011869ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:23:43,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.8m/1011869128895ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:27:27,461][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.2m/193979ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:29:09,108][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@7116abe3, interval=5s}] took [193978ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:28:30,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.2m/193978897487ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:31:24,213][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9m/354001ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:33:34,939][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/353719095958ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:35:52,518][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/267234ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:39:59,588][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/267138204747ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:43:02,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/430916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:44:38,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/430830931239ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:49:09,346][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/366317ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:52:11,939][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/366103970914ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:54:32,818][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/323758ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T17:55:08,676][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@456a523a, interval=1s}] took [324096ms] which is above the warn threshold of [5000ms]
[2022-04-12T17:56:40,163][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/324096550920ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T17:59:20,061][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287425ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:01:52,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/287762195355ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T18:03:04,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/224119ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:05:06,365][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.7m/223667661121ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T18:07:03,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/239315ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:08:28,545][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T18:09:19,110][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.9m/239766388106ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T18:10:54,846][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/230851ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:13:15,192][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.8m/230851073266ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T18:09:57,192][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [751196ms] which is above the warn threshold of [5s]
[2022-04-12T18:15:43,450][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.6m/281622ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:15:50,365][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [1.1h/4154706ms] to compute cluster state update for [put-mapping [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q][_doc]], which exceeds the warn threshold of [10s]
[2022-04-12T18:17:46,618][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.6m/281621611403ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T18:19:54,297][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.3m/258648ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:31:21,743][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T18:31:21,758][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T18:31:21,759][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T18:31:27,288][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T18:31:27,292][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T18:31:27,293][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T18:31:27,293][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T18:31:27,294][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T18:31:27,294][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T18:31:27,295][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T18:31:27,295][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T18:31:27,296][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T18:31:27,296][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T18:31:27,297][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T18:31:27,297][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T18:31:27,297][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T18:31:27,298][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T18:31:27,299][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T18:31:27,299][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T18:31:27,299][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T18:31:27,300][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T18:31:27,300][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T18:31:27,301][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T18:31:27,302][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T18:31:27,303][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T18:31:27,303][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T18:31:27,303][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T18:31:27,304][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T18:31:27,304][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T18:31:27,305][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T18:31:27,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T18:31:27,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T18:31:27,306][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T18:31:27,307][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T18:31:27,307][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T18:31:27,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T18:31:27,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T18:31:27,308][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T18:31:27,309][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T18:31:27,309][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T18:31:27,310][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T18:31:27,310][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T18:31:27,311][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T18:31:27,311][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T18:31:27,312][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T18:31:27,312][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T18:31:27,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T18:31:27,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T18:31:27,313][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T18:31:27,314][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T18:31:27,314][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T18:31:27,314][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T18:31:27,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T18:31:27,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T18:31:27,315][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T18:31:27,316][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T18:31:27,316][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T18:31:27,316][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T18:31:27,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T18:31:27,317][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T18:31:27,318][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T18:31:27,319][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T18:31:27,411][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.4gb], net total_space [125.8gb], types [ext4]
[2022-04-12T18:31:27,412][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T18:31:27,928][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-12T18:32:29,885][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-12T18:32:29,902][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-12T18:32:29,903][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-12T18:32:29,906][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-12T18:32:29,906][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-12T18:32:29,907][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-12T18:32:29,907][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-12T18:32:29,908][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-12T18:32:29,908][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-12T18:32:29,909][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-12T18:32:29,910][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-12T18:32:29,910][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-12T18:32:29,911][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-12T18:32:29,911][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-12T18:32:29,912][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-12T18:32:31,528][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-12T18:32:34,488][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-12T18:34:09,712][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-12T18:34:21,582][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-12T18:34:21,592][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-12T18:34:21,742][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-12T18:34:21,746][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-12T18:34:22,120][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-12T18:34:52,710][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [6251ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:35:18,813][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [12227ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:36:37,011][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [32892ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:37:19,435][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@526e064c] took [30847ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:37:31,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [5603ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:37:47,118][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [10807ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:37:47,832][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [16412ms] which is above the warn threshold of [5s]
[2022-04-12T18:38:05,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [11250ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:38:21,636][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [8806ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:38:49,010][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [14610ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:39:12,563][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [10408ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:39:35,696][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [12208ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:39:57,880][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [5803ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:40:07,646][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [5845ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:40:07,936][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [5645ms] which is above the warn threshold of [5s]
[2022-04-12T18:40:19,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [7004ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:40:35,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [7805ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:40:49,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [5804ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:41:00,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [6404ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:41:14,805][INFO ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][35] overhead, spent [301ms] collecting in the last [1s]
[2022-04-12T18:41:25,347][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][37][9] duration [3.4s], collections [1]/[5.1s], total [3.4s]/[3.9s], memory [266.2mb]->[72.4mb]/[2gb], all_pools {[young] [204mb]->[0b]/[0b]}{[old] [46.3mb]->[58mb]/[2gb]}{[survivor] [23.9mb]->[14.4mb]/[0b]}
[2022-04-12T18:41:25,811][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][37] overhead, spent [3.4s] collecting in the last [5.1s]
[2022-04-12T18:42:05,446][WARN ][o.e.g.PersistedClusterStateService] [tpotcluster-node-01] writing cluster state took [22514ms] which is above the warn threshold of [10s]; wrote full state with [49] indices
[2022-04-12T18:42:05,795][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-12T18:42:06,749][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{_sTjmLetSEGjjgQ3qnQ4eg}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 234, version: 9237, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{_sTjmLetSEGjjgQ3qnQ4eg}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-12T18:42:08,446][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{_sTjmLetSEGjjgQ3qnQ4eg}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 234, version: 9237, reason: Publication{term=234, version=9237}
[2022-04-12T18:42:12,090][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-12T18:42:12,280][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-12T18:42:21,932][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_7.17.0/_search, params: {rest_total_hits_as_int=true, size=20, index=.kibana_7.17.0, from=0}
org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];
	at org.elasticsearch.cluster.block.ClusterBlocks.globalBlockedException(ClusterBlocks.java:179) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.cluster.block.ClusterBlocks.globalBlockedRaiseException(ClusterBlocks.java:165) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeSearch(TransportSearchAction.java:929) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeLocalSearch(TransportSearchAction.java:763) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.lambda$executeRequest$6(TransportSearchAction.java:399) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:136) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.index.query.Rewriteable.rewriteAndFetch(Rewriteable.java:112) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.index.query.Rewriteable.rewriteAndFetch(Rewriteable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.executeRequest(TransportSearchAction.java:487) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:285) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:101) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:179) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:154) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:82) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:95) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.action.RestCancellableNodeClient.doExecute(RestCancellableNodeClient.java:81) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:407) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.action.search.RestSearchAction.lambda$prepareRequest$2(RestSearchAction.java:122) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:109) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:327) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.tryAllHandlers(RestController.java:393) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:245) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.dispatchRequest(AbstractHttpServerTransport.java:382) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.handleIncomingRequest(AbstractHttpServerTransport.java:461) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.AbstractHttpServerTransport.incomingRequest(AbstractHttpServerTransport.java:357) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:32) [transport-netty4-client-7.17.0.jar:7.17.0]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:18) [transport-netty4-client-7.17.0.jar:7.17.0]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at org.elasticsearch.http.netty4.Netty4HttpPipeliningHandler.channelRead(Netty4HttpPipeliningHandler.java:48) [transport-netty4-client-7.17.0.jar:7.17.0]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageCodec.channelRead(MessageToMessageCodec.java:111) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) [netty-handler-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:620) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:583) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) [netty-transport-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) [netty-common-4.1.66.Final.jar:4.1.66.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.66.Final.jar:4.1.66.Final]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-12T18:42:26,110][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_7.17.0/_search?from=0&rest_total_hits_as_int=true&size=20][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:52846}] took [6204ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:43:40,011][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5105/0x00000008017e3bb8@699aaa9f] took [60824ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:44:05,802][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-12T18:44:11,986][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_cat/health][Netty4HttpChannel{localAddress=/127.0.0.1:9200, remoteAddress=/127.0.0.1:52506}] took [52785ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:44:24,225][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [8198ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:44:24,225][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1s/8199ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T18:44:24,876][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [8599ms] which is above the warn threshold of [5s]
[2022-04-12T18:44:26,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.1s/8198872872ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T18:44:31,116][WARN ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] cluster state applier task [Publication{term=234, version=9238}] took [2.1m] which is above the warn threshold of [30s]: [running task [Publication{term=234, version=9238}]] took [0ms], [connecting to new nodes] took [1ms], [applying settings] took [0ms], [org.elasticsearch.repositories.RepositoriesService@41ca22b] took [0ms], [org.elasticsearch.indices.cluster.IndicesClusterStateService@247e1a33] took [61ms], [org.elasticsearch.script.ScriptService@5d6b0f6c] took [0ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@2a3eb4f2] took [790ms], [org.elasticsearch.snapshots.RestoreService@4bd25664] took [0ms], [org.elasticsearch.ingest.IngestService@1f2972af] took [10236ms], [org.elasticsearch.action.ingest.IngestActionForwarder@1abc0e49] took [0ms], [org.elasticsearch.action.admin.cluster.repositories.cleanup.TransportCleanupRepositoryAction$$Lambda$4527/0x00000008016d2640@457aa0c8] took [0ms], [org.elasticsearch.indices.TimestampFieldMapperService@1cc2af75] took [62ms], [org.elasticsearch.tasks.TaskManager@482a1a48] took [0ms], [org.elasticsearch.snapshots.SnapshotsService@329e9b42] took [92ms], [org.elasticsearch.cluster.InternalClusterInfoService@217febe8] took [0ms], [org.elasticsearch.snapshots.InternalSnapshotsInfoService@90df5fa] took [16ms], [org.elasticsearch.indices.SystemIndexManager@37246558] took [270ms], [org.elasticsearch.xpack.shutdown.NodeSeenService@776c42ac] took [0ms], [org.elasticsearch.xpack.autoscaling.capacity.memory.AutoscalingMemoryInfoService$$Lambda$3179/0x00000008013014e8@1ac77e5b] took [30ms], [org.elasticsearch.xpack.ccr.action.ShardFollowTaskCleaner@2be72720] took [30ms], [org.elasticsearch.xpack.enrich.EnrichPolicyMaintenanceService@54c2b234] took [0ms], [org.elasticsearch.xpack.transform.notifications.TransformAuditor$$Lambda$3197/0x00000008013bec08@433462f8] took [0ms], [org.elasticsearch.xpack.transform.TransformClusterStateListener@4b2185cf] took [13ms], [org.elasticsearch.xpack.stack.StackTemplateRegistry@1e6ca343] took [2251ms], [org.elasticsearch.xpack.searchablesnapshots.cache.blob.BlobStoreCacheMaintenanceService@37d3b869] took [0ms], [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots$RepositoryUuidWatcher@51b7c04c] took [0ms], [org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistry@7b0d3ae3] took [1294ms], [org.elasticsearch.xpack.watcher.WatcherLifeCycleService@13e7362] took [818ms], [org.elasticsearch.xpack.watcher.WatcherIndexingListener@7bb98e26] took [103ms], [org.elasticsearch.xpack.ilm.history.ILMHistoryTemplateRegistry@146394bd] took [1546ms], [org.elasticsearch.xpack.ilm.IndexLifecycleService@2a3eb4f2] took [7774ms], [org.elasticsearch.xpack.core.slm.history.SnapshotLifecycleTemplateRegistry@6ab6ef0] took [4884ms], [org.elasticsearch.xpack.slm.SnapshotLifecycleService@747ca824] took [21ms], [org.elasticsearch.xpack.slm.SnapshotRetentionService@164c59f5] took [0ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingTemplateRegistry@62cb998f] took [9235ms], [org.elasticsearch.xpack.deprecation.logging.DeprecationIndexingComponent@40de00b0] took [1796ms], [org.elasticsearch.xpack.fleet.FleetTemplateRegistry@41424f56] took [5642ms], [org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor@7ffba110] took [18513ms], [org.elasticsearch.cluster.metadata.SystemIndexMetadataUpgradeService@4f90e5df] took [51ms], [org.elasticsearch.cluster.metadata.TemplateUpgradeService@7c4e985c] took [274ms], [org.elasticsearch.node.ResponseCollectorService@2f25507c] took [0ms], [org.elasticsearch.snapshots.SnapshotShardsService@df487a9] took [0ms], [org.elasticsearch.persistent.PersistentTasksClusterService@458225d5] took [18309ms], [org.elasticsearch.shutdown.PluginShutdownService@4d06c941] took [31ms], [org.elasticsearch.cluster.routing.DelayedAllocationService@20112167] took [64ms], [org.elasticsearch.indices.store.IndicesStore@4ae1a323] took [2563ms], [org.elasticsearch.persistent.PersistentTasksNodeService@6ec404fb] took [86ms], [org.elasticsearch.license.LicenseService@20ab2bdf] took [27806ms], [org.elasticsearch.xpack.monitoring.exporter.local.LocalExporter@9983cb4] took [16595ms], [org.elasticsearch.xpack.ccr.action.AutoFollowCoordinator@4ea76e1f] took [26ms], [org.elasticsearch.xpack.core.async.AsyncTaskMaintenanceService@587079a6] took [26ms], [org.elasticsearch.gateway.GatewayService@29ca36e1] took [0ms], [org.elasticsearch.indices.recovery.PeerRecoverySourceService@4a189b34] took [0ms]
[2022-04-12T18:44:39,523][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [5403ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:44:45,560][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [49] indices into cluster_state
[2022-04-12T18:44:56,268][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5105/0x00000008017e3bb8@74e3255d] took [8461ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:48:12,994][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5105/0x00000008017e3bb8@6ee53b04] took [164835ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:49:52,666][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [5m/303768ms] to compute cluster state update for [cluster_reroute(async_shard_fetch)], which exceeds the warn threshold of [10s]
[2022-04-12T18:50:47,326][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5105/0x00000008017e3bb8@732b2d84] took [123655ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:50:59,621][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [5604ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:51:15,586][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52890}] took [422208ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:51:15,586][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52914}] took [452751ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:51:15,586][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52910}] took [452751ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:51:15,586][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52912}] took [452951ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:51:21,772][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5105/0x00000008017e3bb8@4fd9bf2c] took [5142ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:51:22,247][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:52842}] took [5342ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:53:43,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5bbe9e6f, interval=1s}] took [131647ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:53:19,493][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52920}] took [101105ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:55:27,968][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@227db247, interval=5s}] took [10706ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:56:22,750][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:52844}] took [291405ms] which is above the warn threshold of [5000ms]
[2022-04-12T18:57:30,219][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@65879017, interval=5s}] took [25098ms] which is above the warn threshold of [5000ms]
[2022-04-12T19:03:46,469][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8s/6809ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:05:17,156][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.7s/6792029413ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:07:27,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/241558ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:09:43,419][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4m/241575380699ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:07:57,900][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52926}] took [241575ms] which is above the warn threshold of [5000ms]
[2022-04-12T19:13:03,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/330809ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:16:21,567][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/330482770236ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:18:42,966][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52938}] took [330483ms] which is above the warn threshold of [5000ms]
[2022-04-12T19:20:15,921][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/429989ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:29:26,068][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/430314749671ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:32:53,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6m/759437ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:36:06,099][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.6m/759155226143ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:39:03,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/371751ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:43:21,181][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1m/371615154751ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:50:20,679][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2m/674836ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T19:54:15,500][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2m/674913642387ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T19:57:35,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2m/435848ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T20:01:25,939][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.2m/435540259626ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T20:08:33,078][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][HEAD][/][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:52950}] took [446601ms] which is above the warn threshold of [5000ms]
[2022-04-12T20:05:38,143][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4m/446283ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T20:17:13,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.4m/446600907175ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T21:50:38,986][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T21:50:39,054][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T21:50:39,054][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T21:50:51,195][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T21:50:51,196][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T21:50:51,196][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T21:50:51,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T21:50:51,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T21:50:51,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T21:50:51,198][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T21:50:51,198][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T21:50:51,199][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T21:50:51,199][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T21:50:51,200][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T21:50:51,201][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T21:50:51,201][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T21:50:51,202][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T21:50:51,202][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T21:50:51,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T21:50:51,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T21:50:51,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T21:50:51,204][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T21:50:51,210][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T21:50:51,211][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T21:50:51,212][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T21:50:51,212][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T21:50:51,212][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T21:50:51,213][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T21:50:51,213][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T21:50:51,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T21:50:51,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T21:50:51,214][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T21:50:51,215][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T21:50:51,215][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T21:50:51,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T21:50:51,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T21:50:51,216][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T21:50:51,217][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T21:50:51,217][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T21:50:51,218][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T21:50:51,224][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T21:50:51,225][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T21:50:51,227][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T21:50:51,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T21:50:51,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T21:50:51,228][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T21:50:51,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T21:50:51,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T21:50:51,229][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T21:50:51,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T21:50:51,230][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T21:50:51,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T21:50:51,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T21:50:51,235][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T21:50:51,236][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T21:50:51,236][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T21:50:51,238][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T21:50:51,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T21:50:51,239][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T21:50:51,240][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T21:50:51,240][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T21:50:51,241][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T21:50:51,414][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.4gb], net total_space [125.8gb], types [ext4]
[2022-04-12T21:50:51,417][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T21:50:51,890][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-12T21:51:05,705][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-12T21:51:05,709][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-12T21:51:07,912][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-12T21:51:08,244][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-12T21:51:10,501][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-12T21:51:12,364][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-12T21:51:12,366][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-12T21:51:12,486][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-12T21:51:12,488][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-12T21:51:13,047][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-12T21:51:17,987][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-12T21:51:18,203][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{bo5r_we6QZalL05SQmGFig}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 235, version: 9239, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{bo5r_we6QZalL05SQmGFig}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-12T21:51:18,523][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{bo5r_we6QZalL05SQmGFig}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 235, version: 9239, reason: Publication{term=235, version=9239}
[2022-04-12T21:51:18,706][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-12T21:51:18,707][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-12T21:51:21,274][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-12T21:51:21,281][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [49] indices into cluster_state
[2022-04-12T21:51:24,191][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:24,354][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-12T21:51:24,358][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-12T21:51:24,903][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:24,935][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:24,982][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:25,749][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:25,767][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:25,781][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:25,793][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:26,162][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-12T21:51:26,170][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-12T21:51:26,174][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-12T21:51:27,307][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-12T21:51:27,443][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-12T21:51:28,713][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:28,782][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:28,795][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:28,812][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:29,540][ERROR][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] exception during geoip databases update
java.net.UnknownHostException: geoip.elastic.co
	at sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:567) ~[?:?]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333) ~[?:?]
	at java.net.Socket.connect(Socket.java:645) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:300) ~[?:?]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:177) ~[?:?]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:497) ~[?:?]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:600) ~[?:?]
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:265) ~[?:?]
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:379) ~[?:?]
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:189) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1232) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1120) ~[?:?]
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:175) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1653) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1577) ~[?:?]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) ~[?:?]
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:308) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.lambda$get$0(HttpClient.java:55) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at java.security.AccessController.doPrivileged(AccessController.java:554) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.doPrivileged(HttpClient.java:97) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.get(HttpClient.java:49) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.getBytes(HttpClient.java:40) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.fetchDatabasesOverview(GeoIpDownloader.java:135) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.updateDatabases(GeoIpDownloader.java:123) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.runDownloader(GeoIpDownloader.java:260) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:97) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:43) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.persistent.NodePersistentTasksExecutor$1.doRun(NodePersistentTasksExecutor.java:42) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-12T21:51:31,697][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:31,714][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:31,732][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:31,750][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-12T21:51:32,214][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-12T21:51:46,760][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.12][0]]]).
[2022-04-12T21:52:19,477][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:19,640][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:19,649][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:19,764][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:20,137][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:20,351][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:20,782][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:21,046][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:22,471][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:23,002][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:23,644][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:24,372][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:52:26,076][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:53:29,352][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T21:53:48,363][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.12/2pb-rQrZQAyeb-Okcx506Q] update_mapping [_doc]
[2022-04-12T22:11:40,726][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@7f37771a, interval=1s}] took [24586ms] which is above the warn threshold of [5000ms]
[2022-04-12T22:13:07,381][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@7f37771a, interval=1s}] took [23173ms] which is above the warn threshold of [5000ms]
[2022-04-12T22:18:48,775][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:53548}] took [18563ms] which is above the warn threshold of [5000ms]
[2022-04-12T22:18:11,703][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5439ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T22:18:23,957][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:53534}] took [42378ms] which is above the warn threshold of [5000ms]
[2022-04-12T22:18:38,348][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:53622}] took [5465ms] which is above the warn threshold of [5000ms]
[2022-04-12T22:18:38,348][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/_bulk][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.5:53626}] took [9881ms] which is above the warn threshold of [5000ms]
[2022-04-12T22:37:10,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5465316637ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T22:31:50,880][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [13.6s/13640ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@eb394dc5], ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@3bd3f6fd]], which exceeds the warn threshold of [10s]
[2022-04-12T22:40:00,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1m/1571986ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T22:44:08,169][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1m/1571601894064ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T22:42:53,695][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [11.7s/11769ms] to compute cluster state update for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@eb394dc5], ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@3bd3f6fd], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.09-000003], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@d06ca3a2], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@8a08a906]], which exceeds the warn threshold of [10s]
[2022-04-12T22:48:15,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2m/495196ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T22:49:06,846][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [26.2s/26217ms] to notify listeners on unchanged cluster state for [ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.16.2-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@eb394dc5], ilm-set-step-info {policy [ilm-history-ilm-policy], index [.ds-ilm-history-5-2022.04.11-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@3bd3f6fd], ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.04.09-000003], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@d06ca3a2], ilm-set-step-info {policy [kibana-event-log-policy], index [.kibana-event-log-7.17.0-000001], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@8a08a906]], which exceeds the warn threshold of [10s]
[2022-04-12T22:50:51,669][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2m/495579632558ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T22:53:00,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/284366ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T22:54:04,530][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_task_manager/_update_by_query?ignore_unavailable=true&refresh=true&conflicts=proceed][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:53520}] took [284216ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:01:41,480][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/284216110323ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:05:44,631][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7m/764529ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:08:44,125][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [8.2m/495580ms] which is longer than the warn threshold of [300000ms]; there are currently [6] pending tasks, the oldest of which has age [20m/1202755ms]
[2022-04-12T23:08:08,575][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.7m/764326520514ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:11:23,898][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/339665ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:11:19,254][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [25.7m/1544122ms] which is longer than the warn threshold of [300000ms]; there are currently [5] pending tasks, the oldest of which has age [36.5m/2192259ms]
[2022-04-12T23:14:34,990][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6m/339756419743ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:14:55,479][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [31.3m/1883879ms] which is longer than the warn threshold of [300000ms]; there are currently [4] pending tasks, the oldest of which has age [39.1m/2351726ms]
[2022-04-12T23:15:37,193][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@7f37771a, interval=1s}] took [339756ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:17:15,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.8m/351319ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:17:47,361][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] pending task queue has been nonempty for [37.2m/2235173ms] which is longer than the warn threshold of [300000ms]; there are currently [4] pending tasks, the oldest of which has age [23.4m/1405468ms]
[2022-04-12T23:30:22,901][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-12T23:30:22,914][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-12T23:30:22,915][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-12T23:30:27,503][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-12T23:30:27,506][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-12T23:30:27,507][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-12T23:30:27,507][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-12T23:30:27,508][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-12T23:30:27,508][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-12T23:30:27,509][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-12T23:30:27,509][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-12T23:30:27,510][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-12T23:30:27,510][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-12T23:30:27,510][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-12T23:30:27,511][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-12T23:30:27,511][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-12T23:30:27,512][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-12T23:30:27,512][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-12T23:30:27,512][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-12T23:30:27,513][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-12T23:30:27,513][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-12T23:30:27,514][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-12T23:30:27,514][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-12T23:30:27,515][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-12T23:30:27,515][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-12T23:30:27,515][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-12T23:30:27,516][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-12T23:30:27,516][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-12T23:30:27,517][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-12T23:30:27,517][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-12T23:30:27,517][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-12T23:30:27,518][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-12T23:30:27,518][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-12T23:30:27,518][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-12T23:30:27,519][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-12T23:30:27,519][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-12T23:30:27,519][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-12T23:30:27,520][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-12T23:30:27,520][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-12T23:30:27,520][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-12T23:30:27,521][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-12T23:30:27,521][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-12T23:30:27,521][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-12T23:30:27,522][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-12T23:30:27,522][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-12T23:30:27,522][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-12T23:30:27,523][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-12T23:30:27,523][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-12T23:30:27,523][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-12T23:30:27,524][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-12T23:30:27,524][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-12T23:30:27,524][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-12T23:30:27,525][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-12T23:30:27,525][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-12T23:30:27,525][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-12T23:30:27,526][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-12T23:30:27,526][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-12T23:30:27,526][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-12T23:30:27,527][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-12T23:30:27,527][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-12T23:30:27,527][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-12T23:30:27,528][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-12T23:30:27,589][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [106.5gb], net total_space [125.8gb], types [ext4]
[2022-04-12T23:30:27,590][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-12T23:30:28,142][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-12T23:30:37,754][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-12T23:30:37,762][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-04-12T23:30:37,763][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-12T23:30:37,766][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-04-12T23:30:37,766][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-12T23:30:37,767][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-04-12T23:30:37,768][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-04-12T23:30:37,768][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-12T23:30:37,769][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-04-12T23:30:37,769][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-04-12T23:30:37,770][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-04-12T23:30:37,770][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-12T23:30:37,771][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-12T23:30:37,771][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-04-12T23:30:37,772][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-12T23:30:39,142][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-12T23:30:39,366][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-12T23:30:40,734][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-12T23:30:41,467][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-12T23:30:41,468][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-12T23:30:41,580][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-12T23:30:41,583][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-12T23:30:41,813][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-12T23:30:48,713][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-12T23:30:48,881][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{M6RrD_AKSiOk8Ia9hJ9g-w}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 236, version: 9323, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{M6RrD_AKSiOk8Ia9hJ9g-w}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-12T23:30:49,053][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{M6RrD_AKSiOk8Ia9hJ9g-w}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 236, version: 9323, reason: Publication{term=236, version=9323}
[2022-04-12T23:30:49,193][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-12T23:30:49,194][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-12T23:30:55,961][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-12T23:30:56,366][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [49] indices into cluster_state
[2022-04-12T23:31:07,938][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5692ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:31:10,269][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@732cd8dc, interval=1s}] took [7026ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:31:11,062][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5691679753ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:31:11,880][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@12de0844, interval=5s}] took [7569ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:31:11,922][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5s/7569ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:31:13,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5s/7569289214ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:31:35,813][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5101/0x00000008017e7788@53b49b9b] took [15465ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:31:43,592][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@732cd8dc, interval=1s}] took [6524ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:31:55,792][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6s/6638ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:32:21,021][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.6s/6637837507ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:32:38,670][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41859ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:32:54,055][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41858464416ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:33:15,701][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.4s/37420ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:33:35,496][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.4s/37420395615ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:33:53,130][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38s/38028ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:33:58,576][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@3a653d01] took [75448ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:34:07,443][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38s/38028183751ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:34:17,987][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24463ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:34:38,483][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24462330216ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:34:57,158][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.9s/38942ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:35:16,214][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.9s/38942359262ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:35:37,196][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40s/40034ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:35:56,802][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40s/40034627390ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:36:02,026][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@732cd8dc, interval=1s}] took [78976ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:36:21,008][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.3s/43347ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:36:41,308][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.3s/43346492378ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:36:59,529][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38209ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:37:15,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.2s/38209123024ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:37:34,749][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.9s/36930ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:37:45,943][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.9s/36930178924ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:37:55,617][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20809ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:38:04,109][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20808209730ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:38:13,791][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16523ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:38:31,278][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.5s/16523982639ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:38:42,785][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31281ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:38:49,312][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31280660210ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:39:04,844][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19515ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:39:17,842][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.5s/19515209488ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:39:33,823][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.9s/30923ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:39:44,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.9s/30922716490ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:39:58,116][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.7s/24793ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:40:17,819][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.7s/24793342672ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:40:38,769][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39265ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:41:01,240][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39264421699ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:41:18,539][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40383ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:41:44,549][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.3s/40383611721ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:42:08,134][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.6s/48646ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:42:28,839][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.6s/48645881818ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:42:49,054][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.9s/41903ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:43:06,826][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.9s/41902811833ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:43:25,585][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.2s/34267ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:43:48,488][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.2s/34267019856ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:44:13,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.2s/49274ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:44:34,923][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.2s/49273366572ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:45:06,140][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.5s/52571ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:45:16,558][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.5s/52571644524ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:45:32,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27336ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:45:49,681][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27335797110ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:46:07,375][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34s/34055ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:46:24,376][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34s/34055508763ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:46:44,625][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.1s/35186ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:47:09,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.1s/35185701798ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:47:39,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.4s/56405ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:48:01,536][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.4s/56404865522ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:48:17,923][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.9s/39916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:48:27,801][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.9s/39916225467ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:48:38,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21853ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:48:49,112][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21852992070ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:49:10,036][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31161ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:49:18,801][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31160622222ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:49:30,888][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18427ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:49:43,686][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18426668027ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:49:54,739][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26111ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:50:04,608][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26111725801ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:50:21,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24621ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:50:39,103][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24620624462ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:51:04,225][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43830ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:51:18,776][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.8s/43830357065ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:51:34,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.1s/30197ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:51:52,976][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.1s/30196948605ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:52:15,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.8s/37800ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:52:36,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37799357485ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:52:56,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.4s/42489ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:53:12,171][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.4s/42489811403ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:53:12,171][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5101/0x00000008017e7788@690bf4ea] took [994679ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:53:36,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:54:06,830][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.2s/39234539340ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:54:38,512][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64433ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:54:59,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64433493079ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:55:19,795][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40555ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:55:39,112][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40554969225ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:56:08,710][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@732cd8dc, interval=1s}] took [104988ms] which is above the warn threshold of [5000ms]
[2022-04-12T23:56:20,073][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60477ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:56:53,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/60476362212ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:57:13,746][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55s/55015ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:56:18,714][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [40555ms] which is above the warn threshold of [5s]
[2022-04-12T23:57:22,317][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55s/55015195328ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:57:32,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18066ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:57:46,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18066040444ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:58:00,795][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27467ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:58:11,826][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27466968683ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:58:23,997][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23975ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:58:39,664][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.9s/23975341247ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:58:50,685][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26945ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:59:03,310][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.9s/26944956679ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:59:13,713][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22962ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:59:22,552][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22962244287ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:59:32,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19444ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-12T23:59:42,277][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.4s/19443601029ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-12T23:59:51,047][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.4s/18451ms] on absolute clock which is above the warn threshold of [5000ms]
