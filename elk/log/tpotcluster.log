[2022-03-29T16:58:42,321][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-29T16:58:42,384][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-29T16:58:42,386][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-29T16:58:58,423][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-29T16:58:58,429][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-29T16:58:58,431][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-29T16:58:58,431][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-29T16:58:58,432][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-29T16:58:58,432][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-29T16:58:58,433][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-29T16:58:58,439][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-29T16:58:58,440][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-29T16:58:58,441][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-29T16:58:58,441][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-29T16:58:58,442][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-29T16:58:58,450][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-29T16:58:58,450][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-29T16:58:58,451][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-29T16:58:58,459][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-29T16:58:58,460][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-29T16:58:58,460][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-29T16:58:58,461][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-29T16:58:58,469][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-29T16:58:58,470][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-29T16:58:58,470][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-29T16:58:58,471][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-29T16:58:58,472][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-29T16:58:58,476][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-29T16:58:58,476][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-29T16:58:58,480][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-29T16:58:58,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-29T16:58:58,481][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-29T16:58:58,489][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-29T16:58:58,490][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-29T16:58:58,500][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-29T16:58:58,502][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-29T16:58:58,502][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-29T16:58:58,503][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-29T16:58:58,504][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-29T16:58:58,504][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-29T16:58:58,505][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-29T16:58:58,510][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-29T16:58:58,511][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-29T16:58:58,521][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-29T16:58:58,522][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-29T16:58:58,523][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-29T16:58:58,523][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-29T16:58:58,530][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-29T16:58:58,530][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-29T16:58:58,531][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-29T16:58:58,531][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-29T16:58:58,532][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-29T16:58:58,533][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-29T16:58:58,533][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-29T16:58:58,540][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-29T16:58:58,541][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-29T16:58:58,541][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-29T16:58:58,543][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-29T16:58:58,548][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-29T16:58:58,550][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-29T16:58:58,554][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-29T16:58:58,555][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-29T16:58:58,741][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.6gb], net total_space [125.8gb], types [ext4]
[2022-03-29T16:58:58,742][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-29T16:58:59,433][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-29T16:59:18,955][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-29T16:59:18,959][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-29T16:59:20,755][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-03-29T16:59:21,003][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-03-29T16:59:22,459][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-03-29T16:59:23,879][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-03-29T16:59:23,888][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-03-29T16:59:23,955][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-03-29T16:59:23,956][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-03-29T16:59:24,303][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-03-29T16:59:28,095][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-03-29T16:59:28,264][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{jR_AE3WqTvG3b_wTAwv1Kw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 153, version: 4375, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{jR_AE3WqTvG3b_wTAwv1Kw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-03-29T16:59:28,560][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{jR_AE3WqTvG3b_wTAwv1Kw}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 153, version: 4375, reason: Publication{term=153, version=4375}
[2022-03-29T16:59:28,722][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-03-29T16:59:28,722][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-03-29T16:59:32,495][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-03-29T16:59:32,504][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [32] indices into cluster_state
[2022-03-29T16:59:35,224][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-03-29T16:59:35,225][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-03-29T16:59:37,169][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-ASN.mmdb] is up to date, updated timestamp
[2022-03-29T16:59:37,636][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-City.mmdb] is up to date, updated timestamp
[2022-03-29T16:59:39,158][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] geoip database [GeoLite2-Country.mmdb] is up to date, updated timestamp
[2022-03-29T16:59:39,322][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-03-29T16:59:39,333][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-03-29T16:59:39,352][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-03-29T16:59:39,644][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] removing template [logstash]
[2022-03-29T16:59:41,097][INFO ][o.e.c.m.MetadataIndexTemplateService] [tpotcluster-node-01] adding template [logstash] for index patterns [logstash-*]
[2022-03-29T16:59:42,354][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-03-29T16:59:42,582][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-03-29T16:59:57,742][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][33] overhead, spent [1s] collecting in the last [1.5s]
[2022-03-29T16:59:59,877][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-03-29T17:00:15,700][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.03.29][0]]]).
[2022-03-29T17:00:49,535][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 515 finished with response BulkByScrollResponse[took=541.4ms,timed_out=false,sliceId=null,updated=17,created=0,deleted=0,batches=1,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-03-29T17:00:52,433][INFO ][o.e.t.LoggingTaskListener] [tpotcluster-node-01] 531 finished with response BulkByScrollResponse[took=3s,timed_out=false,sliceId=null,updated=1038,created=0,deleted=0,batches=2,versionConflicts=0,noops=0,retries=0,throttledUntil=0s,bulk_failures=[],search_failures=[]]
[2022-03-29T17:01:02,273][INFO ][o.e.x.i.a.TransportPutLifecycleAction] [tpotcluster-node-01] updating index lifecycle policy [.alerts-ilm-policy]
[2022-03-29T17:02:03,771][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.29/4CNLAl-yQqmObSIQcEvFWA] update_mapping [_doc]
[2022-03-29T17:04:01,357][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.29/4CNLAl-yQqmObSIQcEvFWA] update_mapping [_doc]
[2022-03-29T17:22:13,418][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.29/4CNLAl-yQqmObSIQcEvFWA] update_mapping [_doc]
[2022-03-29T17:24:31,553][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.03.29/4CNLAl-yQqmObSIQcEvFWA] update_mapping [_doc]
[2022-03-29T17:32:21,449][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@5aef5a62, interval=1s}] took [36279ms] which is above the warn threshold of [5000ms]
[2022-03-29T17:41:01,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.9s/5937ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T18:45:52,886][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-29T18:45:52,930][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-29T18:45:52,931][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-29T18:45:59,636][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-29T18:45:59,639][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-29T18:45:59,640][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-29T18:45:59,641][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-29T18:45:59,642][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-29T18:45:59,644][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-29T18:45:59,644][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-29T18:45:59,645][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-29T18:45:59,646][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-29T18:45:59,647][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-29T18:45:59,647][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-29T18:45:59,649][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-29T18:45:59,650][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-29T18:45:59,650][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-29T18:45:59,652][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-29T18:45:59,653][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-29T18:45:59,654][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-29T18:45:59,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-29T18:45:59,655][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-29T18:45:59,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-29T18:45:59,658][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-29T18:45:59,660][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-29T18:45:59,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-29T18:45:59,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-29T18:45:59,663][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-29T18:45:59,665][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-29T18:45:59,666][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-29T18:45:59,666][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-29T18:45:59,667][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-29T18:45:59,667][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-29T18:45:59,668][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-29T18:45:59,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-29T18:45:59,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-29T18:45:59,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-29T18:45:59,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-29T18:45:59,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-29T18:45:59,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-29T18:45:59,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-29T18:45:59,675][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-29T18:45:59,677][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-29T18:45:59,680][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-29T18:45:59,681][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-29T18:45:59,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-29T18:45:59,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-29T18:45:59,683][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-29T18:45:59,683][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-29T18:45:59,683][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-29T18:45:59,684][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-29T18:45:59,685][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-29T18:45:59,685][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-29T18:45:59,686][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-29T18:45:59,686][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-29T18:45:59,687][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-29T18:45:59,688][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-29T18:45:59,690][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-29T18:45:59,691][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-29T18:45:59,693][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-29T18:45:59,693][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-29T18:45:59,694][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-29T18:45:59,773][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.5gb], net total_space [125.8gb], types [ext4]
[2022-03-29T18:45:59,773][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-29T18:46:00,167][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-29T18:46:12,489][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-29T18:46:12,494][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-03-29T18:46:12,495][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-03-29T18:46:12,496][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-03-29T18:46:12,497][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-29T18:46:12,498][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-03-29T18:46:12,498][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-03-29T18:46:12,499][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-29T18:46:12,500][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-03-29T18:46:12,500][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-03-29T18:46:12,501][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-03-29T18:46:12,502][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-03-29T18:46:12,503][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-03-29T18:46:12,504][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-29T18:46:12,505][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-29T18:46:13,980][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-03-29T18:46:14,175][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-03-29T18:46:15,098][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-03-29T18:46:16,000][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-03-29T18:46:16,001][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-03-29T18:46:16,079][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-03-29T18:46:16,081][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-03-29T18:46:16,314][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-03-29T18:46:18,446][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-03-29T18:46:18,557][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{YXLgQ-tbQ4arHLdAvjQP9A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 154, version: 4424, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{YXLgQ-tbQ4arHLdAvjQP9A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-03-29T18:46:18,744][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{YXLgQ-tbQ4arHLdAvjQP9A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 154, version: 4424, reason: Publication{term=154, version=4424}
[2022-03-29T18:46:18,846][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-03-29T18:46:18,847][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-03-29T18:46:20,028][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-03-29T18:46:20,035][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [32] indices into cluster_state
[2022-03-29T18:46:20,861][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-03-29T18:46:20,862][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-03-29T18:46:23,340][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-03-29T18:46:23,356][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-03-29T18:46:23,382][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-03-29T18:46:25,873][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-03-29T18:46:26,018][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-03-29T18:46:26,024][ERROR][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] exception during geoip databases update
java.net.UnknownHostException: geoip.elastic.co
	at sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:567) ~[?:?]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333) ~[?:?]
	at java.net.Socket.connect(Socket.java:645) ~[?:?]
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:300) ~[?:?]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:177) ~[?:?]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:497) ~[?:?]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:600) ~[?:?]
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:265) ~[?:?]
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:379) ~[?:?]
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:189) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1232) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1120) ~[?:?]
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:175) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1653) ~[?:?]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1577) ~[?:?]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527) ~[?:?]
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:308) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.lambda$get$0(HttpClient.java:55) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at java.security.AccessController.doPrivileged(AccessController.java:554) ~[?:?]
	at org.elasticsearch.ingest.geoip.HttpClient.doPrivileged(HttpClient.java:97) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.get(HttpClient.java:49) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.HttpClient.getBytes(HttpClient.java:40) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.fetchDatabasesOverview(GeoIpDownloader.java:135) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.updateDatabases(GeoIpDownloader.java:123) ~[ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloader.runDownloader(GeoIpDownloader.java:260) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:97) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.ingest.geoip.GeoIpDownloaderTaskExecutor.nodeOperation(GeoIpDownloaderTaskExecutor.java:43) [ingest-geoip-7.17.0.jar:7.17.0]
	at org.elasticsearch.persistent.NodePersistentTasksExecutor$1.doRun(NodePersistentTasksExecutor.java:42) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-03-29T18:46:28,040][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:29,286][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][13] overhead, spent [549ms] collecting in the last [1s]
[2022-03-29T18:46:30,933][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:31,039][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:31,104][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:31,149][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:31,183][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:31,242][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:31,292][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_update_by_query, params: {ignore_unavailable=true, refresh=true, conflicts=proceed, index=.kibana_task_manager}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-03-29T18:46:35,734][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-03-29T18:46:43,990][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.03.29][0]]]).
[2022-03-29T20:11:30,398][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [23058ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:12:02,279][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7995ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:13:10,160][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.9s/7995104458ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:13:18,728][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86225ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:13:19,284][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [86224ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:13:41,255][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86224719044ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:15:55,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/155926ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:17:02,158][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/155926263486ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:17:29,016][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93335ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:17:55,121][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/93335160737ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:18:15,627][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42579ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:18:41,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.5s/42578886914ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:19:19,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68337ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:18:25,731][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [42579ms] which is above the warn threshold of [5s]
[2022-03-29T20:19:44,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/68337055462ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:19:25,128][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [68337ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:20:09,884][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.7s/50763ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:20:30,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.7s/50763069623ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:20:48,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.1s/38196ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:21:02,855][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.1s/38196127756ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:21:15,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27776ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:21:21,766][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27775726145ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:21:36,018][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20098ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:21:51,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19996062453ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:22:10,500][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.4s/34455ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:22:29,770][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.5s/34556593639ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:23:00,508][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.8s/48819ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:23:17,326][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48.8s/48819325868ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:23:31,452][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.4s/32464ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:23:52,658][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.4s/32463659441ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:24:00,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28871ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:24:23,185][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [28870ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:24:18,092][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.8s/28870982273ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:24:53,772][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53.4s/53446ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:25:24,568][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [53.4s/53446736029ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:26:01,692][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67111ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:26:38,011][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/67110742642ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:27:01,510][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.6s/57673ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:27:27,227][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.6s/57672815335ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:27:54,769][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.3s/55348ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:28:23,765][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.3s/55348059814ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:28:49,410][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55490ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:27:37,308][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [57673ms] which is above the warn threshold of [5s]
[2022-03-29T20:29:08,864][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.4s/55489985879ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:29:35,600][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.5s/45543ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:29:55,427][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.5s/45543259312ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:30:26,561][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51s/51011ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:30:51,263][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [50.7s/50718946860ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:31:27,899][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.6s/57669ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:32:35,832][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57.9s/57960866480ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:33:11,478][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/107342ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:33:40,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/107341562999ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:34:07,882][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.8s/56833ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:34:45,901][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [56833ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:34:35,445][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [56.8s/56833551899ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:35:18,868][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70992ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:35:51,354][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70991903315ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:36:14,173][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.2s/55229ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:36:35,303][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.2s/55228408006ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:37:00,032][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.6s/45685ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:37:17,749][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.6s/45685024000ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:37:36,041][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.3s/36307ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:37:53,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [36.3s/36307294405ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:38:16,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.8s/39858ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:38:29,644][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.8s/39857854437ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:38:47,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31278ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:39:08,655][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31278500430ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:39:25,146][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37775ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:40:02,277][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.7s/37774827976ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:40:24,363][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.5s/59512ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:40:38,149][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [59.5s/59512335404ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:41:12,919][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [30785] timed out after [476912ms]
[2022-03-29T20:41:20,023][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.5s/55508ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:41:33,318][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.5s/55507824297ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:41:19,189][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [34.7s/34740ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@3a1f884b]], which exceeds the warn threshold of [10s]
[2022-03-29T20:41:47,714][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27728ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:40:39,920][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [59512ms] which is above the warn threshold of [5s]
[2022-03-29T20:42:14,821][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.7s/27727535530ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:42:39,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.5s/51557ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:42:58,165][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [51.5s/51557230560ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:42:23,861][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:50008}] took [27728ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:42:20,575][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][GET][/_xpack?accept_enterprise=true][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:50016}] took [55508ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:43:16,874][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.5s/37528ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:43:32,765][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.5s/37528141222ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:43:45,190][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.3s/28357ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:43:53,940][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.3s/28356880484ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:44:08,607][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23328ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:44:18,956][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.3s/23327535545ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:44:15,048][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [23327ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:44:34,453][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26131ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:44:55,172][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26131806559ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:45:16,011][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40516ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:45:34,484][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40515884550ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:45:56,413][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40596ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:46:02,857][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017d8258@4892bdc0] took [40595ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:46:15,014][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.5s/40595349418ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:46:29,436][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.5s/33516ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:46:41,607][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.5s/33516508465ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:46:57,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [33516ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:47:10,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41s/41084ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:47:36,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41s/41083515166ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:47:54,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43695ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:48:15,221][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43695100557ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:48:34,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40s/40060ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:48:49,892][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40s/40059931121ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:49:08,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.2s/33299ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:49:24,226][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.2s/33299374005ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:48:44,655][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [40060ms] which is above the warn threshold of [5s]
[2022-03-29T20:49:42,020][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34193ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:50:05,358][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34193224329ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:50:29,662][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.1s/41107ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:50:50,702][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.1s/41106646381ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:51:11,534][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.7s/46756ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:51:47,392][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.7s/46756242969ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:52:12,711][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62819ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:52:31,599][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62819128859ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:52:35,736][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [62819ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:52:51,455][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.9s/38958ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:53:11,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.9s/38957566012ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:53:44,090][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.6s/52621ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:54:00,227][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.6s/52621055808ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:52:57,402][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [30929] timed out after [225847ms]
[2022-03-29T20:54:46,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62730ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:55:04,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/62730270805ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:55:17,756][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31s/31098ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:55:30,991][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31s/31097390846ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:54:49,797][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [39.5m/2372457ms] ago, timed out [31.5m/1895545ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{YXLgQ-tbQ4arHLdAvjQP9A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [30785]
[2022-03-29T20:55:46,334][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28738ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:55:57,812][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28738490797ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:56:17,682][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31203ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:56:44,178][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.2s/31202958364ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:57:02,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.2s/42210ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:57:17,683][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.2s/42209778075ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:57:38,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.4s/38413ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:57:56,084][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.4s/38413439879ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:58:05,742][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [38413ms] which is above the warn threshold of [5000ms]
[2022-03-29T20:58:10,128][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31722ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:57:48,121][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [38413ms] which is above the warn threshold of [5s]
[2022-03-29T20:58:27,583][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.7s/31722260602ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T20:59:00,083][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.8s/49894ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T20:59:29,883][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.8s/49893872514ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:00:11,526][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/71277ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:00:45,642][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/71276704874ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:01:06,242][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.1s/55178ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:01:20,411][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [55.1s/55177519453ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:01:35,175][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28788ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:01:46,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.7s/28788059967ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:02:01,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26151ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:02:23,736][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26151424404ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:02:40,813][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.9s/37916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:02:54,877][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [37.9s/37915835941ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:03:08,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29500ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:03:22,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.5s/29500147762ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:03:34,103][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [29500ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:03:34,559][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.2s/26201ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:03:49,738][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.2s/26201120757ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:04:04,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30s/30034ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:04:15,786][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30s/30034229567ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:04:38,650][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33757ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:04:50,944][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.7s/33756120958ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:04:17,816][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [30034ms] which is above the warn threshold of [5s]
[2022-03-29T21:05:03,774][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25165ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:05:15,432][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25165963736ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:05:31,844][WARN ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] handling request [null][POST][/.kibana_task_manager/_update_by_query?ignore_unavailable=true&refresh=true&conflicts=proceed][Netty4HttpChannel{localAddress=/192.168.48.2:9200, remoteAddress=/192.168.48.4:49996}] took [58922ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:05:36,714][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017d8258@6640227] took [32830ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:05:36,714][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.8s/32831ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:05:50,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.8s/32830339066ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:06:07,227][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30666ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:06:16,523][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.6s/30666636853ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:06:21,380][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [30666ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:06:26,329][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19173ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:06:33,205][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.1s/19172204929ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:06:47,686][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21347ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:06:58,281][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21347184515ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:07:17,502][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.9s/29948ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:07:29,417][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.9s/29948354280ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:07:40,811][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22938ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:07:47,291][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [22937ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:07:50,843][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.9s/22937799922ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:08:02,848][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22174ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:08:07,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5109/0x00000008017d8258@240ded95] took [22173ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:08:12,916][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22173713329ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:08:24,758][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21932ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:08:41,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.9s/21932703037ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:08:56,919][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31458ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:09:10,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31457858082ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:09:23,429][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27141ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:09:24,176][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [27140ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:09:36,467][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.1s/27140658520ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:09:48,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.4s/25436ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:10:11,349][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.4s/25436048599ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:10:23,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35252ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:10:36,550][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35.2s/35252092574ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:10:51,957][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27879ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:11:07,371][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.8s/27878710936ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:11:19,877][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.6s/27610ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:11:34,022][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.6s/27610367974ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:11:06,944][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [24.9m/1496258ms] ago, timed out [21.1m/1270411ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{YXLgQ-tbQ4arHLdAvjQP9A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [30929]
[2022-03-29T21:11:48,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [55662ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:11:48,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28s/28053ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:11:58,140][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28s/28052551553ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:12:13,030][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25117ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:12:27,788][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.1s/25117374277ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:12:45,030][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32224ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:12:46,965][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3f2650d, interval=5s}] took [32223ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:13:02,586][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32223622211ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:13:23,656][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.8s/38860ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:13:38,598][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.8s/38860472439ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:13:53,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30s/30018ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:14:11,829][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30s/30017835396ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:14:33,591][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.7s/39771ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:14:51,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39.7s/39771104766ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:15:17,157][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43605ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:15:28,565][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [43605ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:15:37,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.6s/43605117533ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:15:52,863][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35s/35079ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:16:06,644][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [35s/35078693897ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:16:19,344][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26792ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:16:40,238][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.7s/26792161958ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:17:01,843][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.6s/42616ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:17:23,214][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.6s/42615845209ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:17:43,661][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41816ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:17:01,628][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [31082] timed out after [221653ms]
[2022-03-29T21:18:25,280][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.8s/41816041060ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:18:48,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64537ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:18:50,569][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [64536ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:19:06,552][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1m/64536604650ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:19:39,985][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.6s/49601ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:20:05,218][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.6s/49600963285ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:20:24,966][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.1s/47193ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:20:54,705][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [47.1s/47193181818ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:21:04,124][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [14.9s/14968ms] to compute cluster state update for [ilm-set-step-info {policy [.deprecation-indexing-ilm-policy], index [.ds-.logs-deprecation.elasticsearch-default-2022.03.26-000002], currentStep [{"phase":"hot","action":"rollover","name":"check-rollover-ready"}]}[org.elasticsearch.xpack.ilm.SetStepInfoUpdateTask@3a1f884b]], which exceeds the warn threshold of [10s]
[2022-03-29T21:21:22,480][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57s/57016ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:21:38,194][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [57s/57016366020ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:21:56,131][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34185ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:22:14,224][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [34.1s/34185071745ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:22:22,063][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [34185ms] which is above the warn threshold of [5s]
[2022-03-29T21:22:34,617][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.1s/38189ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:23:00,888][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.1s/38188380119ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:23:23,770][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48s/48041ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:23:41,475][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [48s/48041691703ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:24:02,479][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.1s/40189ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:24:19,172][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [40.1s/40188834664ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:24:41,019][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38347ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:25:04,788][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38346945190ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:25:24,534][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.5s/43547ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:25:42,210][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [43.5s/43547440727ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:26:02,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38376ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:26:22,736][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.3s/38375039126ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:26:42,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39s/39064ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:27:03,096][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [39s/39064799657ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:27:28,758][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.2s/46259ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:27:48,740][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [46258ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:27:50,782][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46.2s/46258803131ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:28:22,734][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.2s/54211ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:28:27,530][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@3f2650d, interval=5s}] took [54210ms] which is above the warn threshold of [5000ms]
[2022-03-29T21:28:46,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54.2s/54210906589ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:29:14,399][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.1s/52155ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:29:31,406][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [52.1s/52154665988ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:29:57,727][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.7s/42707ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:30:22,964][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [42.7s/42706946605ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:30:52,594][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54s/54078ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:31:35,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [54s/54078624091ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:32:09,878][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73285ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:33:10,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/73284700946ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:34:43,450][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/153946ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:35:55,637][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2.5m/153859625323ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:38:19,138][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/184429ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:40:40,224][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/184136232586ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:43:27,153][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/343831ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:47:28,999][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7m/343992365331ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:50:24,589][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9m/416863ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:46:43,044][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [343992ms] which is above the warn threshold of [5s]
[2022-03-29T21:53:11,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.9m/416955095862ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T21:56:05,681][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/326899ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T21:58:25,723][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/326727840142ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:01:55,026][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6m/363108ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:04:18,664][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6m/362918310469ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:06:47,461][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.6m/280828ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:09:22,168][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.6m/280934992153ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:11:36,709][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/301555ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:13:52,285][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5m/301934749374ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:17:09,309][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/331963ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:10:10,620][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [31191] timed out after [958424ms]
[2022-03-29T22:19:30,284][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.5m/331379063583ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:21:42,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273265ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:23:52,057][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273476276397ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:26:13,096][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/270343ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:29:07,508][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/270376194631ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:31:33,520][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/320632ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:33:32,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.3m/320519591166ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:35:44,062][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.1m/250741ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:38:02,730][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.1m/250749403799ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:40:26,622][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/282189ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:42:39,388][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.7m/282181201610ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:45:29,773][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/273776ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:46:54,805][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@62a357b9, interval=1s}] took [274110ms] which is above the warn threshold of [5000ms]
[2022-03-29T22:47:59,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.5m/274110311480ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:50:39,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/325910ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T22:52:43,441][WARN ][o.e.t.TransportService   ] [tpotcluster-node-01] Received response for a request that has timed out, sent [1.4h/5372682ms] ago, timed out [1.4h/5151029ms] ago, action [indices:monitor/stats[n]], node [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{YXLgQ-tbQ4arHLdAvjQP9A}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}{xpack.installed=true, transform.node=true}], id [31082]
[2022-03-29T22:54:56,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4m/325666476623ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T22:57:18,634][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.8m/411695ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:05:30,150][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-03-29T23:05:30,200][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-03-29T23:05:30,203][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-03-29T23:05:40,387][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-03-29T23:05:40,390][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-03-29T23:05:40,393][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-03-29T23:05:40,394][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-03-29T23:05:40,395][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-03-29T23:05:40,397][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-03-29T23:05:40,398][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-03-29T23:05:40,399][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-03-29T23:05:40,400][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-03-29T23:05:40,401][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-03-29T23:05:40,402][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-03-29T23:05:40,403][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-03-29T23:05:40,404][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-03-29T23:05:40,405][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-03-29T23:05:40,406][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-03-29T23:05:40,407][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-03-29T23:05:40,408][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-03-29T23:05:40,409][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-03-29T23:05:40,410][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-03-29T23:05:40,412][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-03-29T23:05:40,413][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-03-29T23:05:40,414][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-03-29T23:05:40,415][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-03-29T23:05:40,416][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-03-29T23:05:40,417][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-03-29T23:05:40,418][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-03-29T23:05:40,419][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-03-29T23:05:40,420][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-03-29T23:05:40,421][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-03-29T23:05:40,422][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-03-29T23:05:40,424][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-03-29T23:05:40,425][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-03-29T23:05:40,426][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-03-29T23:05:40,427][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-03-29T23:05:40,428][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-03-29T23:05:40,429][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-03-29T23:05:40,430][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-03-29T23:05:40,431][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-03-29T23:05:40,432][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-03-29T23:05:40,433][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-03-29T23:05:40,434][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-03-29T23:05:40,435][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-03-29T23:05:40,436][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-03-29T23:05:40,436][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-03-29T23:05:40,437][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-03-29T23:05:40,438][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-03-29T23:05:40,439][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-03-29T23:05:40,440][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-03-29T23:05:40,441][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-03-29T23:05:40,442][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-03-29T23:05:40,443][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-03-29T23:05:40,444][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-03-29T23:05:40,445][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-03-29T23:05:40,446][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-03-29T23:05:40,447][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-03-29T23:05:40,448][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-03-29T23:05:40,449][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-03-29T23:05:40,449][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-03-29T23:05:40,451][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-03-29T23:05:40,548][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [103.3gb], net total_space [125.8gb], types [ext4]
[2022-03-29T23:05:40,550][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-03-29T23:05:40,942][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-03-29T23:05:53,526][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-03-29T23:05:53,536][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_LICENSE.txt]
[2022-03-29T23:05:53,539][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-03-29T23:05:53,545][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_LICENSE.txt]
[2022-03-29T23:05:53,558][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-29T23:05:53,564][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_COPYRIGHT.txt]
[2022-03-29T23:05:53,573][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_COPYRIGHT.txt]
[2022-03-29T23:05:53,574][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-29T23:05:53,575][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_README.txt]
[2022-03-29T23:05:53,576][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb_COPYRIGHT.txt]
[2022-03-29T23:05:53,576][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb_LICENSE.txt]
[2022-03-29T23:05:53,577][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-03-29T23:05:53,580][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-03-29T23:05:53,581][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] deleting stale file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb_elastic-geoip-database-service-agreement-LICENSE.txt]
[2022-03-29T23:05:53,583][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-03-29T23:05:54,881][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-03-29T23:05:55,042][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-03-29T23:05:56,150][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-03-29T23:05:57,161][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-03-29T23:05:57,163][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-03-29T23:05:57,285][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-03-29T23:05:57,291][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-03-29T23:05:57,591][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-03-29T23:06:02,320][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-03-29T23:06:02,463][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{8g0PWzQfTHOEm6Vp4jQRHQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 155, version: 4468, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{8g0PWzQfTHOEm6Vp4jQRHQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-03-29T23:06:02,696][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{8g0PWzQfTHOEm6Vp4jQRHQ}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 155, version: 4468, reason: Publication{term=155, version=4468}
[2022-03-29T23:06:02,829][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-03-29T23:06:02,832][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-03-29T23:06:04,975][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-03-29T23:06:04,998][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [32] indices into cluster_state
[2022-03-29T23:06:07,892][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-03-29T23:06:07,898][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-03-29T23:07:29,248][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@6231b6ab, interval=5s}] took [10431ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:08:11,433][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24550ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:12:02,708][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.5s/24550550801ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:12:30,230][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/309274ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:12:50,862][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1m/309273729605ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:13:05,770][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6d2b9767, interval=1s}] took [309273ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:13:20,094][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.7s/49784ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:13:39,005][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [49.7s/49784398526ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:14:49,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86657ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:15:38,159][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/86656327003ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:16:03,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/77075ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:16:21,572][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/77075796176ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:26:34,669][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5m/632196ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:26:44,402][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.5m/632195607215ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:26:45,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@edd1edc, interval=5s}] took [795927ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:26:55,170][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21479ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:27:05,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21478807048ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:27:17,576][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21643ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:27:50,506][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.6s/21643021308ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:28:02,123][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.2s/45224ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:28:12,496][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.2s/45223853992ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:28:26,127][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23654ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:28:37,539][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23654676120ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:28:48,850][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22s/22097ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:29:02,206][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22s/22096786444ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:29:14,743][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25970ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:29:24,843][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25969972656ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:29:35,881][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21740ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:29:47,614][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.7s/21740174182ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:30:01,493][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24644ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:30:16,891][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24643694030ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:30:46,548][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.8s/45837ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:31:00,132][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [45.8s/45837421111ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:31:10,572][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24410ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:31:21,573][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.4s/24409360099ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:31:35,102][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23059ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:31:45,225][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23s/23059659912ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:31:55,580][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22s/22055ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:32:08,904][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22s/22054801658ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:32:26,251][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.9s/29911ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:32:41,202][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.9s/29910424854ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:32:54,001][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28s/28087ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:33:05,874][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28s/28087444193ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:33:18,294][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.2s/24235ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:33:30,092][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.2s/24234582201ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:33:41,506][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23187ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:33:52,229][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23186836166ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:34:09,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.2s/25236ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:34:20,768][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.2s/25236234506ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:34:31,037][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.8s/24880ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:34:41,948][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.8s/24880048141ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:34:53,253][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21830ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:35:03,145][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.8s/21830551394ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:35:15,238][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21563ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:35:29,387][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.5s/21563173053ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:35:42,714][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.3s/28371ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:35:51,487][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.3s/28370471642ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:36:01,476][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18065ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:36:15,125][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18s/18065331505ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:36:27,918][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26462ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:36:38,315][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.4s/26462136730ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:36:49,266][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21394ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:37:02,612][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.3s/21393265441ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:37:15,150][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26121ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:37:25,808][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26121234318ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:37:36,948][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.5s/20561ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:37:49,930][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.5s/20561487397ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:38:05,161][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.5s/28549ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:38:19,298][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.5s/28548748295ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:38:33,855][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.2s/29217ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:38:48,869][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [29.2s/29217251552ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:39:02,554][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.1s/28123ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:39:13,890][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.1s/28122477952ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:39:27,657][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24680ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:39:44,482][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.6s/24680367738ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:39:58,081][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31427ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:40:11,142][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.4s/31426469910ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:40:24,751][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26182ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:40:41,204][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26182470430ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:40:55,552][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31129ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:40:55,712][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5095/0x00000008017dd978@41bc29e9] took [839542ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:41:09,713][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.1s/31128516418ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:41:37,911][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.9s/41963ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:41:51,352][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [41.9s/41963319547ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:42:10,111][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30533ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:42:25,486][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.5s/30533029811ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:42:41,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.1s/33128ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:42:57,868][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [33.1s/33128357584ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:43:14,524][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32272ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:43:31,926][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.2s/32271699508ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:43:44,511][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.indices.IndicesService$CacheCleaner@21c6dab8] took [32271ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:44:01,031][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46s/46080ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:44:38,844][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [46s/46080324956ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:45:10,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66310ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:45:39,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/66309670352ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:46:30,165][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/82699ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:47:02,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6d2b9767, interval=1s}] took [149008ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:47:24,599][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.3m/82699000058ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:47:40,252][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70402ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:47:52,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70402209969ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:48:06,116][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.8s/25826ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:48:20,018][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.8s/25825664083ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:47:43,210][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [82699ms] which is above the warn threshold of [5s]
[2022-03-29T23:48:35,974][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.8s/31899ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:48:45,253][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [31.8s/31899017624ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:48:51,869][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@edd1edc, interval=5s}] took [31899ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:49:01,881][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23209ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:49:11,260][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.2s/23209106642ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:49:22,976][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23182ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:49:34,132][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23182004428ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:49:42,707][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.3s/20355ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:49:54,158][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.3s/20354664107ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:50:02,873][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.3s/20343ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:50:14,025][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.3s/20343560910ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:50:15,501][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6d2b9767, interval=1s}] took [20343ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:50:23,120][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19932ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:50:36,416][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19931904749ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:50:48,215][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25344ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:50:57,989][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.3s/25344074882ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:04,935][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16604ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:13,232][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.6s/16603250954ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:21,418][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16333ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:30,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6d2b9767, interval=1s}] took [16333ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:51:30,581][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.3s/16333745063ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:40,125][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18127ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:49,495][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.1s/18126218391ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:51:50,889][WARN ][o.e.c.InternalClusterInfoService] [tpotcluster-node-01] failed to retrieve shard stats from node [t9hfPgy_RyC9LOJUxQUrSQ]: [tpotcluster-node-01][127.0.0.1:9300][indices:monitor/stats[n]] request_id [64] timed out after [515450ms]
[2022-03-29T23:51:57,877][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17982ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:06,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17982072904ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:14,972][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17772ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:24,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.7s/17772143909ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:32,953][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18299ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:40,054][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.2s/18299550269ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:16,780][WARN ][o.e.m.f.FsHealthService  ] [tpotcluster-node-01] health check of [/data/elk/data/nodes/0] took [17772ms] which is above the warn threshold of [5s]
[2022-03-29T23:52:47,341][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.2s/13290ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:52:59,566][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.2s/13289861898ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:53:05,438][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@6d2b9767, interval=1s}] took [31589ms] which is above the warn threshold of [5000ms]
[2022-03-29T23:53:09,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22455ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:53:16,115][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.4s/22454859257ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:53:21,380][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12057ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:53:28,598][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12s/12056638404ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:53:36,161][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15355ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:53:43,316][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.3s/15355075979ns] on relative clock which is above the warn threshold of [5000ms]
[2022-03-29T23:56:02,628][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/124029ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-03-29T23:59:25,360][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [2m/123719408405ns] on relative clock which is above the warn threshold of [5000ms]
