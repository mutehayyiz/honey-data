[2022-04-10T00:05:43,832][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5703ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:01:31,852][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [5362ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:14:52,909][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.7s/5703051492ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:02,174][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3m/560356ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:02,928][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@435fa086, interval=1m}] took [560356ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:15:11,529][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3m/560356178519ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:29,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.4s/27422ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:29,232][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [22100ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:15:40,101][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22.1s/22100588657ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:49,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20851ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:56,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26172524096ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:16:07,072][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@435fa086, interval=1m}] took [15869ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:16:05,827][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15870ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:15:29,013][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@6e5911ba] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-10T00:16:14,574][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.8s/15869575666ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:16:28,017][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.8s/17876ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:16:29,370][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@ee98b86, interval=30s}] took [17876ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:16:37,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.8s/17876270538ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:16:49,916][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25979ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:16:52,963][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [25979ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:17:04,543][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25979132151ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:17:32,515][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.9s/32927ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:17:40,265][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [32926ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:17:43,513][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [32.9s/32926350863ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:01,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.1s/38101ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:02,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@435fa086, interval=1m}] took [38101ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:18:10,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [38.1s/38101541581ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:18,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17912ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:18,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [17911ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:18:24,597][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.9s/17911874717ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:30,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13049ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:30,929][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@ee98b86, interval=30s}] took [13048ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:18:40,386][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13048525931ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:47,943][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.7s/16774ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:18:54,060][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [16.7s/16774409519ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:02,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14362ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:02,509][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@ee98b86, interval=30s}] took [14361ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:19:06,789][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.3s/14361444271ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:15,415][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13054ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:22,548][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13s/13054319305ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:31,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15942ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:31,755][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [15941ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:19:41,954][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.9s/15941962243ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:52,439][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21155ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:19:55,270][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [21155ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:20:01,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.1s/21155137553ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:20:13,469][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20831ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:20:16,003][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [20831ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:20:22,128][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20831418059ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:20:32,864][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18609ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:20:37,948][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [18608ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:20:46,221][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.6s/18608267189ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:20:59,494][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.2s/26248ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:21:00,254][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [26248ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:21:12,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.2s/26248288544ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:21:25,299][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26157ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:21:30,051][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [26157ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:21:34,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.1s/26157165432ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:21:45,160][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.4s/20463ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:21:48,171][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [20463ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:21:56,012][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.4s/20463061172ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:22:07,468][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22s/22066ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:22:08,579][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [22065ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:22:19,678][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [22s/22065997040ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:22:35,971][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27318ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:22:39,771][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [27317ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:22:45,463][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [27.3s/27317827851ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:22:55,149][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19963ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:23:04,825][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.9s/19963456657ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:23:15,408][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [18738ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:23:13,403][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.7s/18739ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:23:22,731][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.7s/18738461214ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:23:33,617][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.7s/19707ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:23:34,718][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [19706ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:23:44,370][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [19.7s/19706775321ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:23:55,466][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [21224ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:23:54,777][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.2s/21224ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:24:05,460][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.2s/21224743719ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:24:14,835][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20011ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:24:27,095][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20s/20010355140ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:24:41,330][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [24321ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:24:39,233][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.3s/24321ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:24:50,881][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [24.3s/24321525053ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:25:02,344][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23770ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:25:04,920][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [23769ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:25:14,859][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.7s/23769690026ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:25:26,993][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23630ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:25:26,781][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@435fa086, interval=1m}] took [23629ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:25:36,584][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.6s/23629956057ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:25:46,800][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [20889ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:25:46,946][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20890ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:25:59,369][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [20.8s/20889621767ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:26:12,530][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25918ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:26:15,244][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [25918ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:26:25,025][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [25.9s/25918047416ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:26:39,197][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26036ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:26:39,855][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@435fa086, interval=1m}] took [26036ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:26:47,861][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26s/26036195923ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:27:00,748][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21453ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:27:04,068][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [21453ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:27:13,949][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [21.4s/21453084792ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:27:26,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [26373ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:27:26,086][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26374ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:27:30,582][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [26.3s/26373914912ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:27:31,975][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3s/6394ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:27:31,975][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [6393ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:27:33,464][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.3s/6393913763ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:31:20,868][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [5588ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:32:45,641][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [9207ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:33:11,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [5403ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:33:48,278][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [5982ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:34:18,408][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [5589ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:34:47,599][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.1s/5140ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:38:24,546][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5262713752ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:43:00,649][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@435fa086, interval=1m}] took [428885ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:43:52,199][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/428779ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:47:24,779][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.1m/428885030081ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T00:51:57,336][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.8m/590461ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T00:53:15,237][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@57e4b12d, interval=5s}] took [590047ms] which is above the warn threshold of [5000ms]
[2022-04-10T00:33:33,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] failed to run scheduled task [org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker@6e5911ba] on thread pool [generic]
java.lang.NullPointerException: Cannot invoke "org.elasticsearch.cluster.ClusterState.metadata()" because "state" is null
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.hasSearchableSnapshotsIndices(SearchableSnapshotsUsageTracker.java:37) ~[?:?]
	at org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsUsageTracker.run(SearchableSnapshotsUsageTracker.java:31) ~[?:?]
	at org.elasticsearch.threadpool.Scheduler$ReschedulingRunnable.doRun(Scheduler.java:214) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:777) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:26) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
[2022-04-10T00:56:19,420][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.8m/590047233448ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T01:02:15,695][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.3m/623227ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T01:05:42,218][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.3m/623773341328ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T01:10:03,841][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453820ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T01:10:08,986][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [453687ms] which is above the warn threshold of [5000ms]
[2022-04-10T01:13:47,785][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453687648136ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T01:17:43,631][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453850ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T01:18:27,563][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@ee98b86, interval=30s}] took [453548ms] which is above the warn threshold of [5000ms]
[2022-04-10T01:21:38,541][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/453548944962ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T01:25:51,279][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [482673ms] which is above the warn threshold of [5000ms]
[2022-04-10T01:25:50,303][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8m/482672ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T01:31:17,318][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8m/482673302566ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T01:35:03,178][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3m/560813ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T01:38:31,863][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3m/560823963676ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T01:42:17,996][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.5m/451225ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T01:42:38,711][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@38c3b0ad, interval=5s}] took [451496ms] which is above the warn threshold of [5000ms]
[2022-04-10T01:49:35,644][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-10T01:49:35,697][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-10T01:49:35,698][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-10T02:28:09,546][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-10T02:28:09,618][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-10T02:28:09,619][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-10T02:28:09,619][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-10T02:28:09,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-10T02:28:09,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-10T02:28:09,620][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-10T02:28:09,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-10T02:28:09,621][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-10T02:28:09,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-10T02:28:09,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-10T02:28:09,622][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-10T02:28:09,623][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-10T02:28:09,623][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-10T02:28:09,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-10T02:28:09,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-10T02:28:09,624][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-10T02:28:09,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-10T02:28:09,625][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-10T02:28:09,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-10T02:28:09,626][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-10T02:28:09,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-10T02:28:09,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-10T02:28:09,627][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-10T02:28:09,628][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-10T02:28:09,628][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-10T02:28:09,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-10T02:28:09,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-10T02:28:09,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-10T02:28:09,629][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-10T02:28:09,630][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-10T02:28:09,630][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-10T02:28:09,630][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-10T02:28:09,631][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-10T02:28:09,631][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-10T02:28:09,632][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-10T02:28:09,632][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-10T02:28:09,632][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-10T02:28:09,633][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-10T02:28:09,633][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-10T02:28:09,634][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-10T02:28:09,634][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-10T02:28:09,634][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-10T02:28:09,635][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-10T02:28:09,635][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-10T02:28:09,635][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-10T02:28:09,636][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-10T02:28:09,636][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-10T02:28:09,636][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-10T02:28:09,637][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-10T02:28:09,637][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-10T02:28:09,638][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-10T02:28:09,638][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-10T02:28:09,638][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-10T02:28:09,639][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-10T02:28:09,639][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-10T02:28:09,640][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-10T02:28:09,640][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-10T02:28:09,641][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-10T02:28:14,392][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [107.3gb], net total_space [125.8gb], types [ext4]
[2022-04-10T02:28:14,435][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-10T02:28:16,754][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-10T02:30:24,236][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5227ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:30:36,652][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [7205ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:31:53,995][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.2s/5226802989ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:32:11,300][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/117342ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:32:13,389][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [117342ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:32:28,014][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.9m/117342431995ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:32:40,164][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.3s/30380ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:32:51,092][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [30.3s/30379658305ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:32:58,002][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18375ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:05,425][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [18.3s/18375385285ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:13,557][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15287ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:25,232][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.2s/15286691226ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:30,535][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17393ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:37,351][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [17.3s/17393157783ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:43,973][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13494ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:44,117][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [13494ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:33:50,187][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13494044207ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:55,053][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2s/11245ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:33:58,693][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.2s/11244736495ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:08,568][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13437ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:18,259][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [13.4s/13437164965ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:25,029][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.6s/15628ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:34,440][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [15.6s/15627855315ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:38,630][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14695ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:40,951][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [14.6s/14695315152ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:44,420][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5493ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:47,294][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.4s/5492867369ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:49,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5697ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:53,787][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [5.6s/5696794388ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:56,008][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.2s/6200ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T02:34:56,895][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.1s/6199889067ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T02:35:26,436][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [7363ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:36:17,811][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [11079ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:37:15,484][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [12676ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:38:08,385][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [13475ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:39:03,400][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [10748ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:39:56,246][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [11548ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:40:59,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [9033ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:41:59,331][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [10087ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:43:07,916][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [8813ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:43:58,546][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [11430ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:44:46,117][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [9646ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:45:31,346][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [10643ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:46:21,813][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [11303ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:47:28,132][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [15863ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:48:34,542][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [11942ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:49:19,319][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [10460ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:51:07,587][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [9912ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:52:26,611][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [18154ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:53:42,917][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [19463ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:54:46,218][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [16563ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:55:16,692][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [6369ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:55:44,620][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [6856ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:56:19,286][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [5369ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:56:51,820][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [6177ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:57:21,027][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [5441ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:57:46,323][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [6246ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:58:42,422][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [11334ms] which is above the warn threshold of [5000ms]
[2022-04-10T02:59:37,556][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [13710ms] which is above the warn threshold of [5000ms]
[2022-04-10T03:00:33,014][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [11046ms] which is above the warn threshold of [5000ms]
[2022-04-10T03:01:49,704][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@7624d3a1, interval=5s}] took [18282ms] which is above the warn threshold of [5000ms]
[2022-04-10T03:04:47,044][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [21026ms] which is above the warn threshold of [5000ms]
[2022-04-10T03:08:58,046][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7099ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T03:08:57,430][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@55ef50fb, interval=1m}] took [20319ms] which is above the warn threshold of [5000ms]
[2022-04-10T03:16:46,035][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7s/7099317722ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T03:21:29,522][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.8m/770970ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T03:26:11,365][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [12.8m/770935282793ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T03:31:32,697][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9m/595763ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T03:36:00,488][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.9m/595479926333ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T03:40:29,198][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9m/545984ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T03:44:59,603][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.1m/546301767065ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T03:50:29,287][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3m/563702ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T03:50:09,211][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@4f0d045d, interval=30s}] took [563159ms] which is above the warn threshold of [5000ms]
[2022-04-10T03:55:19,946][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.3m/563159153495ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T03:59:38,272][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7m/586040ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T04:02:59,178][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.7m/586212245781ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T04:08:05,243][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2m/495206ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T04:12:43,636][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [8.2m/495576321870ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T04:17:39,113][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [9.5m/573904ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T05:36:14,646][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-10T05:36:27,088][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-10T05:36:27,154][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-10T09:37:54,703][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-10T09:37:54,725][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-10T09:37:54,727][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-10T09:38:01,158][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-10T09:38:01,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-10T09:38:01,160][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-10T09:38:01,164][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-10T09:38:01,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-10T09:38:01,165][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-10T09:38:01,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-10T09:38:01,166][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-10T09:38:01,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-10T09:38:01,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-10T09:38:01,167][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-10T09:38:01,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-10T09:38:01,168][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-10T09:38:01,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-10T09:38:01,169][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-10T09:38:01,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-10T09:38:01,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-10T09:38:01,170][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-10T09:38:01,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-10T09:38:01,171][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-10T09:38:01,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-10T09:38:01,172][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-10T09:38:01,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-10T09:38:01,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-10T09:38:01,173][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-10T09:38:01,177][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-10T09:38:01,178][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-10T09:38:01,180][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-10T09:38:01,181][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-10T09:38:01,183][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-10T09:38:01,183][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-10T09:38:01,184][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-10T09:38:01,186][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-10T09:38:01,187][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-10T09:38:01,188][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-10T09:38:01,189][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-10T09:38:01,190][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-10T09:38:01,191][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-10T09:38:01,192][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-10T09:38:01,193][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-10T09:38:01,193][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-10T09:38:01,194][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-10T09:38:01,194][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-10T09:38:01,195][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-10T09:38:01,195][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-10T09:38:01,195][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-10T09:38:01,196][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-10T09:38:01,196][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-10T09:38:01,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-10T09:38:01,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-10T09:38:01,197][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-10T09:38:01,198][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-10T09:38:01,198][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-10T09:38:01,200][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-10T09:38:01,200][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-10T09:38:01,201][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-10T09:38:01,201][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-10T09:38:01,201][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-10T09:38:01,203][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-10T09:38:01,323][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [107.2gb], net total_space [125.8gb], types [ext4]
[2022-04-10T09:38:01,324][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-10T09:38:01,662][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
[2022-04-10T09:38:18,715][INFO ][o.e.i.g.ConfigDatabases  ] [tpotcluster-node-01] initialized default databases [[GeoLite2-Country.mmdb, GeoLite2-City.mmdb, GeoLite2-ASN.mmdb]], config databases [[]] and watching [/usr/share/elasticsearch/config/ingest-geoip] for changes
[2022-04-10T09:38:18,724][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] initialized database registry, using geoip-databases directory [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ]
[2022-04-10T09:38:21,375][INFO ][o.e.t.NettyAllocator     ] [tpotcluster-node-01] creating NettyAllocator with the following configs: [name=elasticsearch_configured, chunk_size=1mb, suggested_max_allocation_size=1mb, factors={es.unsafe.use_netty_default_chunk_and_page_size=false, g1gc_enabled=true, g1gc_region_size=4mb}]
[2022-04-10T09:38:21,597][INFO ][o.e.d.DiscoveryModule    ] [tpotcluster-node-01] using discovery type [single-node] and seed hosts providers [settings]
[2022-04-10T09:38:23,182][INFO ][o.e.g.DanglingIndicesState] [tpotcluster-node-01] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
[2022-04-10T09:38:24,607][INFO ][o.e.n.Node               ] [tpotcluster-node-01] initialized
[2022-04-10T09:38:24,608][INFO ][o.e.n.Node               ] [tpotcluster-node-01] starting ...
[2022-04-10T09:38:24,650][INFO ][o.e.x.s.c.f.PersistentCache] [tpotcluster-node-01] persistent cache index loaded
[2022-04-10T09:38:24,652][INFO ][o.e.x.d.l.DeprecationIndexingComponent] [tpotcluster-node-01] deprecation component started
[2022-04-10T09:38:25,020][INFO ][o.e.t.TransportService   ] [tpotcluster-node-01] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}
[2022-04-10T09:38:28,472][INFO ][o.e.c.c.Coordinator      ] [tpotcluster-node-01] cluster UUID [Qbw2pof0QzSXC1OvK0aFSw]
[2022-04-10T09:38:28,630][INFO ][o.e.c.s.MasterService    ] [tpotcluster-node-01] elected-as-master ([1] nodes joined)[{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{pSm5apvwSaqxlsQ9tcD2MA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 224, version: 8467, delta: master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{pSm5apvwSaqxlsQ9tcD2MA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}
[2022-04-10T09:38:28,994][INFO ][o.e.c.s.ClusterApplierService] [tpotcluster-node-01] master node changed {previous [], current [{tpotcluster-node-01}{t9hfPgy_RyC9LOJUxQUrSQ}{pSm5apvwSaqxlsQ9tcD2MA}{127.0.0.1}{127.0.0.1:9300}{cdfhimrstw}]}, term: 224, version: 8467, reason: Publication{term=224, version=8467}
[2022-04-10T09:38:29,219][INFO ][o.e.h.AbstractHttpServerTransport] [tpotcluster-node-01] publish_address {192.168.48.2:9200}, bound_addresses {0.0.0.0:9200}
[2022-04-10T09:38:29,223][INFO ][o.e.n.Node               ] [tpotcluster-node-01] started
[2022-04-10T09:38:30,447][INFO ][o.e.l.LicenseService     ] [tpotcluster-node-01] license [06f03395-4097-4495-8e63-b3dc92f4de14] mode [basic] - valid
[2022-04-10T09:38:30,453][INFO ][o.e.g.GatewayService     ] [tpotcluster-node-01] recovered [44] indices into cluster_state
[2022-04-10T09:38:31,808][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip databases
[2022-04-10T09:38:31,813][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] fetching geoip databases overview from [https://geoip.elastic.co/v1/database?elastic_geoip_service_tos=agree]
[2022-04-10T09:38:33,261][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-ASN.mmdb]
[2022-04-10T09:38:34,388][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-10T09:38:34,401][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-10T09:38:34,408][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-10T09:38:35,504][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-10T09:38:36,362][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-10T09:38:37,006][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-10T09:38:37,130][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-10T09:38:37,152][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-10T09:38:37,216][WARN ][r.suppressed             ] [tpotcluster-node-01] path: /.kibana_task_manager/_search, params: {ignore_unavailable=true, index=.kibana_task_manager, track_total_hits=true}
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:725) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:412) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:757) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:509) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$000(AbstractSearchAsyncAction.java:64) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:343) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListener$Delegating.onFailure(ActionListener.java:66) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:48) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:651) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$4.handleException(TransportService.java:853) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1481) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1590) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1564) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:50) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.transport.TransportChannel.sendErrorResponse(TransportChannel.java:45) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:41) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.ActionRunnable.onFailure(ActionRunnable.java:77) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:765) [elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:28) [elasticsearch-7.17.0.jar:7.17.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]
	at java.lang.Thread.run(Thread.java:831) [?:?]
Caused by: org.elasticsearch.action.NoShardAvailableActionException: [tpotcluster-node-01][127.0.0.1:9300][indices:data/read/search[phase/query]]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:544) ~[elasticsearch-7.17.0.jar:7.17.0]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onShardFailure(AbstractSearchAsyncAction.java:491) [elasticsearch-7.17.0.jar:7.17.0]
	... 18 more
[2022-04-10T09:38:41,228][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-ASN.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb.tmp.gz]
[2022-04-10T09:38:41,243][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-10T09:38:41,610][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-ASN.mmdb]
[2022-04-10T09:38:41,660][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-City.mmdb]
[2022-04-10T09:38:42,322][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-10T09:38:42,322][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-ASN.mmdb]
[2022-04-10T09:38:49,082][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [.ds-.logs-deprecation.elasticsearch-default-2022.04.09-000003/gql1LYRDRDCM8vLep2Y_bw] update_mapping [_doc]
[2022-04-10T09:38:54,146][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-City.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb.tmp.gz]
[2022-04-10T09:38:54,207][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-City.mmdb]
[2022-04-10T09:38:54,212][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updating geoip database [GeoLite2-Country.mmdb]
[2022-04-10T09:38:55,335][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] downloading geoip database [GeoLite2-Country.mmdb] to [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb.tmp.gz]
[2022-04-10T09:38:55,370][INFO ][o.e.i.g.GeoIpDownloader  ] [tpotcluster-node-01] updated geoip database [GeoLite2-Country.mmdb]
[2022-04-10T09:38:55,669][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-10T09:38:55,673][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-Country.mmdb]
[2022-04-10T09:38:57,524][INFO ][o.e.i.g.DatabaseReaderLazyLoader] [tpotcluster-node-01] evicted [0] entries from cache after reloading database [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-10T09:38:57,526][INFO ][o.e.i.g.DatabaseNodeService] [tpotcluster-node-01] successfully reloaded changed geoip database file [/tmp/geoip-databases/t9hfPgy_RyC9LOJUxQUrSQ/GeoLite2-City.mmdb]
[2022-04-10T09:39:01,580][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[logstash-2022.04.09][0]]]).
[2022-04-10T09:39:27,142][INFO ][o.e.c.m.MetadataCreateIndexService] [tpotcluster-node-01] [logstash-2022.04.10] creating index, cause [auto(bulk api)], templates [logstash], shards [1]/[0]
[2022-04-10T09:39:27,283][INFO ][o.e.c.r.a.AllocationService] [tpotcluster-node-01] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[logstash-2022.04.10][0]]]).
[2022-04-10T09:39:27,451][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:27,694][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:27,751][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:27,884][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:27,888][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:27,981][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,074][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,157][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,168][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,298][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,392][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,475][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,485][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,644][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:28,815][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:29,531][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:29,847][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:30,228][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:32,542][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:32,730][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:32,737][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:32,752][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:32,959][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:33,440][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:35,536][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:35,721][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:35,733][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:35,945][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,049][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,056][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,202][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,298][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,305][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,320][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,709][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,725][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,938][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:36,946][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:37,103][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:37,284][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:37,465][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:37,752][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:37,944][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:38,177][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:38,398][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:38,407][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:38,730][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:40,365][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:42,740][INFO ][o.e.c.m.MetadataMappingService] [tpotcluster-node-01] [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA] update_mapping [_doc]
[2022-04-10T09:39:52,199][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@44cef54e, interval=1s}] took [6346ms] which is above the warn threshold of [5000ms]
[2022-04-10T09:40:11,946][WARN ][o.e.c.s.MasterService    ] [tpotcluster-node-01] took [16.9s/16930ms] to compute cluster state update for [put-mapping [logstash-2022.04.10/rVYd29SrQtOIx322WnLIUA][_doc]], which exceeds the warn threshold of [10s]
[2022-04-10T09:40:08,561][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4s/6448ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:41:57,759][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [6.4s/6448889760ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:43:16,179][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.2m/192883ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:45:44,330][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3.2m/192882960896ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:45:48,456][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][young][81][22] duration [4.6s], collections [1]/[7.9s], total [4.6s]/[7s], memory [413.5mb]->[244.9mb]/[2gb], all_pools {[young] [168mb]->[4mb]/[0b]}{[old] [207.8mb]->[231.2mb]/[2gb]}{[survivor] [37.6mb]->[13.6mb]/[0b]}
[2022-04-10T09:46:25,340][WARN ][o.e.m.j.JvmGcMonitorService] [tpotcluster-node-01] [gc][81] overhead, spent [4.6s] collecting in the last [7.9s]
[2022-04-10T09:46:18,679][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/183453ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:47:21,757][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [3m/183452370115ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:47:18,069][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@44cef54e, interval=1s}] took [376335ms] which is above the warn threshold of [5000ms]
[2022-04-10T09:47:43,347][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/84371ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:48:32,145][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/84371143314ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:48:58,906][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74924ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:50:15,162][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.2m/74924167018ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:50:42,391][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/104573ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:50:57,732][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.7m/104572876156ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:51:53,697][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70427ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:52:07,407][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.1m/70427280879ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:52:21,587][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.5s/28563ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:52:33,401][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [28.5s/28562308988ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:52:46,095][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23168ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:53:02,507][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [23.1s/23168505227ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:54:15,152][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/89504ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:54:42,750][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.4m/89503663486ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:55:51,026][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91477ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T09:57:37,052][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [1.5m/91477123094ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T09:58:30,350][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.indices.IndexingMemoryController$ShardsIndicesStatusChecker@4e226752, interval=5s}] took [407711ms] which is above the warn threshold of [5000ms]
[2022-04-10T10:00:13,239][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/265167ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T10:03:36,471][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [4.4m/264575507127ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T10:11:54,463][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.6m/701109ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T10:19:34,859][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11.6m/701701157350ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T10:19:40,019][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [ReschedulingRunnable{runnable=org.elasticsearch.watcher.ResourceWatcherService$ResourceMonitor@423e096, interval=5s}] took [701701ms] which is above the warn threshold of [5000ms]
[2022-04-10T10:22:58,756][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11m/663821ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T10:26:31,605][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [11m/663529599502ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T10:30:45,565][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.7m/465638ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T10:35:39,767][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.7m/465359800570ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T10:42:02,671][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9m/654646ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T10:45:46,832][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [10.9m/655214925282ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T10:49:01,442][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/442916ms] on absolute clock which is above the warn threshold of [5000ms]
[2022-04-10T10:54:56,834][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] timer thread slept for [7.3m/442916092797ns] on relative clock which is above the warn threshold of [5000ms]
[2022-04-10T10:57:23,609][WARN ][o.e.t.ThreadPool         ] [tpotcluster-node-01] execution of [org.elasticsearch.cluster.InternalClusterInfoService$RefreshScheduler$$Lambda$5101/0x00000008017dcb18@578e9e6c] took [1098131ms] which is above the warn threshold of [5000ms]
[2022-04-10T11:09:20,421][INFO ][o.e.n.Node               ] [tpotcluster-node-01] version[7.17.0], pid[1], build[default/tar/bee86328705acaa9a6daede7140defd4d9ec56bd/2022-01-28T08:36:04.875279988Z], OS[Linux/4.19.0-20-cloud-amd64/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/16.0.2/16.0.2+7-alpine-r1]
[2022-04-10T11:09:20,576][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM home [/usr/lib/jvm/java-16-openjdk], using bundled JDK [false]
[2022-04-10T11:09:20,577][INFO ][o.e.n.Node               ] [tpotcluster-node-01] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=SPI,COMPAT, --add-opens=java.base/java.io=ALL-UNNAMED, -XX:+UseG1GC, -Djava.io.tmpdir=/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:+ExitOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms2048m, -Xmx2048m, -XX:MaxDirectMemorySize=1073741824, -XX:G1HeapRegionSize=4m, -XX:InitiatingHeapOccupancyPercent=30, -XX:G1ReservePercent=15, -Des.path.home=/usr/share/elasticsearch, -Des.path.conf=/usr/share/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true]
[2022-04-10T11:09:48,661][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [aggs-matrix-stats]
[2022-04-10T11:09:48,667][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [analysis-common]
[2022-04-10T11:09:48,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [constant-keyword]
[2022-04-10T11:09:48,669][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [frozen-indices]
[2022-04-10T11:09:48,670][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-common]
[2022-04-10T11:09:48,671][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-geoip]
[2022-04-10T11:09:48,672][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [ingest-user-agent]
[2022-04-10T11:09:48,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [kibana]
[2022-04-10T11:09:48,673][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-expression]
[2022-04-10T11:09:48,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-mustache]
[2022-04-10T11:09:48,674][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [lang-painless]
[2022-04-10T11:09:48,675][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [legacy-geo]
[2022-04-10T11:09:48,675][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-extras]
[2022-04-10T11:09:48,676][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [mapper-version]
[2022-04-10T11:09:48,676][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [parent-join]
[2022-04-10T11:09:48,677][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [percolator]
[2022-04-10T11:09:48,677][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [rank-eval]
[2022-04-10T11:09:48,678][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [reindex]
[2022-04-10T11:09:48,678][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repositories-metering-api]
[2022-04-10T11:09:48,679][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-encrypted]
[2022-04-10T11:09:48,679][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [repository-url]
[2022-04-10T11:09:48,679][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [runtime-fields-common]
[2022-04-10T11:09:48,680][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [search-business-rules]
[2022-04-10T11:09:48,680][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [searchable-snapshots]
[2022-04-10T11:09:48,680][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [snapshot-repo-test-kit]
[2022-04-10T11:09:48,681][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [spatial]
[2022-04-10T11:09:48,681][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transform]
[2022-04-10T11:09:48,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [transport-netty4]
[2022-04-10T11:09:48,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [unsigned-long]
[2022-04-10T11:09:48,682][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vector-tile]
[2022-04-10T11:09:48,683][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [vectors]
[2022-04-10T11:09:48,683][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [wildcard]
[2022-04-10T11:09:48,684][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-aggregate-metric]
[2022-04-10T11:09:48,684][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-analytics]
[2022-04-10T11:09:48,684][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async]
[2022-04-10T11:09:48,685][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-async-search]
[2022-04-10T11:09:48,685][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-autoscaling]
[2022-04-10T11:09:48,685][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ccr]
[2022-04-10T11:09:48,686][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-core]
[2022-04-10T11:09:48,686][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-data-streams]
[2022-04-10T11:09:48,686][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-deprecation]
[2022-04-10T11:09:48,687][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-enrich]
[2022-04-10T11:09:48,687][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-eql]
[2022-04-10T11:09:48,687][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-fleet]
[2022-04-10T11:09:48,689][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-graph]
[2022-04-10T11:09:48,689][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-identity-provider]
[2022-04-10T11:09:48,690][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ilm]
[2022-04-10T11:09:48,690][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-logstash]
[2022-04-10T11:09:48,691][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-monitoring]
[2022-04-10T11:09:48,691][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-ql]
[2022-04-10T11:09:48,691][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-rollup]
[2022-04-10T11:09:48,692][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-security]
[2022-04-10T11:09:48,692][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-shutdown]
[2022-04-10T11:09:48,692][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-sql]
[2022-04-10T11:09:48,693][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-stack]
[2022-04-10T11:09:48,693][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-text-structure]
[2022-04-10T11:09:48,694][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-voting-only-node]
[2022-04-10T11:09:48,694][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] loaded module [x-pack-watcher]
[2022-04-10T11:09:48,699][INFO ][o.e.p.PluginsService     ] [tpotcluster-node-01] no plugins loaded
[2022-04-10T11:09:48,789][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] using [1] data paths, mounts [[/data (/dev/sda1)]], net usable_space [107.1gb], net total_space [125.8gb], types [ext4]
[2022-04-10T11:09:48,790][INFO ][o.e.e.NodeEnvironment    ] [tpotcluster-node-01] heap size [2gb], compressed ordinary object pointers [true]
[2022-04-10T11:48:12,286][INFO ][o.e.n.Node               ] [tpotcluster-node-01] node name [tpotcluster-node-01], node ID [t9hfPgy_RyC9LOJUxQUrSQ], cluster name [tpotcluster], roles [transform, data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
